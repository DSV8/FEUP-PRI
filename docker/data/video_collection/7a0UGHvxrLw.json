{
    "id": "7a0UGHvxrLw",
    "title": "This is NVIDIAâ€™s new GPU - Blackwell NVL72 Rack",
    "channel": "Linus Tech Tips",
    "channel_id": "UCXuqSBlHAE6Xw-yeJA0Tunw",
    "subscriber_count": 15900000,
    "upload_date": "2024-06-04T18:24:57Z",
    "video_url": "https://www.youtube.com/watch?v=7a0UGHvxrLw",
    "category": "Science & Technology",
    "tags": [
        "NVidia",
        "Computex",
        "Gaming",
        "Computer",
        "Server",
        "Networking",
        "Switch",
        "Games",
        "AI",
        "Programming",
        "Development",
        "Medical",
        "Research",
        "Generative AI"
    ],
    "views": 1681528,
    "likes": 54655,
    "comments_count": 3133,
    "description": "Get a 15-day free trial for unlimited backup at   Check out Ridges Fathers Day sale at  and enjoy up to 40% off!  Linus explores the NVIDIA booth at Computex 2024 looking at one of the LARGEST GPUs we have ever seen, well since its the size of a Server Rack. They also look at Network switches, and use cases for AI in Video Gamers!  Discuss on the forum:   Purchases made through some store links may provide some compensation to Linus Media Group.   GET MERCH:   GET EXCLUSIVE CONTENT ON FLOATPLANE:   GET A VPN:   SPONSORS, AFFILIATES, AND PARTNERS:   EQUIPMENT WE USE TO FILM LTT:   OUR WAN PODCAST GEAR:   FOLLOW US  ---------------------------------------------------  Twitter:  Facebook:  Instagram:  TikTok:  Twitch:   MUSIC CREDIT --------------------------------------------------- Intro: Laszlo - Supernova Video Link:  iTunes Download Link:  Artist Link:   Outro: Approaching Nirvana - Sugar High Video Link:  Listen on Spotify:  Artist Link:   Intro animation by MBarek Abdelwassaa  Monitor And Keyboard by vadimmihalkevich / CC BY 4.0  Mechanical RGB Keyboard by BigBrotherECE / CC BY 4.0  Mouse Gamer free Model By Oscar Creativo / CC BY 4.0   CHAPTERS --------------------------------------------------- 0:00 Intro 2:33 B200 Specs 3:24 The Super Chip 4:10 The Spline? 4:57 Full Tower GPU 6:23 HGX Unit 8:01 NVidia Network Switch 8:24 Use Cases for all this Power 9:12 Use Cases for Gamers 12:45 Outro",
    "description_links": [
        "https://www.backblaze.com/landing/podcast-ltt.html",
        "https://www.ridge.com/LINUS",
        "https://linustechtips.com/topic/1572555-this-is-nvidia%E2%80%99s-new-gpu/",
        "https://lttstore.com",
        "https://lmg.gg/lttfloatplane",
        "http://www.piavpn.com/linus",
        "https://lmg.gg/partners",
        "https://lmg.gg/LTTEquipment",
        "https://lmg.gg/wanset",
        "https://twitter.com/linustech",
        "http://www.facebook.com/LinusTech",
        "https://www.instagram.com/linustech",
        "https://www.tiktok.com/@linustech",
        "https://www.twitch.tv/linustech",
        "https://www.youtube.com/watch?v=PKfxmFU3lWY",
        "https://itunes.apple.com/us/album/supernova/id936805712",
        "https://soundcloud.com/laszlomusic",
        "https://www.youtube.com/watch?v=ngsGBSCDwcI",
        "http://spoti.fi/UxWkUw",
        "http://www.youtube.com/approachingnirvana",
        "https://www.instagram.com/mbarek_abdel/",
        "https://geni.us/PgGWp",
        "https://geni.us/mj6pHk4",
        "https://geni.us/Ps3XfE"
    ],
    "transcript": "Here it is my friends concrete proof that satire truly is dead the GPU beside me contains 36 Nvidia grace Blackwell super chips and is estimated to cost over three million US dollars now Obviously the big heat sink on the side is illustrative. You won't be installing one of these in your gaming rig unless You happen to have a hundred thousand watts of power on tap and a building scale liquid cooling system But many of the technologies nvidia is introducing here will benefit gamers though The biggest one isn't really obvious until you go under the hood in my hands is one GB 200 Super chip now some of this we've seen before like this 72 core nvidia grace CPU But these puppies right here these are all new very very exciting Do you guys see this tiny tiny line here thinner than the width of a human hair? That is the gap between the two black well dies that make up a B200 gpu Wait a second gpu Is that not two gpus? Yes, but also no While SLI might be dead for consumers, NVIDIA has been hard at work creating interconnects that run at absolutely dizzying speeds allowing multiple GPU dies to now act as a single GPU that allow multiple GPUs to act as a single super chip and that allow multiple super chips to act as a single- oh no! to act as a single cohesive processing unit and it is going to unlock gaming experiences and more that are going to blow your mind. You speak English, right? Yes, I speak English. How can I help you? Do you speak chinese? I can speak a little, but it's not my expertise. Can you also speak segue to our sponsor? No, I am also skilled in survival and archery. Yes, you can. Yes, you can. It's fine. Ridge. Ridge has got your last-minute Father's Day gift covered with a big sale. Click on our link in the description and get up to 40% off their rings, their wallets, and more. We'll get to the demos in a bit, but first, let's take a closer look at the product that is turning global tech media into Jensen Huang's Swifties. Nvidia chose not to disclose the number of CUDA cores, tensor cores, or even the size of the on-die caches of their new B200 Blackwell GPU, but they did give us some numbers to work with. Apples to Apples, they expected to hit around 10. Petaflops at FP8 sparse, which puts it roughly two and a half times faster than last gen hopper also each of these is expected to draw about a thousand watts hence the Liquid cooling each of our GPUs gets 192 gigabytes of HBM 3e high speed memory running at a casual 8 terabytes a second and Equipped with 1.8 terabyte per second envy link and these numbers get even more ridiculous when we look at the superchip as a Whole each superchip has to B200 GPUs and a gray CPU for a total of 72 arm CPU cores 864 gigabytes of RAM and draws a total of 2700 watts oh and by the way each of the 18 of these Blackwell compute nodes that make up an nvl-72 rack contains two Superchips good lord in California the rack that I was standing next to in the intro would cost a whopping $30 an hour to run or about a quarter million dollars a year Assuming you're paying residential energy rates speaking of running they literally need to take these demos to another room, so I'm gonna have to tell you about the spline on our way out of here. We got our hands, however temporarily, on what NVIDIA is calling the \"spline\" of their NVL72 rack. This here contains 5,000 wires totaling over 2 miles, and is cleverly laid out to optimize the latency and power efficiency. See, the networking all goes in the middle, right here, and the Blackwell compute nodes, like the one they just took from us, go at the top and the bottom. Now, they could have used fiber optics, except that that would have cost them a casual 20,000 watts of additional power consumption, so clever layout for the win. Put it all together and you've got a whopping 72 Blackwell GPUs, 2,600 gray CPU cores, 13.5 terabytes of HBM3E memory with over half a petabyte per second of aggregate bandwidth. That's good for 720 petaflops of FP8 training, delivering results upwards of 30 times faster than a previous generation HGX-H100. And, if you didn't notice, with perfect linear scaling. Something that is only possible when integrating your system this tightly. Even the placement of the individual blades matter on our super micro rack that we're looking at here You can see that they've got 10 up top and 8 at the bottom with the 9 NVLink switch units sandwiched in between That's because timing the electrical signals matters a lot and is easier on a more symmetrical setup now Unfortunately NVIDIA didn't have a switch for us to show you they'll have to be represented by This piece of plastic, but each of the nine units can handle 14.4 terabytes per second of NB-Link. It is so integrated that Nvidia says they think of this entire rack as one massive power hungry single GPU and It's kind of hard to argue otherwise other than that most of the time It's not doing graphics and I thought that's what the G was for and the craziest part is we haven't even looked at the craziest systems yet That was all MGX, a standard set of reference designs that's intended to be compatible with multiple generations, hence the MG. HGX is a whole different beast. In this, or on it, it is eight Blackwell B200 GPUs with a combined 1.44 terabytes of GPU memory. Absolutely ridiculous. But the difference between this and what I just showed you is completely gone is any trace of grace CPUs. This is purely a GPU board because this insanity is meant to be integrated into a partner system like, say, from Supermicro. Now, Nvidia does sell their own DGX unit with this board and the rest of the components that make up a complete system. But that's mostly intended to be a reference system. These eight GPUs. Get combined with NVLink, just like the rack setup, for a whopping 72 petaflops of FP8 training, while drawing nearly, really, 10,000 watts? Now, naturally, this much power is a little hard to cool, which is why it's so massive. But the good thing about it is it doesn't require messing around with water, or racks with 120,000 watts of power. If you're installing these into an existing data center, since those practically don't exist. So you've got to spread them out a little bit according to your power budget, which means you need networking. And that is where Nvidia's new hardware networking products come in. This ethernet switch will do something in the neighborhood if I think it's like 50 terabits per second of switching. Which is all really cool, but what are we doing with this exactly? I don't know how about health care the tools I'm looking at right here use machine learning to approximate viral protein folding Generate potential drug molecules to disable them and then test rapidly accelerating drug development. Oh, and this is cool Finding exactly what it is you're supposed to be taking a picture of with the ultrasound wand can take a bit of time Why not let the machine identify it for you? That's all left ventricle, right? Cool. Know what else is cool? Simulations like the one we're living in Behind me is earth 2 a climate and weather simulation program that can run at such a high resolution that you can determine what's gonna happen on A one kilometer by one kilometer basis ish, which is pretty cool But what if you need to simulate the movement of hot and cold air on a molecular level? Well, you can do that too. That is nuts, which is all cool But what if I can't afford a DGX or an MGX to train those data sets? Well, you can still use or experience NVIDIA's new NIMS or NVIDIA Inference Microservices. NIMS are pre-trained and pre-optimized containerized AI models that you can download and deploy for any number of use cases. And if that all sounded like gobbledygook, let's go back to that bilingual demo for a second. Facial animations can be an extremely time-consuming component of game development, and are one of the big reasons that localization can be such a challenge. The NIM in use here allows automatic mapping of speech-to-mouth animations and facial expressions. Meanwhile, this guy takes things two steps further, using NIMs for automatic speech recognition and facial animations, but also a third one that I think is perhaps the most interesting to me. There's a major concern right now in the games industry that AI is going to take jobs away from writers. But this guy uses a NIM for data retrieval that is part of in- world AI's platform, and this is really cool. Instead of him just crapping out whatever response chat GPT might throw at you, he's actually got an extensive backstory that does need to be written by a human writer in order to give you a personality and context-specific information that will help you advance the story. Have you ever tried any of the fine merchandise from lttstore.com? Now that is really cool, and we're just scratching the surface right now. Over time, Nvidia is going to be looking to the gaming community, both developers and gamers for inspiration for what to do with these, and oh, I've got one more really cool demo. G-Assist here might just be a tech demo at the moment, but it's a pretty darn compelling one. How do I craft a stone axe? Okay, that is cool, but what dinosaur am I looking at right now? Okay, that's kind of sick. And what's cool is the image recognition, and I believe the voice-to-text are both running locally on this RTX Series GPU. I don't know about you guys, but I think this is so cool that I don't know what to say gue to our sponsor. Backblaze. Losing your data is never fun. So having solid backups of everything is super important. And Backblaze is an affordable, easy-to-use cloud backup solution with plans that start at just $9 a month. You can backup almost anything from your Mac or PC and access it anywhere in the world with their web and mobile apps. And they've restored over 55 billion files. With multiple options for how you can retrieve your data, including having them send a physical hard drive straight to your door. And if you're worried about accidentally deleting files, you can increase your retention history to one year for free. Plus, for organizational and business purposes, their advanced admin controls are designed for security, scalability, and ransomware resilience. Backblaze has over 3 exabytes of data under their management and has the trust of over half a million customers. Including us. That's right. We not only work with them on a sponsored basis, we actually back up our servers nightly to Backblaze. So starting at $9 a month, it is hard to find a better investment than your peace of mind. So sign up today and get a free 15-day trial at backblaze.com/LTT. If you guys enjoyed this video, why not check out our video from last Computex showing off the Grace CPUs and their last-gen Superchips. We got a little bit more into the weeds and it was very, very cool.",
    "transcript_keywords": [
        "friends concrete proof",
        "Blackwell super chips",
        "single super chip",
        "Nvidia",
        "GPU",
        "cool",
        "super chips",
        "gpus",
        "grace Blackwell super",
        "multiple super chips",
        "Nvidia grace Blackwell",
        "single GPU",
        "big heat sink",
        "super",
        "Blackwell",
        "nvidia grace CPU",
        "side is illustrative",
        "friends concrete",
        "concrete proof",
        "proof that satire"
    ],
    "transcript_entity_values": [
        "nine",
        "13.5 terabytes",
        "one",
        "eight",
        "9",
        "Supermicro",
        "3e",
        "NVLink",
        "GPU",
        "Jensen Huang's",
        "nvidia",
        "a hundred thousand watts",
        "G-Assist",
        "AI",
        "about a quarter million dollars",
        "over half",
        "SLI",
        "1.8 terabyte",
        "9",
        "1.44 terabytes",
        "B200 Blackwell GPU",
        "Blackwell",
        "English",
        "first",
        "DGX",
        "Liquid",
        "120,000 watts",
        "nightly",
        "NIMS",
        "Computex",
        "Mac",
        "B200",
        "HBM",
        "just $9",
        "20,000 watts",
        "720 petaflops",
        "one kilometer",
        "CPU",
        "third",
        "chinese",
        "2,600",
        "Blackwell",
        "NVIDIA Inference Microservices",
        "GPT",
        "Ridge",
        "864 gigabytes",
        "50 terabits",
        "California",
        "A one kilometer",
        "Grace",
        "NIM",
        "30",
        "MG",
        "HGX",
        "10",
        "roughly two and a half",
        "5,000",
        "30",
        "18",
        "Superchips",
        "15-day",
        "about a thousand watts",
        "72 petaflops",
        "Swifties",
        "2 miles",
        "two",
        "14.4 terabytes",
        "one year",
        "over half a million",
        "36",
        "second",
        "up to 40%",
        "over three million US dollars",
        "today",
        "NVIDIA",
        "CUDA",
        "RAM",
        "8",
        "72",
        "200",
        "Nvidia",
        "MGX",
        "192 gigabytes",
        "2",
        "10,000 watts",
        "over 55 billion",
        "2700",
        "last-minute"
    ],
    "transcript_entity_types": [
        "CARDINAL",
        "QUANTITY",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "ORG",
        "ORG",
        "PERSON",
        "ORG",
        "QUANTITY",
        "ORG",
        "ORG",
        "MONEY",
        "CARDINAL",
        "ORG",
        "QUANTITY",
        "MONEY",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "LANGUAGE",
        "ORDINAL",
        "ORG",
        "PRODUCT",
        "QUANTITY",
        "DATE",
        "ORG",
        "GPE",
        "PERSON",
        "PRODUCT",
        "ORG",
        "MONEY",
        "QUANTITY",
        "QUANTITY",
        "QUANTITY",
        "ORG",
        "ORDINAL",
        "NORP",
        "CARDINAL",
        "PERSON",
        "ORG",
        "ORG",
        "PERSON",
        "QUANTITY",
        "QUANTITY",
        "GPE",
        "QUANTITY",
        "ORG",
        "ORG",
        "MONEY",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "DATE",
        "CARDINAL",
        "QUANTITY",
        "PERSON",
        "QUANTITY",
        "CARDINAL",
        "TIME",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "ORDINAL",
        "PERCENT",
        "MONEY",
        "DATE",
        "ORG",
        "ORG",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "QUANTITY",
        "MONEY",
        "CARDINAL",
        "TIME"
    ]
}