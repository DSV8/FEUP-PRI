{
    "id": "M9XoUUYeZD8",
    "title": "Yoel Roth warns new X CEO about Elon and company status [FULL INTERVIEW]",
    "channel": "The Verge",
    "channel_id": "UCddiUEpeqJcYeBxX1IVBKvQ",
    "subscriber_count": 3390000,
    "upload_date": "2023-09-29T03:07:32Z",
    "video_url": "https://www.youtube.com/watch?v=M9XoUUYeZD8",
    "category": "Science & Technology",
    "tags": [
        "yoel roth",
        "twitter",
        "elon musk",
        "linda yaccarino",
        "yoel roth interview",
        "kara swisher",
        "yoel roth code 2023",
        "code 2023",
        "code conference",
        "elon musk twitter",
        "twitter ceo",
        "new twitter ceo",
        "twitter elon musk",
        "elon musk twitter ceo",
        "linda yaccarino elon musk",
        "elon musk linda yaccarino twitter",
        "musk twitter",
        "linda yaccarino twitter ceo",
        "code conference 2023 linda yaccarino",
        "social media",
        "twitter news",
        "tech",
        "the verge"
    ],
    "views": 95447,
    "likes": 1776,
    "comments_count": 386,
    "description": "At Code 2023, Yoel Roth, former Head of Trust and Safety at Twitter joined Kara Swisher as a surprise guest an hour before Linda Yaccarino, current X CEO, took the stage. Roth recounted the death threats he received because of Elon Musk, Xs declining users and advertisers, and shared some advice for the platforms new leaders. The two interviews back to back made for a meta-conversation about Twitters past and Xs future. #Code2023 #Technology #Business   Read more:   Watch can watch Linda Yaccarino's full interview here:    0:00 Intro 0:50 Leaving Twitter 4:44 Elons Twitter takeover 7:14 Content moderation on Twitter 10:08 Death threats and Elon 17:08 The use of lawsuits 19:28 Elon Musk biography 20:34 Op-ed 21:55 Censorship investigation 24:50 Government and social media 27:10 TikTok and the 2024 election 29:39 Truth Social and Trump 31:39 Linda Yaccarino and advertisers 33:02 Elon and content moderation 34:07 Xs full potential 35:06 Advice for Linda Yaccarino and Elon 37:00 Audience Q&A  Subscribe:  Like The Verge on Facebook:  Follow on Twitter:  Follow on Instagram:  Follow on TikTok:   The Vergecast Podcast:  Decoder with Nilay Patel:   More about our podcasts:   Read More:  Community guidelines:  Wallpapers from The Verge:   Subscribe to The Vergecast on YouTube, new episodes on Wednesday and Friday:",
    "description_links": [
        "https://bit.ly/3LEqpBb",
        "https://youtu.be/hYymRU-bfpQ?si=gTo2lr1Fl-4DPfes",
        "http://goo.gl/G5RXGs",
        "https://goo.gl/2P1aGc",
        "https://goo.gl/XTWX61",
        "https://goo.gl/7ZeLvX",
        "http://bit.ly/42VeCVU",
        "https://pod.link/430333725",
        "http://apple.co/3v29nDc",
        "https://www.theverge.com/podcasts",
        "http://www.theverge.com",
        "http://bit.ly/2D0hlAv",
        "https://bit.ly/2xQXYJr",
        "https://bit.ly/3I6nJtz"
    ],
    "transcript": "- This is someone who is a truth-teller and someone I really like talking to and you'll see why in just a second, Yoel Roth. (audience applauding) (upbeat techno music) We also coordinated our outfit. - Always. - [Kara] This is like nutty. - I aspire to dress like a stylish lesbian. - Yes, and you've done it. Once again, you've done it. Anyway, how you doing? - [Yoel] I'm all right. - So you were the last-minute add, too, and a replacement for actually- - Surprise! - For Mary Barra, who's the CEO of GM. She was busy. So how's the strike negotiations going? No, wait, wrong question. (Yoel chuckles) I'm excited you're here. And you happen to be in Los Angeles and we were gonna do another interview, so it worked out perfectly. - [Yoel] Yeah. - We did an interview in late 2022, about a year ago when you left Twitter. And it was a month before you left, Elon Musk, who's the owner of Twitter, tweeted, \"I recommend following Yoel for the most accurate understanding of what's happening with trust and safety at Twitter.\" But you left for a number of reasons soon after that, within a month. And I remember when you were on the call, I think I described it on pivot, like a hostage crisis. But anyway, leaving that aside. You said to me, \"I was weighing the pros and cons of an ongoing basis. I knew my limits were. And by the time I chose to leave, I realized that even if I spent all day every day trying to avert whatever next disaster there was gonna be, the ones that got through, there were ones that were got through. And blue verification got through over written advice prepared by my team and others at Twitter. We knew that what was gonna happen. It's not that it was a surprise, it failed in exactly the ways we said it would.\" I'd like you to reflect on that now, about what you were thinking at the time 'cause I think you were surprised and disappointed. - Yeah. You know, when I left Twitter, I reflected on nearly eight years at the company and really on what had been my dream job. Like, I can truthfully say I had a job that was hard, I had a job that exacted some significant consequences, but it was a job I would pick over any other if I could still pick now. Not at Twitter- - And you stayed in the transition for people. You stayed. - Yeah, I did. - Go ahead. - And I stayed because I cared about the platform. I cared about the role that it plays in the world. I'm sure many of us in this room are, were Twitter addicts, and I thought the platform was significant for the future of humanity and democratic deliberation. I also came to realize that there was only so much that one person or a team of people could do at the company in the face of overwhelming pressure to change it. And maybe that pressure would prove to be positive in the long run, but my experience was that it wasn't and that at a certain point I was taking personal costs for decisions that were made against my advice, against my team's advice, and really against common sense. When I left Twitter, shortly before you and I spoke last time, I wrote an essay in the New York Times, where I was like, \"Look, don't panic, everyone. There's all these factors that are gonna constrain what happens next at Twitter.\" And I said, \"It's gonna be advertisers.\" Like surely Elon doesn't wanna burn this $44 billion asset that he just bought to the ground so he doesn't wanna chase away the advertisers. There's no way. He won't do it. I was wrong on that front. 60% of advertisers left and haven't come back. That's a problem. Then I was like, all right, forget advertisers. There's going to be regulatory pressure. The Digital Services Act in Europe is now in force. They can penalize platforms, 6% of their global revenue for non-compliance. It was like, they're not gonna screw it. That 6% is a massive, nope, I was wrong. Twitter withdrew from the disinformation code of practice in Europe. They're the only large platform to do so. And just today, Commissioner Jourova has said that Twitter attempting fate that they are an easy target for enforcement. And so, all right, I was wrong on that point as well. And then the third one I was like, you know, they're not gonna mess with the app stores. That one was more complicated 'cause I gather that Elon and Tim Cook went for a walk in Cupertino and everything is now kinda copacetic. But I wrote all of this expecting Twitter to behave rationally. I wrote this expecting a company that would play by the rules and pursue with self-interest. That was the company that I had known for eight years and that's sort of how we expect large businesses to operate. And that's not what happened at all. - All right, let's talk about what happened because it was a troubled business. I make this point out. They had issues around advertising. They had issues around size, around innovation, about fast-moving. Mark Zuckerberg actually just addressed that in an interview which we'll get to in a minute. And he said exactly what we all said, that this is not innovating fast enough. So there were definite... When he took over, I thought, \"Oh, finally someone's gonna change something.\" I had exactly the same. And we exchanged a number of emails that were very hopeful about what was gonna change. And you stayed. So you decided to stay. But you also said you refused to lie. You had things that you were gonna do. You refused to lie. \"And that one of my limits was if Twitter starts being ruled by dictatorial edict rather than by policy, there's no longer a need for me or my role or doing what I do.\" This is the reason you left, correct? - It is. Twitter was not perfect. It was flawed for all of the reasons you pointed out. And I would add another really big one, which is it had giant safety and security problems. I did the work that I was doing 'cause I wanted to try to improve them, but Twitter was always a platform that was sort of constraining itself and governing itself according to a set of rules and principles, imperfect, but ones that we were striving to perfect. There was always something we could point to that said, \"This is how we are operating.\" And then all of a sudden that didn't exist anymore. There was just sort of direction coming from above about what to do. The first day after the acquisition, there was the directive to change the logged out experience on Twitter. Just a product change out of nowhere. Do it in 24 hours. Why should we do it? Just do it. And the team did. But that was a warning sign. Then it was reinstate some of these accounts. And I managed to talk Elon out of doing that, but it was a directive and that worried me. And we've seen it more and more in the months since. We've seen that the company makes impetuous decisions about banning journalists for talking about the location of Elon Musk's plane and then it reinstates them, sort of, and then it blocks links and then they- - You know, that guy's over on Threads now. But go ahead. - All of this reads to me like a company that has abandoned the rule of law, not just the laws of the land, like the Digital Services Act, but also the laws that it imposed on itself, the operating principles that guided it as a company. - Which some criticized. We'll get to those things. But you also told me, \"One way of streamlining the work of trust and safety, I guess, is to have fewer rules,\" what you're saying. What's been the result of that in your estimation? And in terms of what's gotten worse, is there a good reason for doing it? - Yeah. You know, I think Twitter comms are really terrified that I'm here to trash the company right before their CEO gets on stage. Like, I promise I'm not. - [Kara] No. - I deal in facts, right? I'm a university professor. Let's talk about facts. - By the way, I'm sorry, they can all handle it. So go ahead. - I would hope so. - They're paid the big bucks. Not the title but- - It turns out university life is not as financially lucrative. - [Kara] Right. (audience laughs) - So no, like, let's look at the evidence. We have seen just this week a study out from researchers in Europe talking about the prevalence and spread of disinformation across all of the major platforms. I will give you one guess which platform has the highest degree of spread. It's Twitter. We have also seen research that suggests that the prevalence of hate speech and abuse on the platform is higher. We've seen independent research that suggests that ISIS has staged a 70% return on Twitter. This isn't like free speech. This is ISIS, right? Like, we're not talking about the gray areas of content moderation. By any measure, it's worse. Except by Twitter's measures. So let's actually talk about those, right? So Twitter partnered with a company called Sprinklr and they put out a study in May talking about the prevalence of English language hate speech on Twitter. And their data was impressions on English language hate speech are three-one thousandths of a percent of impressions on Twitter. I'm like, wow, what a tiny number. That sounds amazing. Let's break down what that actually means. So first, this is a completely non-auditable number, right? We are talking about data shared in private between Twitter and one of its partners. This is data about the number of views that a tweet gets, data that nobody can confirm. And it's made available on a privileged basis from Twitter to a select partner whose existence as a company is dependent on continued access to Twitter. That seems to me like a slight conflict of interest, but like, fine, let's set that aside. Don't worry about it. Second, the study is saying impressions on hate speech. This is based on a machine learning model that predicts if something is hate speech. Is the model good? Is it bad? What was it trained on? What are its biases? We don't know. Peer review is a pain in the ass. Every academic will tell you that. But the reason that it exists is so you can answer these questions in a satisfying, empirical way. You can say, \"If we're talking about hate speech, it is defined in a rigorous way.\" We don't know that about Twitter's data. There's simply no way to know. - So, you don't have the ability. So, this is an issue. You've been pointing out these things, including pieces in the New York Times and various places and speaking out. But after you left November 10th, Elon's attitude towards you changed very significantly and he put you, I would say, in deep harm by mischaracterizing a paper you wrote long ago. Explain what you wrote and what he did. - Yeah. So long, long ago, when I was a graduate student, I was studying dating apps. This was back in the early days of dating apps being a thing and I was writing pretty critically about the trust and safety efforts that some of these platforms employed. Specifically, I was writing about the gay dating app Grindr and I said, \"Look, even if this app says it is only for people who are 18 and over, we all know that kids lie. And even if platforms really, really wish that nobody under the age of 18 would sign up for them, they obviously will.\" And so platforms have a responsibility to deal with that. You have to live in the real world, not the imagine world. - This is a problem shared by Facebook and many others. - Everyone. This is just a statement about the reality of the internet and the responsibility that platforms have to deal with. And so what I wrote was very simple. I said, \"Don't pretend that this policy is enough. Recognize your responsibility to protect kids and build a platform that can be safe for them. Don't expect that no kids will be there, expect that they will be there and that you need to create an experience that is safe for them regardless of that fact.\" - And a separate space. No different than Instagram for kids or anything like that. - Which is really hard, right? Instagram for kids scares the bejesus out of me. I think all of these things, any social network that targets kids specifically, has a giant uphill battle. But it's work worth doing. And my argument was that platforms like Grindr should be doing it. That's it. - So, you weren't advocating older people to be dating underage. - No. I mean, my husband's 10 years older than me, but like no, I'm not like making a recommendation that platforms like Grindr or anywhere else have any tolerance for pedophilia, of course not. - So what happened? - So after tweeting publicly that I'm a person of high integrity, after telling people that he has complete confidence in me, you know, the last time I sat down for an interview with you, the retaliation was all of this. So I'm curious to see what will happen after we talk today. But back then, Elon Musk turned to some random person on Twitter who was tweeting at him with an extract from my dissertation and said, \"Well, that explains a lot.\" And what he was suggesting was that the presence of child sexual abuse on Twitter wasn't just a tragedy, it wasn't just a failure of content moderation; it was my responsibility and my fault and that I'd actually made an intentional decision to allow the proliferation of child sexual abuse on Twitter. Nothing could be further from the truth, but it was a smear tactic. It's one that's deployed commonly against LGBTQ folks, and it worked. - So, tell me how you lived for the past year. - In transit, I guess would be the polite way to put it. Shortly after this happened, the Daily Mail published where I live. I had to sell my house. I had to move. I bounced between a couple of different places for a few months with my husband and my dog and all my crap, and then lived in a temporary apartment for a while while I tried to figure out where to land next. - And you got death threats? - Absolutely, many of them on Twitter. And I would note, you know, I imagine one of the things that you'll hear a little bit later on is about all of the work that's been done to make Twitter safer. I would encourage Twitter to take a look at the death threats targeting me, the death threats that were inspired by the company's leader. They're all still there. Twitter didn't take them down. Thousands of them. They're still on the platform today. - I just recently interviewed Adam Kinzinger, same thing. He had death threats. He had all kinds of things because of what he did around January sixth, in opposing Trump. It has a lot of echoes of the same kind of behavior. Did you contact Elon at all, tell him to lay off, or, \"Why are you calling me essentially a pedophile?\" - I've thought about it. - Or implying, I guess. - I've thought about it, but no I didn't. It was so divorced from reality that I was kind of like, do you bring facts to a defamation fight? Like, it didn't make sense in reality. The conversation didn't seem like it was based on anything I said or anything I did and so I didn't believe that anything I said or did would actually change what was playing out. And this is really the thesis of the piece that I wrote in the New York Times last week. I don't think that this is just personal invective. I don't think this is just targeting me because I'm a bad person- - Or you left. - I think it's a strategy. It's a strategy to get people to shut up. It's a strategy to scare every other ex-Twitter employee into never speaking their mind again because look what happens. Look how easy it is to blow up the life of this schmuck. It happened with one tweet. - Let me ask you, what was the worst threat that happened to you? I don't wanna dwell there, but what... Were you scared? - You know, I've been getting death threats online for years- - [Kara] Yes, and Kellyanne Conway was your first. - Was the first person who really put me out there in public. That was an interesting one. But, you know, I don't believe I've had it, the worst of anybody who has been harassed online, far from it. But at a certain point, you start to lose perspective on what's realistic and what isn't. When day in and day out you're getting emails and text messages and DMs and tweets saying that you should be thrown into a wood chipper for what you have done to, you know, sexualize children or to undermine democracy, at a certain point you have to ask yourself like, is this real or is this not? Is somebody going to pull up a wood chipper in front of my house, which, by the way, now they know where it is 'cause the Daily mail published where it is. Like, every time you read one of these things, go through this mental anguish of figuring out, is it real, is it not? - So yeah, whether you're under threat. No, it's terrible. I actually talked to Paul Pelosi about this, which was another tweet- - And, you know, the people who try to defend this as a matter of free speech say, \"Eh, thin-skinned,\" like, \"Why would you take it seriously? This is just people saying things on the internet.\" That's not the experience that anybody who has been abused online will attest to having. - One of the things I always said is one of the reasons the internet is more unsafe than it should be is 'cause the people who made it never felt unsafe a day in their lives. And that's always been my thesis, a general thesis. Not all of 'em, but a lot of them. Let's talk about the use of lawsuits. Elon uses them a lot. People are using 'em now in threats against those, he and other people oppose. It's not just Elon, it's a lot of people. It's a strategy, as you said. You wrote, \"Private individuals from academic researchers to employees and tech companies are increasingly the target of lawsuits, congressional hearings, and vicious online attacks. These efforts, largely staged by the right, are having their desired effect.\" - We've stopped having a conversation about the facts. We've stopped having a debate about which ideas are good, which ideas are bad, good research, bad research. We've sort of entered this phase where silencing people has become the de facto way to advance your interests. And this is playing out really, really clearly in the academic domain. Hundreds of university researchers, people who are not usually in the limelight, they're writing some papers, they have some graduate students, university researchers are now getting sued and are subject to discovery in these lawsuits and have to turn over thousands of emails between them and their students and about research projects for ultimately frivolous and vexatious lawsuits about, I don't know, censorship or something. These are, to be clear, not people who could ever censor anybody on any social media platform- - They don't have the power. - But they're now being sued. They have to do it. - All the people I cover, who used to talk to me regularly, will not talk to me, on the record. None of them. They're terrified. Now, let me be very... The critique is that left does this, too, in the cancel culture, academics. \"The corollary,\" next sentence, \"being universities are weeding out professors for having dissenting opinions. Social media companies are booting or disclaiming those that disagree.\" I agree with you, but it's not the same thing. But give us a nuanced argument a 1,200 word piece can't have, what's that defense? 'Cause there's censoriousness, most certainly, on the left. - Yeah. Look, I think the refutation here is, I think the phrase is you're decorum-pilled. It's this idea that like if people aren't behaving with perfect decorum, then you can silence them by attacking the manner of their expression rather than the content of their ideas. And I'm actually pretty sympathetic to that. I haven't read the Musk biography yet. I know we're gonna talk about that, but like my husband flipped through it- - I did that for everybody so you didn't have to. - Excellent. My husband flipped through it and he gave me his review, and he said, \"You use a lot of profanity.\" And for anybody who knows me, that's broadly accurate. I'm actually very surprised I haven't yet cursed on stage. But the question is like, is that legitimate? Is that a question of decorum? And are my ideas delegitimized by the fact that I use profanity? I think having those kinds of arguments gets silly. You should be talking to people about what they're trying to argue, what their points are, and what their evidence are. And we end up in these slightly silly conversations about who's using the right word for what and are you saying it in the right ways? I think all of that undermines the quality of the discussion. I want us to have a conversation about evidence. When we talk about how much hate speech there is on Twitter, I wanna have a conversation about the methods behind the study. Is the data real? Is it three-one thousandths of a percent or not? And we've moved so far away from that. - Right, and that's the way they do it. Let's talk about the effective tools to fight back narrative towards like your op-eds, or in this discussion, lawsuits like ex-employees are pursuing, in the case of Twitter at least, regulation government inquiries like the FTC consent degree. Can any or all of them work when it comes to arguing with the person who's the richest person on earth? And then you call for regulation and pulling out of tricky countries in your op-ed, which seems unrealistic. - Yeah. Look, I think the regulatory time moves a lot slower than internet time and so I think we're going to see lagging effects here. But it is inevitable. I think if the European Union has proven anything, it's that they are willing and able to regulate large companies and push them to abide by the laws of the European Union. And so if I had to make a prediction, it would be that, it won't be right now, might not even be a year from now, but there will be consequences. The question is how much damage happens between now and then to individual people who work at companies, like me, to the quality of the conversation on Twitter, to the platform itself? I think there's a lot that can be done before regulation catches up with reality, and that's what really worries me. - Okay. It's not just these ridiculous tweets from Elon, it's Jim Jordan, his goose chase of you, and I'm gonna call it a goose chase, whatever he does, and Chris Krebs who worked for Trump and was fired because he told the truth about the election denialism, what is the status of that and the impact? I saw his badly written letter to you. Where is that right now? They're investigating you for being the great censor of, you don't particularly strike me as the most powerful person on earth, but- - No, I'm truly not- - Please, disabuse me if that's the case. - I don't believe so. But no, I'm one of hundreds of academics who have received letters from Jim Jordan and the House Judiciary Committee, saying that they would like to interview us. And these interviews are not public. The transcripts of these interviews are not public. But you are asked questions for hours. And to be clear, I already testified about everything that I know in front of the House Judiciary Committee for five hours in February. Like, that already happened. But there's more questions, I guess. I haven't had the interview yet, but there have been many others who have. And what happens is a strategy. There's an interview. The transcript of the interview isn't public. Excerpts of it are then taken out of context and make their way into things like an amicus brief, in a lawsuit, or then become a quote that's used in a report attacking the Department of Homeland Security. None of it is fact-based. All of it is about insinuation and innuendo, and that's the outcome. And what really worries me is not sitting down on the record for another interview with Jim Jordan or his staffers, bring it on. What I worry about is that the results of that, the transcript of it, the things that I'm saying, won't actually be made public. I don't believe I have anything to hide. The Twitter files, or the contents of my corporate email account for eight years, like it's all out there. I'm an open book. But I want it to actually be open and that's not what we're getting as a product of these investigations. - Yeah, that investigation at the Twitter files seemed a little light. - Yeah, yeah. You know, I think by the time I left my corporate Gmail account, was like 150 gigabytes of stuff. And there's a lot there. There's a lot there that I think would be important for understanding the future of social media, what- - Yeah, there's something about us coordinating our outfits and everything like that, yeah. - Yeah, it's true. It's true. But like, that's not what we got, right? We didn't get meaningful transparency into the coercive influences on Twitter's decisions. I think that's a real problem, right? I think if the government is pressuring tech platforms to censor, like we should all be terrified about that. I wrote a piece today for the Knight First Amendment Institute that says, yeah, jawboning is an issue, but we need to have a fact-based- - This is from the government pressure, and I'll get to that case 'cause it was interesting. At one point you and a bunch of you were dealing with an issue and the person, that particular person, I don't remember which one of them was, was saying, \"Can you believe they all got together and discussed this?\" And I was like, \"They're the managers of the whole company. Yes, I do believe it.\" Like, it was- - I believe we were doing our job. - That's what I said. And you may or may not have made good decisions, that's very different. But there are also critical court cases of the government talking to social media, you're calling it jawboning, that are winning. They're winning in these things, that the government now is completely, everyone in government is not talking to social media companies as we're going into a election. If you were still running trust and safety, what do you do then? You're not hearing from the government critical things, whether it's CISA or whoever. - This scares the crap outta me. Like when I think about the biggest risks that we are facing in 2024, it's actually not, even if these court cases succeed, this is the interesting bit, a lot of elements, 9 parts out of 10 of the Fifth Circuit's ruling in Missouri v. Biden were actually overturned. The decision was most of the communication between governments and platforms can happen. But after that happened, did you see governments start talking to platforms again? No. The meetings are still canceled. Nobody's talking. The strategy works even when it loses in court, and that's really what worries me. It's a chilling effect. You don't actually need to prohibit government from talking to platforms, you just need to scare them into not doing it. It's what they're doing to academics, it's what they're doing to folks working in government, and it's what they're doing to the platforms themselves. And the result of it is that- - 'Cause they don't know what's gonna happen so they'd rather be judicious, correct? - Because the alternative is getting roped into a lawsuit, getting hauled in front of the judiciary committee, having a public hearing where Marjorie Taylor Greene calls you a pedophile, like those are the consequences. - Did she do that? - To me? Yeah. - Okay. - Not fun. But if you look at it and you're like, \"Well, I could talk to platforms and deal with all of that, or I could just not do that,\" the decision is obvious, you don't do it. Engaging on these issues is an act of courage and the incentives for that courage no longer exist in Silicon Valley. - Right, to do anything about it. So, let's get into the real implications of the upcoming election. Who is doing it well? There's Facebook, Instagram/Threads, there's Bluesky, Mastodon/post-Snapchat. Who can do it well, or are they all just like, \"Eh, we don't have to do it anymore.\" - All right, I'm gonna say something really controversial. - Okay. - I think TikTok are doing it well. - [Kara] Oh, wow, okay. - So let me caveat this by saying I don't use TikTok, I don't allow it on my phone, and I don't allow my husband to have it on his phone on our home WiFi. I've also written previously about why I worry, from a national security standpoint, about TikTok. But of all of the big platforms, of all of the VLOPs, the very large online platforms as they're called in Europe, only one of them hasn't laid off their trust and safety staff this year. It's TikTok. And they continue to invest heavily in addressing misinformation. They continue to invest heavily in identifying inauthentic behavior, bracket, would they find it if it was coming from China? I don't know. But I continue to see them actually invest in these areas because they're worried about getting banned, but they're still doing it. So, I think TikTok are doing a good job here. - And everybody else is pulling back. - Other than the new platforms, right? I'm seeing that we're about out of time so I'll end on perhaps- - No, it's okay. It's okay. No, I've got a couple more. I get to stay here as long as I want. I made this conference. - The perks of being Kara Swisher. (audience cheers) (audience applauding) So on an optimistic note, like we are in probably the most exciting moment in the last 15 years of social media because finally there's an incredible amount of investment in building new stuff. We are seeing a lot of new entrants. You named a lot of them. My personal favorite is Bluesky at the moment, but it's anybody's game, and that's really cool. Because from a consumer standpoint, for the first time in 15 years, it's not something that's taken for granted, that your network is on Twitter or on Instagram. It's wherever. - [Kara] Or you have many. Or you have many, you know. I'm using Threads a lot, which is interesting, which apparently caused Mark Zuckerberg, he said, \"She must really like me more.\" And someone's like, \"No, she likes Elon less.\" (Kara laughs) I don't like either of them. So I mean, whatever. I don't care. I don't honestly care. I have a life and a family. Anyway, on Truth Social, I have a couple more questions, I do wanna get through them, Trump is kind of losing his mind. It's a short trip obviously. (audience laughs) He's called for the execution of the US as a top general. People are shrugging. Oh, well, he did that today. You know, every day it's a different, like new fresh hell and everyone doesn't care. Give me your argument for just letting this go or the argument for doing more vigilant kinda stuff. They just sorta let him, like he's the crazy uncle on the corner screaming at people. - Yeah, we can't let that happen, right? Like the shifting Overton window of what is acceptable and what isn't, even on something as simple as violence, is terrifying to me. Like, when you sort of ease up on questioning whether it's ever acceptable for somebody to call for the death of another person, I feel like there's a profound loss there for humanity and I worry that we can't walk back from that. - So what do you do? - Well, I'm not using Truth Social. - Yeah, okay, good. All right, check. What are the breaks in the system you're seeing? Or where is the company better off where you left it or what's going to happen from having been there so long? Now you're not on the inside, you don't know. There might be Keebler elves in there making it all right but- - It could happen. I'm not optimistic. I mean, just today the last remaining staffers at Twitter, who have expertise in election security, we're all summarily fired. So like when I went into to this year and people started asking me, \"What do you predict about 2024?\" I was like, look, there's one person still left at Twitter in Dublin who has single-handedly kept global elections from going off the rails. I hired him myself. He's brilliant. For as long as he can stick it out, there's a hope. Summarily fired. So I'm not super optimistic about that. - Mm-hmm, okay. Just three more questions and we'll get to some questions in the audience and the people backstage can deal with it. Linda Yaccarino will be up here shortly. I know Linda really well, terrific advertising executive. I have had great experiences with her over the years. I'm surprised by some of the stuff at Twitter, but she'll answer her questions from Julia Borsten. I think the big question here is whether she's got the power to effect change or recruit advertisers, something she's again fantastic at, giving Elon's incessant and sometimes problematic meddling, and that's a nice version of it. Do you think she has the power to lead Twitter/X? And will advertisers come back? - Advertisers aren't stupid. If there's a change that I saw in my time at the company, it was that the advertising industry and the marketing industry collectively stopped buying bullshit from platforms. They demand data, they demand evidence. And it can't just be cherry-picked evidence that the platform hands out in an unaccountable way, they want proof. And I think having a reasonable, tenured, well-respected executive at the helm is a good thing. I don't know her personally, but I hear a lot of the same things that you just said. I think that's great. But for advertisers to come back to Twitter, and to be clear that's where the money comes from, I think they're going to need evidence of progress on safety that Twitter can't provide. And they can't provide it because Twitter is less safe now than it used to be. - And What is the impact end of Elon if he is, is he the singular leader from your perspective and can you have an effective content moderation organization where this is, over here he's talking with the, I haven't brought up the ADL at all yet. That was just, again, the latest fresh hell. - Yeah. If Elon is calling the shots, then that is a version of content moderation. But is it what Twitter's users are looking for, and is it what Twitter's advertisers are looking for? And I think the evidence suggests that it isn't. Twitter's own data about the number of tweets on the platform suggests that there's been a 75% drop in the amount of content on the service. Three quarters of the content on Twitter went away from its peak. That's their numbers. That should be really scary. That should be setting off alarm bells for Linda and for the rest of the executive team at Twitter. How do you turn that around? How do you make people start tweeting again? I'll give you a hint. Make it safe. They're not doing that. I don't think it works. - Okay, so I have two more quick interviews, it's interesting in this interview that Mark Zuckerberg did with Alex Heath, saying he was a change agent, and I believe that too. \"I do think he's been pretty polarizing.\" This is Mark saying, it's so typical. Pretty polarizing. Really, Mark? You're kidding. Oh, Mark Zuckerberg. He's funny. \"The chance that X reaches the full potential on the trajectory it's on, I think it's less of a chance than it was before.\" So do you agree with Mark Zuckerberg on that? - That X is not on the most positive trajectory? Yeah, that seems like a safe statement. - Okay. And you said to me at the end of our interview a year ago, it's my last question, when I asked you for any advice for Elon before he attacked you, by the way, and you were very kind, I thought, much kinder than you needed to be, and you said, \"Humility would go a long way.\" And I said, (laughs) \"No.\" I was dubious, and I was right. But that's not the point of that. What advice would you now give to Elon and what advice would you give to Linda? - I'll start with Linda. I read the profile of her in the Financial Times by Hannah Murphy and I was really struck by her talking about the challenges that she experiences with abuse and harassment targeting her and I truly feel for her. I genuinely, genuinely do. Nobody should have to experience that. Not a CEO, not a journalist, not me, not anybody. Look at what your boss did to me. It happened to me. It happened after he sang my praises publicly. It happened after... I didn't attack him, I didn't attack the company, I- - You quietly left. You wouldn't talk to me. I know that. - And then he did that to me. If not for yourself, for your family, for your friends, for those that you love, be worried. You should be worried. I wish I had been more worried. And so I hope she is thinking about what those risks are and what she might face. - And to Elon? - I believe there are still people within Twitter who care about the platform, who care about making thoughtful, principled, evidence-backed decisions, and who advocate for Twitter's users. Listen to them, give them space, don't overrule them. And that's very hard to do, I think. I wouldn't bet that it's likely to happen. But building a social network is really complicated. It's really hard and it requires a lot of difficult decisions. You can't do it by instinct. You've gotta do it by data. And I worry that that's not the decision-making style at Twitter anymore. - On that note, questions? - Hi, Ina Fried from Axios. I'm curious what your advice would be to the advertisers. In your piece, you wrote that advertisers would be, you know, a check on what Elon did. You know, many of them left, but a number, Apple, Amazon continue to advertise- - Cheech and Chong, don't forget them. - [Ina] Cheech and Chong, you know- - Really? - Yeah. A lot of fucking Cheech and Chong. - They have great edibles by the way. - [Kara] Yeah. - [Yoel] Huh, noted. - But what responsibility, do you think, the current advertisers have? What would you encourage them to do? Should they all just leave? Do you think they can be a force for change? - I believe they can be. I think advertisers are one of the most powerful forces influencing social media. And I believe they can use that power to affect positive change. I would encourage them to use it. But I would encourage them to use it thoughtfully and to demand rigorous data that helps them evaluate what's going on. If Twitter becomes safer and they can prove it, then run ads on it. If Twitter isn't safer or they can't prove it, then don't run ads on it. But I would really encourage, you know, the concept of brand safety is having a moment now. Everybody's talking about brand safety, they're talking about the proximity of, you know, ads to hateful tweets. That's not how people think of platforms like Twitter. If I'm encountering hate speech on Twitter, I don't think about it as, is the tweet before or after an ad hateful? And if it isn't, then everything on Twitter is great. Hate speech is more than just ad proximity. Don't just look at brand safety metrics when you're evaluating this. But it has to come down to data. And I do believe advertisers are smart enough to demand that kind of information. - Right here. - Jay Peters with The Verge. Do you think we'll ever see something like Twitter ever again? I'm not asking you to pick a winner between Threads or whatever, but will there ever be something that was quite as culturally relevant as Twitter ever was? - Twitter was never the biggest, as we all know. It was never the platform with billions of people. But it was the platform where a community of influential people were able to connect with each other, connect with their audiences, and where people were able to influence the elites. I agree actually with some of what Mark Zuckerberg said in his interview, that there remains a hunger for that. I think that needs to exist in the world. I think people want it to exist in the world. I do hope somebody can capture that. I hope they can do it better than Twitter did. - Do you have who it's gonna be? Will it be Twitter? - Again, I'm really excited about decentralized platforms. I'm excited about bringing more user agency and control to how social media works. I'm excited about the idea of having online communities that are smaller than all of humanity. Like, Instagram's like two billion people, like that seems a little bit too big to govern in my opinion. - One of the problems is they're hard to use, some of them. I mean, my favorite joke is that certain, I guess it was Mastodon, is like the waiter giving, handing you a gun and saying there's the cow, good luck kinda thing. (audience laughs) - Anyway. - That's brutal. - I know it was, but it was- - But no, like you can solve UX problems, right? Like, somebody can fix that. There are thoughtful designers who can solve that. - Okay, good. Very quick. One, two, very quick. All right, go ahead. - It's so nice to see you. I'm so glad you're here. As a content creator, I just wondered how, similar to the Axios question, you know, how can we sort of influence trust and safety? You know, I left the platform Twitter after covering the Twitter matter last year in a lot of depth. And it was really sad when I had to leave because I just felt like it wasn't a place where I could keep contributing content anymore with what it's become. And sometimes that feels like the right decision, sometimes it feels like the wrong decision. And I just wondered what your thoughts were about, you know, sort of- - Content creators. - Yeah. You know, people ask me, do you judge people who still use Twitter after everything that happened to you? And my answer is no. And the reason that I don't is because I think it's hard to walk away from an audience. If your livelihood is dependent in many ways on having that audience, on being able to reach people, if your theory of change in the world is being able to impact public discourse, walking away from that audience means sacrificing your ability to do what you are on this planet to do. And so I don't judge people who use Twitter, but I would encourage them to, I would encourage everybody really to think about where you can find a new audience and to take your attention and the value that you are creating for these platforms to somewhere that is consistent with your values and your theory of change in the world. And it's hard to walk away from the followers, but find somewhere that is consistent with what you want to do in the world and the audience will find you again. - I've stayed there. I mean, I got there first. Fuck you all. I got there in 2007. I was like, I'm not leavin'. I don't put anything about my personal life on it now, and I block comments. And let me just say publicly, I get so many stupid right-wing people saying, \"How dare she block comments,\" as if I'm gonna let someone vomit on me all day. But it's because I have never gotten attacked until this year. I've been on there since 2007, and the stuff I get is vile, so I block comments. That's just the way it goes and it's my business. I don't feel like being vomited on all day, and I get that. Last very quick question 'cause they're gonna kill me if I say stuff, not that I care. - I just wanted to leave with hope. And that as CEO now, she's not co-CEO, she's CEO, to give her that chance and that hope that she will bring brand safety to a great platform as X and to leave it with that. - Do you think she has the power to do so? - I absolutely do. He wouldn't have chosen her as CEO. - Okay, where do you work? - The Female Quotient. - Okay, great, perfect. All right, we'll do that. We do have hope that- - I hope so. - Yeah. - I really do. I'll close with what I told Elon when I quit. I told him I'm rooting for you and I'm rooting for Twitter. This was before he called me a pedophile. So I will say like my opinion of Elon has shifted somewhat. But I am rooting for the people who use Twitter to affect change in the world. I'm rooting for the platform and I'm rooting for its role in the world. And if Linda, as a leader, can make that platform a success, that will be a wonderful, wonderful thing and I'm rooting for her too. - On that truthful, not neutral, fantastic. Thank you, Yoel. (audience applauding) Thank you.",
    "transcript_keywords": [
        "Twitter",
        "people",
        "Elon",
        "Yeah",
        "left Twitter",
        "platform",
        "platforms",
        "Mark Zuckerberg",
        "lot",
        "left",
        "Yoel Roth",
        "advertisers",
        "platform Twitter",
        "change",
        "company",
        "social media",
        "social",
        "talking",
        "interview",
        "time"
    ],
    "transcript_entity_values": [
        "hours",
        "The first day",
        "Biden",
        "Elon",
        "three",
        "Ina Fried",
        "November 10th",
        "the last 15 years",
        "a month before",
        "Alex Heath",
        "Jim Jordan",
        "Twitter",
        "late 2022",
        "Ina] Cheech",
        "a year from now",
        "Kara",
        "a few months",
        "2024",
        "Missouri",
        "English",
        "One",
        "Kellyanne Conway",
        "75%",
        "Mastodon",
        "TikTok",
        "Chong",
        "Yoel Roth",
        "150 gigabytes",
        "24 hours",
        "May",
        "18",
        "the Knight First Amendment Institute",
        "this week",
        "hundreds",
        "third",
        "Second",
        "Hannah Murphy",
        "GM",
        "Paul Pelosi",
        "Overton",
        "60%",
        "Twitter",
        "nearly eight years",
        "Thousands",
        "the Department of Homeland Security",
        "LGBTQ",
        "Hundreds",
        "Gmail",
        "Mary Barra",
        "Linda",
        "70%",
        "Julia Borsten",
        "Elon Musk",
        "Daily",
        "three-one thousandths",
        "Three quarters",
        "eight years",
        "this year",
        "China",
        "ISIS",
        "1,200",
        "the Financial Times",
        "10 years",
        "first",
        "Adam Kinzinger",
        "Instagram",
        "about a year ago",
        "a year ago",
        "Truth Social",
        "Mark",
        "Twitter",
        "10",
        "last year",
        "Elon",
        "only one",
        "6%",
        "two billion",
        "FTC",
        "Cupertino",
        "a month",
        "ADL",
        "Silicon Valley",
        "the early days",
        "US",
        "Facebook, Instagram/Threads",
        "Jourova",
        "the months",
        "15 years",
        "Keebler",
        "Facebook",
        "Trump",
        "last week",
        "billions",
        "Yoel",
        "second",
        "Elon",
        "the judiciary committee",
        "Threads",
        "Linda Yaccarino",
        "Grindr",
        "the New York Times",
        "CISA",
        "The Verge",
        "a minute",
        "Marjorie Taylor Greene",
        "Los Angeles",
        "Bluesky",
        "February",
        "one",
        "Kara Swisher",
        "Apple",
        "Cheech",
        "Jay Peters",
        "Axios",
        "UX",
        "the European Union",
        "today",
        "$44 billion",
        "January sixth",
        "the Fifth Circuit's",
        "Twitter/X",
        "Europe",
        "Trump",
        "the years",
        "Tim Cook",
        "the House Judiciary Committee",
        "all day every day",
        "five hours",
        "two",
        "the past year",
        "Elon Musk's",
        "turn over thousands",
        "Chris Krebs",
        "Amazon",
        "all day",
        "9",
        "Dublin",
        "Mark Zuckerberg",
        "2007",
        "Sprinklr"
    ],
    "transcript_entity_types": [
        "TIME",
        "DATE",
        "PERSON",
        "PRODUCT",
        "CARDINAL",
        "PERSON",
        "DATE",
        "DATE",
        "DATE",
        "PERSON",
        "PERSON",
        "PRODUCT",
        "DATE",
        "PERSON",
        "DATE",
        "PERSON",
        "DATE",
        "DATE",
        "GPE",
        "LANGUAGE",
        "CARDINAL",
        "PERSON",
        "PERCENT",
        "PERSON",
        "ORG",
        "PERSON",
        "PERSON",
        "QUANTITY",
        "TIME",
        "DATE",
        "CARDINAL",
        "ORG",
        "DATE",
        "CARDINAL",
        "ORDINAL",
        "ORDINAL",
        "PERSON",
        "ORG",
        "PERSON",
        "PERSON",
        "PERCENT",
        "ORG",
        "DATE",
        "CARDINAL",
        "ORG",
        "ORG",
        "CARDINAL",
        "ORG",
        "PERSON",
        "PERSON",
        "PERCENT",
        "PERSON",
        "PERSON",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "DATE",
        "DATE",
        "GPE",
        "ORG",
        "CARDINAL",
        "ORG",
        "DATE",
        "ORDINAL",
        "PERSON",
        "ORG",
        "DATE",
        "DATE",
        "WORK_OF_ART",
        "PERSON",
        "PERSON",
        "CARDINAL",
        "DATE",
        "ORG",
        "CARDINAL",
        "PERCENT",
        "CARDINAL",
        "ORG",
        "GPE",
        "DATE",
        "ORG",
        "LOC",
        "DATE",
        "GPE",
        "WORK_OF_ART",
        "PERSON",
        "DATE",
        "DATE",
        "ORG",
        "ORG",
        "WORK_OF_ART",
        "DATE",
        "CARDINAL",
        "PERSON",
        "ORDINAL",
        "PERSON",
        "ORG",
        "PERSON",
        "PERSON",
        "PERSON",
        "ORG",
        "ORG",
        "ORG",
        "TIME",
        "PERSON",
        "GPE",
        "PERSON",
        "DATE",
        "CARDINAL",
        "PERSON",
        "ORG",
        "PERSON",
        "PERSON",
        "PERSON",
        "ORG",
        "ORG",
        "DATE",
        "MONEY",
        "DATE",
        "ORG",
        "PRODUCT",
        "LOC",
        "ORG",
        "DATE",
        "PERSON",
        "ORG",
        "DATE",
        "TIME",
        "CARDINAL",
        "DATE",
        "PERSON",
        "CARDINAL",
        "PERSON",
        "ORG",
        "DATE",
        "CARDINAL",
        "GPE",
        "PERSON",
        "DATE",
        "ORG"
    ]
}