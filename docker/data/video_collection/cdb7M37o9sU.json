{
    "id": "cdb7M37o9sU",
    "title": "The Internet just changed.",
    "channel": "David Bombal",
    "channel_id": "UCP7WmQ_U4GB3K51Od9QvM0w",
    "subscriber_count": 2650000,
    "upload_date": "2022-07-24T14:30:07Z",
    "video_url": "https://www.youtube.com/watch?v=cdb7M37o9sU",
    "category": "Science & Technology",
    "tags": [
        "tcp",
        "udp",
        "quic",
        "http",
        "http/3",
        "http 3",
        "http 2.0",
        "http 2 vs http 1.1",
        "http3 vs http2",
        "http 3 nodejs",
        "http 301 redirect",
        "http 3 explained",
        "python http 3",
        "http 3a",
        "www",
        "wireshark",
        "wireshark http",
        "wireshark https decrypt",
        "wireshark http 2",
        "wireshark quic",
        "wireshark http 3"
    ],
    "views": 412409,
    "likes": 10777,
    "comments_count": 882,
    "description": "You better be aware of what just changed on the Internet. TCP is being replaced with QUIC. UDP is being used more and more instead of TCP. This affects your firewalls. It affects a lot of your network troubleshooting. HTTP/3 has been standardized. Everything is encrypted with QUIC - welcome to the new world of network troubleshooting and security.   // MENU // 00:00 - The Problem with TCP 00:12 - Introducing//Robin Marx 02:12 - Clean Ship, Clean House//RFCs 03:25 - HTTP Semantics//QUIC//HTTP/3 04:17 - Why the Hell Do We Need HTTP/3? 05:05 - Why QUIC? 08:35 - QUIC & TLS Integration 10:02 - Why Use UDP? 13:50 - Replacing TCP with QUIC 14:28 - Summary So Far  15:22 - Stream Multiplexing 15:40 - Head-of-line blocking 18:40 - Why This Slows Things Down 19:29 - How QUIC Does It Differently 20:58 - TCP vs QUIC//Packet Handling 23:11 - HTTP/3 Prioritization 25:25 - Stats//QUIC Isn't Going Anywhere  26:30 - Firewalls are almost useless 27:20 - Firewalls Blocking QUIC? 28:04 - QUIC & Other Protocols? 29:20 - IPv4 & IPv6//Different for QUIC? 29:54 - Challenges for QUIC's Growth 30:43 - Connection Migration 33:33 - What About Hackers?  36:32 - How Do I Get To Use QUIC? 38:28 - Large Companies Adopting QUIC 39:09 - The Internet is Too Centralized? 40:02 - Header Compression 41:55 - Server Push 43:47 - Practical Examples with Wireshark 50:34 - Thank You & How to Contact Robin  // Robin SOCIAL // Twitter:  LinkedIn:   YouTube:   // Robin's Blog articles // HTTP3 core concepts Part 1:  HTTP3 core concepts Part 2:  HTTP3 core concepts Part 3:   // Chris Greer Videos // HTTPS Decryption with Wireshark:  Decrypting TLS, HTTP/2 and QUIC with Wireshark:   // David SOCIAL // Discord:  Twitter:   Instagram:   LinkedIn:   Facebook:   TikTok:  YouTube:    // MY STUFF //   // SPONSORS // Interested in sponsoring my videos? Reach out to my team here: sponsors@davidbombal.com  http https quic tcp udp http/1 http/2 http/3 wireshark firewall firewall quic quic firewall http/3 firewall  #http3 #quic #tcp",
    "description_links": [
        "https://twitter.com/programmingart",
        "https://www.linkedin.com/in/rmarx/",
        "https://www.youtube.com/channel/UCyqPrNfndJ7OPhPdYJG-mmQ/videos",
        "https://www.smashingmagazine.com/2021/08/http3-core-concepts-part1/",
        "https://www.smashingmagazine.com/2021/08/http3-performance-improvements-part2/",
        "https://www.smashingmagazine.com/2021/09/http3-practical-deployment-options-part3/",
        "https://youtu.be/GMNOT1aZmD8",
        "https://youtu.be/yodDbgoCnLM",
        "https://discord.com/invite/usKSyzb",
        "https://www.twitter.com/davidbombal",
        "https://www.instagram.com/davidbombal",
        "https://www.linkedin.com/in/davidbombal",
        "https://www.facebook.com/davidbombal.co",
        "http://tiktok.com/@davidbombal",
        "https://www.youtube.com/davidbombal",
        "https://www.amazon.com/shop/davidbombal"
    ],
    "transcript": "- And that's kind of the problem with TCP. - What about hackers? 'Cause is that connection ID not exposed? - [Robin] And that's the question, right? - This is gonna make a lot more sense. (upbeat music) Hey, everyone, it's David Bombal. Back with a very special guest, Robin, welcome. - Hello, David. - It's wonderful to have you because I believe things have changed recently on the internet, which affects all of us, right? - Exactly, the introduction of HTTP/3 will have massive repercussions in the coming years. So, important to get to know right now. - I saw you tweet about this and that's how we set this call up. So tell us kind of like, what's happened briefly and why do we care? - Interestingly, it's already been affecting you for quite some time. HTTP/3 has been in the works since 2012, started at Google who deployed it widely for Google Search and YouTube. And then they transferred it to what is called the IETF, the Internet Engineering Task Force. The organization that actually standardizes protocols. So a lot of people from like Mozilla, Microsoft, Facebook, several bigger companies came to join in to specify what this new HTTP/3 and actually the underlying transport protocol called QUIC, that we're gonna talk about should be. And the idea is that these are next generation protocols that are very evolvable towards the future. And they've actually been deployed at wide scale since 2018 already. And a lot of browsers already have support and about one fourth, so 25% of current internet traffic, at least for the bigger companies, is already HTTP/3 and QUIC. So if you're watching this on YouTube, big chance you're already using HTTP/3 right now. - Are you helping write the standards or what's your sort of involvement? I've seen you say you've been doing this for quite a few years. - So I started as a PhD researcher on HTTP/2, looking at its performance. And then just as I was doing that, HTTP/3 was starting up at the IETF. And so I was able to kind of organically roll into that and I was able to actually contribute quite a bit to this effort. I mainly made a lot of debugging and analysis tools. Think about Wireshark, and then very specific for QUIC and HTTP/3. And if you scroll down to the HTTP/3 RFC, all the way at the bottom, there's a long list of people involved and quite proud that my name is on there as well. So I wouldn't say I had the biggest impact there, but I've definitely been involved I think for over five years now. - Let's start with the RFC thing. What's the RFC for HTTP/3, but there's quite a few of them, isn't it? - This is where it gets somewhat complicated. HTTP/3 itself is one RFC, It's 9,114. But it's actually comprised of several other RFCs you also need to make the total package work. The two main ones you need are also called QPACK, which is header compression. And then there's also a new, Extensible Priorities RFC that kind of works for both HTTP/2 and HTTP/3. So you need that to get optimal performance. And the reason why HTTP/3, its standardization was delayed somewhat because for example, QUIC, the underlying protocol has been standardized for a few months already. This was delayed because they have also done a major reworking of HTTP/1, HTTP/2, and then they've kind of split out common concepts in two new documents called HTTP semantics and then also caching separate document. Those were previously coupled very tightly with HTTP/1. And so now they decided to clean ship, clean house, do everything correct in their separate documents. They call it the cluster, a big cluster of different HTTP-related RFCs. And that came out exactly three weeks ago now. Was finally standardized, yeah. - You've mentioned QUIC and HTTP/3, is it the same thing, is it different? And how's has it changed things? So I just wanna give you the floor and if you can kind of explain the rationale to getting here and I see you got UDP there. Why is there UDP? Why are we not using TCP? So a bunch of random questions, but what is QUIC? What is HTTP/3? Why do we care? Why are we using UDP, et cetera? - Lots to unpack, let's start at the beginning. What is HTTP/3? And why do we need it especially? That's the question I get a lot because HTTP/2 has only been from 2015, that's not too long ago, right? And as you can see in this slide, I like this slide because it really shows that HTTP/2 and HTTP/3 are really quite similar. They do very similar things. There was a much, much bigger difference between HTTP/1 and HTTP/2, but two and three are much more similar. So why in hell do we need HTTP/3? It's really not HTTP/3 we wanted, we wanted QUIC. And what is QUIC is actually more intended to be a replacement for TCP. So TCP, your bread and butter protocol that most things on the internet use. That is something we have wanted to upgrade or replace for a long, long time, and that is now finally here with QUIC. And originally the idea was that we would just run HTTP/2 on top of QUIC, that that was just gonna be like a swap-out replacement as is intended by this whole layered protocol model. In practice that turned out to be way too difficult. And so we kind of made a new version called HTTP/3. It has exactly the same features as HTTP/2, I should say, but implements them in a very different way. So the practical details are different, the high-level features are almost exactly the same. - So why do we have QUIC? - So QUIC, and this is an interesting one. TCP has been around since, say the '80s. And it served us very, very well, but there are some downsides that we want to mitigate. And a good example of that is connection set up time. So as you probably know, TCP starts with a three-way handshake, the SYN SYN-ACK ACK handshake. And that takes a full round trip on the network. And especially if your client and server are far from each other, that round trip can take about, say even 200 to 300 milliseconds. And it's not just that, after that you get also the TLS handshake, which an older version of TLS took two round trips. Luckily with the newer TLS 1.3, we got that down to just one. But it's still one additional round trip. And it's only after that, that you can actually start doing HTTP level requests, like send your first request and get response back. So in these situations, even with TLS 1.3, you're raising three round trips, sometimes over half a second before you get useful data back. And that is somewhat logical. If we go back historically, we of course wanted to run HTTP/1 for example, with and without TLS on TCP. You had HTTP plain text and then HTTPS, and you could just swap out TLS or just leave it out. So that was logical, and that's what led to this setup. Everything is nicely and cleanly separated. The protocols don't need to know about each other to function, but it's inefficient because what you really want is kind of like the third column here, where you would actually want to combine the TCP and the TLS handshake in a single round trip. What you actually actually want is the fourth column. Why can't we just do everything at once? Single round trip, everything is as fast as it can be. There was no technical reason why we can't do that because QUIC does exactly this. So what they tried to do was integrate this into TCP. TCP originally can't do this, but they were like, \"Okay, let's just make a new TCP extension, which is called TCP fast open. And TCP fast open says, \"Okay, normally in the SYN SYN-ACK, you cannot send data. The SYN and SYN-ACK packets cannot contain data. They're only TCP headers. New extension fast open allows you to carry data. And so you can put in there the TLS data, and even if you want HTTP data as well. Fine, everything happy, everything is more efficient now. That's not really what happened because what happens on the internet is it's not just your client and server. In between are a lot of what they call middle boxes, other appliances that also speak TCP. One of the best examples of this is a firewall and a firewall is gonna look at the TCP-level data and try to figure out is this a legit connection or is there a hacker trying to do something that's not correct? If you have a firewall that was implemented before TCP fast open was thought of, that firewall is gonna see, \"Okay, TCP should not have data in their SYN packets. Suddenly I see connections with data in the SYN packets, that's not okay, that's probably a hacker trying to do some nasty stuff. I'm just gonna drop these weird SYN packets.\" And so when they tried to deploy TCP fast open, which has been around for almost a decade, I think since 2012, this was standardized. A lot of connections simply fail. They simply get dropped at these middle boxes. And so it has taken almost a decade for this kind of optimization to be introduced into TCP proper. So it kind of works now. It still doesn't work well enough for big browsers to enable it, but it sort of works on most networks by now. And so the idea for QUIC is then if we want the next big feature, we don't wanna wait a decade. We want to be able to deploy this within months of us needing it, and so we want to do something new. And so this is basically the big thing that QUIC changes, as opposed to TCP. What QUIC is going to do is gonna deeply integrate with TLS. TLS is no longer an optional protocol. It's no longer layered on top of QUIC, it is deeply integrated inside of the protocol. - HTTP/3 is always encrypted, is that right? - Yes, absolutely. Now HTTP/2 conceptually could be done plain text, but no browser ever implemented that. So in practice, HTTP/2 was also always encrypted. At least for the browsers. But so HTTP/3, yes, there is currently no way to do this unencrypted. And this is not really to provide better encryption of your user data, because that is already fully secure with HTTP/2 as well, right? All your passwords, all your emails are perfectly safe. What QUIC is going to do is it's also going to encrypt the transport level headers. In TCP, you have things like packet numbers or sequence numbers, acknowledgement numbers, flow control windows, that kind of stuff. All the things that are in TCP header, those are plain texts visible on the wire. With QUIC, that is no longer the case. As you see here, we encrypt much, much more of the transport-level stuff, including things like packet numbers that were usually visible. The reason for that is, again, the hope that if the middle boxes cannot read this data because encrypted data looks like random data to outside observers. If they can't read it, they can't interpret it. And so they can't break, if we ever change QUIC to have a new field in there or a different extension that we want to add. The firewalls can't read it, so they hopefully won't drop it if it's something they don't expect. - Is that the same reason why you use UDP rather than just having QUIC directly on IPs? Is that kind of the logic because of these middle boxes? - Yeah, and that's exactly the same reason. That's always a question, a misinterpretation I've seen. They say, okay, they use UDP because it is faster. And that is completely not true because QUIC basically re-implements everything we have from TCP. Everything that makes TCP conceptually slower than UDP. It re-implements it. We have congestion control, we have connection setup, that kind of stuff. UDP is only used because middle boxes, again, don't expect anything else than TCP or UDP directly on top of IP. - So it's a myth to say that HTTP/3 is a lot quicker than HTTP/2, or is it kind of quick, but not really that quick, is that right? - No, it is faster, but it's not because it's using UDP. It's because it's doing smarter things or doing more things. What I will show you about the connection setup in a moment. That is why HTTP/3 and QUIC are faster. It's not because of UDP. UDP is only there again, because middle boxes expect TCP or UDP. If we try to run QUIC directly on top of IP, that's possible, there's no technical reason why that's not possible, but practically and deployment wise, you would also, again, have to update a lot of those middle boxes along the way to suddenly expect that. And they said, \"Let's not do that, let's just run it on top of UDP,\" because most appliances, if maybe they don't allow UDP yet, but at least they speak UDP, they know who UDP is. That's, indeed two things. We run on top of UDP and we are deeply encrypted mainly to prevent middle boxes from messing with our traffic. And that allows us to be much more flexible in the future. And that's also why we can't just have a TCP 2.0, because that would take years to deploy. As we've seen with TCP fast open, and there are several other TCP extensions that we've tried over the years that also failed to quickly find sufficient deployment. One example would be TCP multipath for example. QUIC is much more flexible, and the TLS integration means that we can do in QUIC standard what we wanted to do with TCP all along. So if we look at the QUIC's basic handshake, that's the third column here. It is always going to combine the QUIC transport-level handshake, basically the QUIC SYN SYN-ACK flow. And then the TLS handshake is combined into a single round trip. So that's how QUIC is already one RTT faster on average than your basic TCP stack. Not because of UDP again, but because it combines the two. And it can then interestingly go even further. What we really wanted, as I said before, was something like here on the right side, right? Combine everything into a fully complete round trip. And that's now actually possible with QUIC, with a feature called 0-RTT. And the idea there is that the first connection you have to a QUIC server that you haven't seen before, that has to do the two handshake. But during that connection, you can actually negotiate encryption keys for the next connection after that. And so if you do the next connection to a server you've already known and you've remembered those encryption keys, then you can immediately encrypt your first HTTP request in the first round trip. And so you can combine all three layers. The transport layer, the security layer, and the application layer all into a single round trip basically, and get a lot of data in earlier. And that's, I would say the killer feature of HTTP/3 and QUIC. There are other performance optimizations that we'll talk about later, but this is the main one. The one that most users probably will find impact on, the most websites will find most impact from this one. One nuance I want to add is that 0-RTT is not a QUIC-only feature. It's also something you can use with HTTP/2, because it's a TLS feature. So you can also do this for the TCP stack, which is great. You can also speed that up. You just won't have the nice one RTT for everything. You will still need two RTTs because we can't combine the TCP handshake with other things because TCP fast open is difficult to deploy. - I've read on your blog, you said something along these lines that this is replacing TCP with QUIC, and then you get HTTP/3 as a bonus, kind of thing. Is that right? - Yeah, I would say that's correct. The idea of QUIC is to replace TCP for the future to make it more flexible in the end. TCP HTTP/3 is not really a bonus. It was more like a necessity, because we can't run HTTP/2 directly on top of QUIC. HTTP/2 apparently was designed with a little bit too much reliance on TCP specifics that QUIC broke that we can talk about in a second. And so it was too difficult to just keep it. And so HTTP/3 is just something we need to be able to use QUIC practically. - To get the benefits like faster connection set up. Well, I mean it's been tried, tried to rewrite TCP or add features to TCP, but it was taking forever to get the middle boxes to support this stuff like the routers and the switches and all the firewalls really, I suppose the big one. So it made more sense to create a new protocol. So QUIC is like TCP version whatever. Like a brand new protocol. You had to use UDP because otherwise the little boxes wouldn't support it. And then to use QUIC, you had to get HTTP/3 because HTTP/2 doesn't support all the stuff of QUIC. So that's kind of like big picture. Is that a correct summary? - I think it's a perfect summary, yeah. - The first big killer feature is the QUIC setup. Rather than going three-way handshake and then a bunch of other stuff sent between. In the best case scenario, it's one to server from client and then back again, and we're done, yeah? - Exactly, that's right. That's the first big feature. The second big feature, and maybe that'll give you some insight in why we couldn't just reuse HTTP/2. You could see that here on the image, the stream multiplexing. In HTTP/2, that was part of H/2. And now that has actually moved into QUIC to reduce something called head of line blocking. - I've seen that used a lot, can you explain that? - This is a bit technical, so let's see if I can explain it correctly. The idea is that TCP, so the second row here, TCP, as you may know, it doesn't actually have packet numbers, TCP has sequence numbers. And the sequence numbers mean this TCP packet carries between byte, let's say here, byte 450 and byte 749, in a specific byte stream. So basically TCP thinks it's only carrying one byte stream, in practice, just one resource. One file is being downloaded over TCP. That's how it was originally designed. For websites, that's of course not the case. We don't have just one resource, we have multiple. In this case, we have two, we have a CSS file and a JavaScript file. We both want to download those over a single TCP connection. And you can't do that because TCP doesn't allow you more than one resource at a time. That was one of the big problems with HTTP/1. And so what HTTP/2 did was say, \"Okay, we're just gonna abstract that away, and we're gonna introduce the concept of independent byte streams at the HTTP/2 layer. So as you can see there on the top, what HTTP/2 actually does, it injects, they call it frames, but it's really like a mini packet, like a mini HTTP/2 packet gets inserted there. And this says for example, the data frame is called. It says the CSS file is a stream with ID one. And the JavaScript file is a stream with ID two. So those are different, one and two are different. And so we have separate resources. This means that when you get this data back, the browser can decode this. They can know, \"Okay, the coming 450 bytes are CSS, the ones after that, the 300 bytes after that or JavaScript. And so they need to be handled differently. And that works fine. TCP doesn't have to know anything about this, and we can still send multiple resources on one connection. The problem becomes what happens if this middle TCP packet is dropped. There is there's some problem in the network, the center packet is lost, but the third packet it does arrive. And so now conceptually at the HTTP/2 layer, we know, and the browser knows that the CSS stuff is actually not interrupted. CSS, we had the first 450 bytes, and in the next 550 bytes, we have that. Those are there, we can actually just process all of our CSS data. It's only the JavaScript that has been delayed. That's the only one we should wait for the retransmission to come in. We know that at the HTTP layer. TCP does not notice. TCP thinks it's only sending one file. It only has like one byte range there. And so it loses a full byte range 450 to 749. It doesn't know any data after that might be independent from that central packet. And so what it has to do is it has to be conservative. It knows the center packet is lost. Everything after that might depend on the center packet, I'm gonna have to be careful and just not process anything after the lost packet, until the return transmission comes. You leave a little bit of performance lie on the table. Because the CSS could have been processed before the retransmission came. And this is what is called head of line blocking. So the packet loss is at the head of the line, the head of the packet line. And you have to replace it at the head of the line before everything else can proceed. - So in other words, the CSS gets delayed, even though it's not necessary to delay it, while we're waiting for that piece that went missing to come back. The head of line, like you said, that initial packet is delaying all the others from being processed, even though they could have been processed, right? - Yeah, that's exactly the problem. - It slows things down again. - It slows things down again, not necessarily slows it down in a huge way, but it is less efficient than it could be. You could squeeze more performance out of it, that's the way I like to look at it. And so basically, what QUIC does is it takes this concept of these streams, so the stream IDs that we had in HTTP/2, and it takes those from the HTTP layer and it brings it down into the transport layer. And so you get a comparison like this, where this stream ID stuff and tracking which bytes belong to what stream, that's no longer done at the HTTP level, this is done at the transport level. So now QUIC suddenly knows there are multiple independent streams going over the network. - Oh, I see, you've moved it down. Yeah, yeah. - We've moved it down, QUIC no longer has sequence numbers. QUIC has actually proper packet numbers. Packet one, two, three, not sequence number that are sometimes difficult to follow in something like Wireshark. QUIC has nice packet numbers, very good. QUIC uses what are called stream frames, which are basically saying, \"Okay, for this stream, we now have byte X to Y. So in this case, byte zero to 449, that's for stream one. The next packet carries JavaScript. That starts again, that is again byte zero to 299, because it's specific for that JavaScript stream number two. An important note to make that I like to make also is that QUIC doesn't need to know about JavaScript, CSS. What exactly is in these streams of course, it's not that tightly coupled. It just needs to know these are independent things that are going over my single connection. Why? And this is where we get to the fun stuff, right? If in QUIC, here the second packet is lost. QUIC will then receive the third packet and it can see, \"Okay, the first packet had byte zero 449 for CSS, and this third packet just starts at byte 450.\" So there is no gap for the CSS, and so, \"Hey, why wouldn't I be able to process the CSS? Because I have all the data, the full byte stream of CSS is intact.\" For JavaScript it sees, \"Oh, this suddenly starts at by 300. I haven't gotten bytes zero to 299 yet,\" because that's in the lost packet, so it blocks the JavaScript file, but it passes on the CSS data to, for example, the browser for processing. - In TCP, if you are the server, let's say, and I'm the client, my client would set up a connection to your service. So that would be one connection, and within that connection, I've got these little streams, which are like, I don't know what the right term is, but stream is obviously the right name, but many connections within that one main connection. But TCP is not clever enough to handle that if one of those goes missing. In QUIC, we've still got one connection, multiple streams, but just the way that it's been implemented, QUIC doesn't slow things down when one of those streams has a problem, like many connections has a problem, correct? - Yeah, exactly. - And the reason for doing this is if you connect to a modern web server, you've got a whole bunch of different files rather than downloading them sequentially. You wanna be able to download them in parallel. Hence the idea of streams, is that right? - Yeah, you want to download in chunks, interleaved in many different ways to get more performance as well there. That is one of the main ways that this works. This then leads to other QUIC benefits, like smarter loss detection and usage. QUIC doesn't need to retransmit full packets, it can retransmit parts of packets if it wants to. And this is one of the key points I think that makes HTTP/3 plus QUIC faster, is that QUIC, can for example in HTTP/3, we will have a concept of stream priority. So some files are gonna be more important than others. Your JavaScript and CSS are gonna be more important than the image file on the bottom of your page, at least in the beginning. So if you have a packet loss for both the JavaScript and the image file, in TCP it wouldn't matter. It would just transmit it in the order they were originally transferred. In QUIC, you can make much smarter decisions. You can say, \"Oh, the JavaScript file is much more important, has a higher priority. I'm going to retransmit the lost packets for the JavaScript file first so that they can be processed first and later I will retransmit the image.\" I can even delay the retransmissions for the image until after the CSS is done, or until after higher images have been discovered and processed. This allows for a much tighter integration between HTTP/3 logic, with us knowing some files in a webpage are more important than others. And that then directly impacts for example, retransmission logic, loss detection logic, at the transport layer through this stream mechanism. - Who decides what's more important? - Yeah, so that is a wholly different topic. I've got this next slide kind of tries to show you how difficult this can get. So here each row is a different way of doing prioritization and each color is a different resource. As you can also see in the legend at the bottom. And there are many, many different ways to do this. You can say that the JavaScript files are all more important, you can say the fonts are more important. You can say it depends where the JavaScript file is in the webpage, the JavaScript file is async or defer. Many, many different ways of doing this. And browsers now, even if you're a front-end developer, you can use features like preload resource hints or things like priority hints or image lazy loading attributes if people are familiar with that, to explicitly tell the browser, these resources are more or less important for my specific page. And that then influences how this prioritization is done. To answer your question, the browser has a basic set of rules that it thinks these things are more important most of the time and then developers can actually influence this in small ways using HTML and JavaScript APIs for that. And that then also influences how this is actually sent on the wire as you can see here. But prioritization is a much more complex concept. I don't think we want to dig too deep into that today. - No, no, I mean, the fact that you said that the browser has stuff built in and the developers can kind of influence it. That's enough, I think for us to know. It's just good to know that that's possible. - Exactly, and so to get back to this, I wanted to round this up with this is one of the main reasons why we couldn't just run HTTP/2 on top of QUIC. Because HTTP/2 has streams. QUIC also has streams, and so we would have two different stream abstractions colliding basically. And we tried to solve this with all kinds of hacks and work arounds, it just didn't work. So one of the big changes between HTTP/2 and HTTP/3 is HTTP/3 doesn't know about these streams directly. It offloads that to QUIC internally, basically. But the concept is still the same, like I said initially. The high-level feature, the idea of the multiple streams is still there, it's just technical implementation that has changed. - For a long time, it was like, TCP is the protocol. And now suddenly it's like UDP is the protocol. You've basically replaced TCP with QUIC, but you were forced to use UDP. So we are gonna see a lot more UDP I'm assuming. I mean, like you said, 25% or something already on the internet, right? - Yeah, yeah, yeah, exactly. So you're gonna see a lot more UDP, but really it's QUIC over UDP. But yeah, at this point, for example, companies like CloudFlare, they track it. So radar.cloudflare.com, they show a breakdown of a lot of statistics and one of them is HTTP version and they get like 26-30%, depending on when you look at it. Another question I often get asked is when will QUIC completely overtake TCP. When will it be 100%? And so what I think will happen is that we will grow very fast to like 50% QUIC, within the year from the big deployments, because Amazon is now rolling it out. Azure is starting to roll it out. So within the year 50%, and then it's gonna take us about 10 years to go up to like 80 to 90%. One of the problems there is of course security. Firewall administrators and network administrators don't like to allow UDP because it's often used in all kinds of attacks, that's one aspect. Even if they would allow QUIC over UDP, QUIC is so encrypted. Again, this allows QUIC to be flexible, this allows QUIC to evolve, but it also means that firewalls are almost useless for QUIC. They almost have nothing to work with. They either just have to trust that QUIC will get it right, or just drop it in its entirety. And that's not really fair. There are a lot of security features built into QUIC that help prevent this kind of attack. So a lot of UDP-based attacks are actually mitigated in several ways inside of QUIC as well. So it should be quite safe to use, but then of course will be a lot of network administrators saying, \"No, I'll rather be safe than sorry,\" and just block it entirely. So I don't think HTTP/3 will ever get 100% deployment or I should say QUIC will ever get a 100%. They will always coexist next to each other or at least for a long time for those reasons. - If a firewall blocks QUIC, do the browsers and the servers just renegotiate or negotiate to go back to TCP? - Yeah, it's actually smarter than that. Browsers will open parallel connections. If they try to do HTTP/3, they also do HTTP/2 at the same time. If HTTP/3 is blocked, it doesn't get through, then HTTP/2 will just go through. And the user usually doesn't notice any interruption of service because of that. - So yeah, so the browsers and the servers work around that problem, which is great, 'cause I mean, I think the worry is okay, so if browsers are going to QUIC, what happens? Do I have to go and change all my firewall rules? - But that is also kind of a downside because that doesn't force firewall administrators to switch because they could just, \"Even if I block QUIC, it doesn't matter because people will still be able to use HTTP/2. - Does QUIC only support HTTP or does it support other protocols? - No, and this is crucial, I think, it's a very good question. I think this is a crucial thing to understand and also why we often make the difference between H/3 and QUIC. They are completely different because QUIC is really a replacement for TCP. Meaning you can run any type of application level protocol on top of it, conceptually. We are seeing SSH over QUIC. We are seeing SMB over QUIC. People are talking about doing realtime video streaming over QUIC in various ways. So it's really intended to be a general purpose transport-level protocol that can be used for many other application layer stuff, not just HTTP/3. HTTP/3 was the main reason. The main use case that we had in mind originally, but it has evolved to be much, much more flexible. Again, very important to know, these things are not tightly coupled. QUIC is completely loose from HTTP/3, even though a tighter coupling is possible and get you even more benefits. You can run basically anything on top of QUIC, but probably like with H/2 to H/3, it's gonna require some changes to your application level protocol. You're rarely able to just take the application level protocol and run it over QUIC without any changes. So that's gonna be a long-term process to see who wants to switch and how that can be done for individual protocols. - QUIC implementation, I see you've got IPv4, IPv6. It's similar, or do I have to learn a whole different type of QUIC for IPv6, or is it the same kind of idea? - No, it's exactly the same. Just like with TCP, it's completely independent from the IP version used. - For years, we've been told to learn UDP and TCP as the two big transport layer protocols. Now it's gonna be QUIC, TCP, UDP kind of thing. - Yeah, and from my perspective, I've been teaching this at the university as well. I've had some networking courses and that's gonna be a big challenge from my perspective. QUIC is difficult to properly understand. If you look at the RFCs for QUIC, those are four different documents. Many, many, many pages to even understand the basics of how it actually works internally. You need a lot of baggage and even then. So that's gonna be a big challenge, educating people. And that's one of the reasons that I've been trying to push out a lot of videos and blog posts and Twitter threads to help people understand in a more simpler way, to help them understand the basics before digging into the really underlying complex stuff and really trying to use it. That's another reason why I think it will take a long time to get from the 50% to the 80% because the moment people can't just flip a switch, for example, on a CDN like CloudFlare or Akamai. The moment people actually have to start manually using this, for example, in their apps through libraries, or in their stuff. Is gonna be much more difficult. - We've covered two big advantages already, is faster connection setup and then head of the line blocking. Is there another big advantage? - So one of the most talked-about features is called connection migration. The common use case is what they call the parking lot problem. So let's say you are currently indoors. You have your cell phone, which is connected through wifi to your office, for example. But then you move outside to the parking lot, it's time to go home. You move out of range of the wifi and your cellphone automatically switches over to the 4g network. And that works, the problem is from a TCP standpoint, you suddenly switch IPs 'cause 4g network is completely different. And the way a TCP connection works, it just looks at the client and server IP and the TCP ports and the client ports and the client IP changes because we change networks. Any TCP connection you have in that instance is gonna have to be shut down, it's not usable anymore, and you need to reestablish all your TCP connections from the start. So you need to do all the connection setups again, you need to warm up your congestion window to get up to better data speeds again and so on. If you're doing something like let's say video streaming or a big file download or a game for example, you will have an interruption of service that may or may not be quite large. And that's kind of the problem with TCP. So what QUIC does instead is it will use what is called a connection ID. So each connection is not just the IPs, it is also a unique number, and then when you move between networks, it will keep this connection ID the same. Because we keep that constant, even though the IP and the ports change, the connection ID is the same, and so the server knows, \"Oh, this is actually the exact same client that I had before, we can keep on using the same connection. We don't need to do a new connection setup. - That's great, that's a huge thing, yeah, that's huge. - The way that works, by the way, is by including this connection ID in every packet. So QUIC's packet header is quite different from TCP's already. And it also includes this new field called the connection ID. And that's actually one of the few fields that are not encrypted in the QUIC packet header, because you do want middle boxes to be able to view the connection ID. For example, load balancers. They usually work on the IPs and they keep the load balancing routing stable based on IPs. that no longer works here. So they need to be updated to use the connection IDs to keep the same connection going to the same backend server, even though the IPs change. - That's great, so from a client point of view, it's seamless, yeah? You just go from your wifi to your 4g or whatever and it just switches. - Exactly, it's probably not gonna be 100% seamless, because we change networks and we don't know how much capacity we have on a network. So what you're basically gonna do is you're gonna fall back to what is called slow start. If you were on a very fast wifi sending several megabits per second, you're not gonna be able to keep on doing that on 4g, you're gonna start slow again, try to figure out what capacity do I have. So it's not gonna be seamless, seamless, but it's gonna be much better than TCP. - You're not resetting your connection. I mean, that's huge. - Exactly, exactly, and that's already a big one. - What about hackers? 'Cause is that connection ID not exposed? - Oh, and that's the question, right? Because a connection ID is exposed. If you would do it exactly like here on the right side, you could have big hackers, let's say nation states or big companies that have a lot of different points of observing traffic. They can actually start tracking users geographically across different networks. We don't want that. You set up a connection on wifi. Once that is encrypted, so no-one in between can see what's happening, QUIC is going to negotiate new connection IDs. Those are exchanged in encrypted ways when the encrypted QUIC connection. So the middle boxes, the observers don't know about these, but the client and the server they do. So basically every connection is mapped to several connection IDs, not just one, it's several. And so when you switch networks, you just switch to the next connection ID as well. So here we're not reusing the green one, that would be very unsafe. We switch to the purple one. And the client and server know purple equals to green because it negotiated it. But no hacker in between knows this because the negotiation was done in the encrypted connection. In the QUIC RFC, they call the linkability prevention. They can't link different connections for the same user on different networks. This helps against hackers, and in practice it's even worse. This is one of the reasons that connection migration is actually very badly supported at this point. No single large deployment actually does this yet because it's really quite difficult to do. It's actually asymmetrical. So the client and the server, they use different connection IDs on their legs. So the client uses one connection ID value, and the server uses another for several deployment reasons that I don't really want to go into. But basically you no longer have like three connection IDs mapping to the same connection, you suddenly have six. And in practice, you don't have six, you have 32. All different numbers mapping to the same connection to make deployments easier. For example, they use this to make it easier to do load balancing or indeed also fire walling. This is why these two are split up, but this makes it much more difficult to implement a track to figure out what is going wrong. And so connection migration has some potential benefit if you're changing networks, but it's really not that well supported yet at this point. Sometimes people call this one of the big performance features of HTTP/3 as well. I don't really agree with that as much because to get benefits from this on H/3 level, you would have to switch networks as you are loading webpage, which doesn't take all that long usually. I think this will be much more impactful if you're doing other use cases. Like I said, downloading a large file, doing video conferencing, doing gaming over QUIC, that kind of stuff there is where we'll see the big changes, not so much the HTTP/3 by page loading use case. - At the time of this recording, it's only been three weeks since this was standardized. So it's still early days. But like you said, 25% of the internet approximately is using a lot of this stuff. So you can imagine, I think now that it's standardized, people who write applications for downloading, or like you said, gaming, this is gonna make a lot more sense. And we'll hopefully see a lot of really cool applications coming out. I think the concern at the moment is, as a user, do I need a special browser? Or do I need the latest iPhone? Or what do I need to actually do this? Or does it just happen in the background? - It's interesting you use an iPhone as an example because that's the exception to the rule. The thing is, because QUIC is so encrypted, the idea is we only need to update the client and server. So you do need to have a specific server deployment. If you're using Apache or Nginx or Node.js or something like that. Not all of them already support this. So you need a compatible server, that's one. Most of the browsers support it. You have Chrome, Firefox and Edge have been supporting it for quite some time. Safari, very funny story. They were the first ones to implement it, three years ago, I think. The very first ones to have full HTTP/3 support, but they have kept it behind on an experimental flag. So not enabled by default, you have to enable it manually. And they've now slowly started to enable it by default for some of their users starting iOS 16. But so that means for iPhones, specifically for safari, you do need iOS 16 to be able to use it without manual action. But for all the other browsers, you just need an updated version of the browser and updated here means literally a year old. That's how long it's been enabled already. That's for the browsers. If you want to start using this in your own applications, let's say you have a native app that's more difficult. They would need to download an actual library, software library to do this because none of the operating system kernels already have QUIC support at this point. QUIC and HTTP/3 are just user space level implementations at this point, again, to keep them flexible. Eventually they might move to kernel-level implementations for performance as well. But for now it's all higher level. This means you can easily drop in a library. As long as you have UDP access, you can start using QUIC and H/3. But again, using those libraries is probably gonna be quite complex. - I love the way that you guys use UDP, because like you said, I could use Linux, Mac, whatever, because they just see UDP. You guys can do all kinds of interesting things and make it better in the background without trying to rewrite every operating system out there. - Yep, exactly. - You mentioned Facebook, it's Google. Is it the big companies that are using this and that's why such a large portion of the Internet's already using it, is that correct? - Yeah, I think that's a very good statement. All the big deployments, like the common delivery networks, the CDNs were one of the major pushers and contributors to this. So they have enabled it on mass. Google, obviously all the YouTube, all the Gmail stuff is on there as well. Facebook, we have Microsoft starting to push it now, Amazon is jumping on board. It's basically the bigger companies. And that's one of the, I would say sad things about the modern internet. We are relatively centralized. And this means if just the big companies enable it, we will get to that about 50% mark quite easily, because they just have such a big share of total traffic. - A lot of people will say that's the problem. I think you've said this in other articles. The Internet's so centralized among a few big companies. - Exactly, this is something I want to push back against. Some people have been claiming that this is all a Google thing, right? And it's a conspiracy from Google and Google has been pushing QUIC and H/3 because of their own nefarious purposes, and that's not true. It started at Google, but the original Google QUIC as it's called is oh so different from the current QUIC and HTTP/3, because QUIC and HTTP/3 have been contributed to, like I said, by other companies and not just the big bad ones, like you might say, Facebook or Meta might not be your favorite companies either, but Mozilla, Mozilla has been a major contributor to QUIC and H/3. And I think you can hardly argue that Mozilla is trying to fight your privacy or something. - No, that's a good point. Are there any other cool highlights that you can show us, other things that we perhaps should be aware of? - So there are two other main things that you should be aware of. One of them is called header compression, or as they call it now field compression because they renamed headers to fields. So the idea is that you don't want to send your headers or at least your header values in plain text over the wire because things like cookies, for example, or some of the security headers nowadays are getting quite large and what you want to do, because those values are usually the same in every request and response, you want to compress them. You want to send them once and then reuse a reference to them at the time. This is also an HTTP/2, where it's called HPACK. And so now it's over QUIC, so it's QPACK, even though it's HTTP/3. That's another one of the reasons that we needed H/3 instead of H/2, because QPACK, this header compression stuff is a lot more complex now because we have those independent streams at the QUIC layer now. Again, a bit technical to explain why, but this was actually one of the most difficult things to do to get right for HTTP/3. We might show Wireshark at the end of this. Wireshark doesn't yet do QPACK decoding at this point. So you can't actually do full H/3 introspection with Wireshark yet because it's so complex. And there are very few implementations that do full QPACK. Most of them do a basic version of it. There is a standard version that gives you, let's say 70% compression benefit and the full version that gives you the 100% benefit. But the full version is much more complex. And I think only Google, Facebook and a company called Lightspeed have full implementations for that at this point. But this is something you will see pop up. I hope you never need to implement it because it's crazy difficult. It just means for some tooling, like Wireshark, are still suffering from its complexity. - If I went to Google, you said they're implementing this. If I was using the latest version of Chrome, it might be doing this in the background, right? - It is definitely doing it in the background. So you need to use the basic version. You have to use it, you can't use HTTP/3 without this. If you want extra performance, you need the advanced version and almost no-one is using that at this point. The last feature that was also in HTTP/2, and it is still in HTTP/3 is called server push. The idea from push is illustrated here. You do request for, in this case, the HTML. If you do this on the CDN or a proxy, it sometimes has to forward this request to a different origin server, and that can take a while. So here it takes a long while for the actual GET for the index.html to get finalized by the origin. And so you have some time in between, they call this server think time or server in between time. During that time, why wouldn't you be able to send other stuff back towards the client? And so that was the idea of push. You request your HTML, that will take a while, but you already start sending the CSS and the JavaScript because you know the browser needs this. You kind of fill in the think time with something useful. That was the idea. In practice, it turns out that it's very difficult to know which resources the browser already has cached. And so which you actually need to push, because it could be that the browser already has your CSS and JavaScript, you just don't know it, and you're basically sending useless data over the wire. And there were other problems with push as well. And so push was kind of deprecated. Chrome has actually actively disabled it. It is still in the HTTP/3 spec. Not because it's gonna be used, Chrome will not implement this, they have said. It is mainly there to make sure that HTTP/3 has all the features of HTTP/2, even though they might not be useful for the webpage loading use case. Again, often get this question. No, server push is still not usable. It's only in there for legacy reasons. There is something else you should use. It's called 103 Early Hints, which is a very similar concept, but uses a HTTP-level mechanism to get the same results. So if you're interested in that very recent blog post from Cloudfare and Shopify on this, they're using 103 Early Hints to get this kind of performance benefit. So you should be checking that out instead of trying to use push in 2022. - You mentioned you had Wireshark, is that right? Could you show us some Wireshark stuff? Yeah, that'd be great. - You can use Wireshark to look up what QUIC and HTTP/3 are doing quite well today. I know you had a video with with Chris Greer originally on this, so people should probably check that out for the basics here. But so QUIC is gonna start with an initial packet, which is basically the QUIC version of the SYN in TCP. And then the server is going to send back the replies. And as you can see here, the server is already going to be able to send back some HTTP/3 data. Even without 0-RTT. And what is in there is actually metadata. It's not really as a request or a response. It's not really usable data for the user. This is mostly like control setup. So this is literally what it's called. It's a control stream, and it has a settings frame in there. The settings frame for example, has a lot of QPACK related stuff. So it says how much space can you use for the header compression. How risky do you want the header compression to be in terms of head of line blocking? As we discussed, QUIC removes head of line blocking, but with QPACK, you have a risk of reintroducing it if you're not careful. This parameter is like a way to tune that, how much risk do I want to take? The server sends back this, and then two other things it does is opens the QPACK streams. These will be used to send instructions to set up the header compression stuff. Again, you don't need to know what exactly is happening there, but you do need to understand here. We're already seeing HTTP/3, but it's really just low level metadata that we need to later use it. This is the first round trip that I talked about. Client sends something, server sends something back and then the client is going to start responding. This is the second round trip, and you can already see here the round trip, the HTTP/3. This is where the client is gonna start replying with HTTP/3 level data as well. So here, it basically sends back the same settings frame, but from the client side respective to the server. And then afterwards we're gonna see HTTP/3-level data. This is the actual request that we're gonna send. And this is where we get this problem that I talked about earlier. We can't actually see what's in this headers. - Yeah, I was gonna say, it's all encrypted, isn't it? So you can't really see much. - No, this is another thing. This is decrypted. If I didn't decrypt it, I wouldn't be able to see this. - You'd just see UDP, yeah. - Yeah, I would just see UDP, and maybe QUIC. But we wouldn't know what is in there. This is actually decrypted, but I can't see what is in the headers frame because it is compressed with QPACK. - Oh, I see. - And Wireshark doesn't have QPACK yet. I should also mention this, it's coming. I think we only have to wait for a few more months for it to be worked on. And for apple is actually actively contributing this. But for now you should be aware if you're trying to do this, it's very normal that you can't see what is in the headers. For HTTP/2, for example, you will be able to see, \"Okay, this is the status code. This is the content encoding,\" and so on, all the headers that you know and love. For H/3 we can't do this yet, at least not on Wireshark. The same goes for the reply that we get back. Wireshark doesn't even show us the actual contents of the reply at this point. It will show us other things like the frames that are going on. There are other types of frames. Like for example, here we have a priority frame. It's what we talked about earlier. Those can also be signaled in frames like you see here. You can use Wireshark to look at what HTTP/3 is doing, what QUIC is doing, but not everything yet. And this was a connection setup without 0-RTT. So it waits a while. It takes a full round trip before we see HTTP/3-level data. So let's compare this with one that does use 0-RTT, which is this one. As you can see here, the very first thing the the client sends, this is the very first packet the client sends. It's already 0-RTT and it's identified as HTTP/3. What it looks like on the wire. It's very interesting. It actually has two QUIC packets in it. This is why it says two. So one QUIC packet is what is called typical long header packet, so this is your initial packet. That is what we see before in the previous capture. But then the other QUIC packet, the second one that's in the same UDP datagram is the 0-RTT packet. And this one already carries HTTP/3-level data that is being set up and here, this stream's zero, so these other streams two, six, and 10 are again the control streams and the QPACK streams that use separate streams. But the stream zero here is actually the stream that is carrying the actual request. Again, we can't see what's in the request, but believe me when I tell you this is an HTTP GET for facebook.com. And so it is sent in the very first packet. The first thing the client sends contains QUIC, all the QUIC stuff. In here is also the TLS stuff, that's in the crypto frame. So this is a TLS handshake. The Client Hello for the start of the TLS handshake also includes HTTP/3-level requests and other metadata. All in a single round trip. That is what I was earlier showing with the arrows. That's basically the same thing in Wireshark. You could see that again here. You send these and what you get back from the server. The first round trip from the server sends back five packets apparently here. You can already get HTTP/3-level data back. It's already in there in the first response. And so that is how HTTP/3 can be a lot faster than HTTP/2 in practice. - Suppose from a troubleshooting point of view, a networking point of view, it's a bit of a nightmare because all you see is encryption. It's difficult to troubleshoot stuff unless you get the keys or the certificates, yeah. - Exactly, and that's very important to note. And these are decrypted traces, right? So again, if you want to learn how to use that, David has other videos on his channel that explain that. This is already decrypted. If you are not using decryption, you basically see almost nothing of this. Your Wireshark is just gonna show, \"oh, I don't have the keys for this, this is just random data for me.\" You won't even see, it won't even show here that it's HTTP/3. You will only see that it's QUIC because it doesn't even know that. And that is annoying for you as a user, as a network administrator. It's very difficult to know what it's doing, because if you are, for example, taking packet captures on a load balance or on a firewall or anything else inside of the network, you won't have access to these encryption keys. So it's very difficult to get anything useful out of QUIC and H/3 that way. And that's one of the big challenges we will have. And again, why I think a lot of network administrators won't allow QUIC or H/3 on the networks on mass, because it's so difficult to view what it's actually doing on your network, yeah. - But I suppose it's good to know because let's say you had trouble troubleshooting issues on your network and all you're seeing is encrypted stuff. It's good to know that if we block QUIC, the browsers will, well, I mean who knows what we're gonna break, but hopefully the browsers will go back to using HTTP/2 and then we can actually see stuff. - Yeah, for now the browsers will indeed fall back, but please, please, please, don't take that to mean that you should all be blocking QUIC. - Exactly. - I did not say that. (both laughing) Like I said before, there is very few reasons to be afraid to allow this, even though it uses UDP, QUIC has a lot of security mitigations built in. If you are worried about specific types of attack, read about those first and then decide whether or not to allow it. - Already 25% of the Internet's using this or traffic on the internet. So it's already here, it's not like you can ignore it. It's already here, the big companies are pushing it. - Yeah, that's exactly true. And while for now, you might still have a very simple fallback. I definitely can see bigger companies like Google or Facebook starting to disable HTTP/2 over TCP over time to try and force people to switch to that. We're definitely not there yet, not enough people supported, but I can definitely see that happening in four to five years, let's say. - Robin, I wanna thank you so much for sharing. You've shared so much knowledge with us. Thank you so much for simplifying it and coming down to our level. Really appreciate you doing this. - Yeah, no, thank you so much for having it. Like I said during the talk, this is so complex. And if people just have to start from the complex documents that are out there, it's gonna be very difficult for people to get anywhere near what they need to be actually able to use it. And that's why I've been trying to do this kind of video. And my own blog post is to get people at least to a basic level of understanding that they can then bootstrap themselves to start using it a bit more. So thank you for giving me this opportunity to share this with your viewers as well. - I appreciate it, and where can people find you? Are you on Twitter? Is that a good place? - I'm mostly on Twitter. My handle is @programmingart, and I will also be starting a new blog soon. You've mentioned my blog a couple of times. It's not really my blog, I have many different blog posts and many different spaces. I'm gonna start my own blog soon. - No, that'd be great. - Kind of consolidate all of that, yeah. - Yeah, I mean the articles that you've written are amazing. For this interview, I read some of the ones that you recommend and it's great, 'cause you explain it. I think it's great that you've done it in video format like now trying to keep it simple and then people can go and read your articles, which I'll link below. And then if they've got questions, can they shout at you on Twitter, is that right? - Oh yeah, absolutely. Please do, please do. I love interacting with people on Twitter about this and seeing other people from the QUIC and HTTP/3 join in and they often give a lot of good answers as well. So if you have any questions, please, please, please, reach out, we are more than happy to help. - That's brilliant. So Twitter's the best place. Are there any other places that you'd recommend? - I'm also on LinkedIn of course. And if you really have some very specific stuff, you can also reach me on my email, which you can also easily find online. - Brilliant. Robin, thanks so much. - All right, David, thanks, and see you all later. (upbeat music)",
    "transcript_keywords": [
        "QUIC",
        "HTTP",
        "TCP",
        "UDP",
        "connection",
        "QUIC packet",
        "TCP HTTP",
        "QUIC packet header",
        "packet",
        "TCP connection",
        "QUIC and HTTP",
        "TCP fast",
        "QUIC SYN SYNACK",
        "run HTTP",
        "CSS",
        "yeah",
        "lot",
        "TCP fast open",
        "big",
        "TLS"
    ],
    "transcript_entity_values": [
        "Microsoft",
        "three",
        "TLS",
        "a decade",
        "SSH",
        "32",
        "Akamai",
        "quite a few years",
        "PhD",
        "299",
        "two",
        "four",
        "749",
        "the 50%",
        "TCP",
        "second",
        "YouTube",
        "Edge",
        "four to five years",
        "Google",
        "103",
        "2018",
        "the year",
        "2015",
        "80%",
        "CloudFlare",
        "Lightspeed",
        "David Bombal",
        "three weeks",
        "months",
        "Facebook",
        "Google Search",
        "the years",
        "4",
        "more than one",
        "Wireshark",
        "QPACK",
        "SYN",
        "early days",
        "200 to 300 milliseconds",
        "today",
        "three weeks ago",
        "Nginx",
        "Safari",
        "Robin",
        "Mozilla",
        "one",
        "over five years",
        "HTML",
        "TCP",
        "about one fourth",
        "70%",
        "first",
        "about 10 years",
        "9,114",
        "300",
        "the next 550",
        "Amazon",
        "years",
        "Twitter",
        "iPhones",
        "IETF",
        "iPhone",
        "David",
        "Meta",
        "2022",
        "IP",
        "449",
        "25%",
        "LinkedIn",
        "Gmail",
        "2012",
        "several megabits",
        "Linux, Mac",
        "16",
        "80 to 90%",
        "10",
        "six",
        "26-30%",
        "50%",
        "third",
        "Chrome",
        "about 50%",
        "five",
        "a few more months",
        "One",
        "one byte",
        "Wireshark",
        "a few months",
        "Cloudfare",
        "zero",
        "the '80s",
        "Apache",
        "three years ago",
        "CSS",
        "100%",
        "CDN",
        "the coming years",
        "JavaScript",
        "HTTPS",
        "450",
        "a year old",
        "almost a decade",
        "0",
        "Node.js",
        "iOS 16",
        "Twitter",
        "Wireshark",
        "fourth",
        "Firefox",
        "Chris Greer",
        "QUIC",
        "UDP"
    ],
    "transcript_entity_types": [
        "ORG",
        "CARDINAL",
        "ORG",
        "DATE",
        "ORG",
        "CARDINAL",
        "ORG",
        "DATE",
        "WORK_OF_ART",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "PERCENT",
        "NORP",
        "ORDINAL",
        "ORG",
        "ORG",
        "DATE",
        "ORG",
        "CARDINAL",
        "DATE",
        "DATE",
        "DATE",
        "PERCENT",
        "ORG",
        "ORG",
        "PERSON",
        "DATE",
        "DATE",
        "ORG",
        "ORG",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "PERSON",
        "ORG",
        "ORG",
        "DATE",
        "QUANTITY",
        "DATE",
        "DATE",
        "ORG",
        "ORG",
        "PERSON",
        "ORG",
        "CARDINAL",
        "DATE",
        "ORG",
        "ORG",
        "CARDINAL",
        "PERCENT",
        "ORDINAL",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "DATE",
        "ORG",
        "DATE",
        "PERSON",
        "ORG",
        "PRODUCT",
        "ORG",
        "PERSON",
        "ORG",
        "DATE",
        "ORG",
        "CARDINAL",
        "PERCENT",
        "PERSON",
        "ORG",
        "DATE",
        "QUANTITY",
        "ORG",
        "CARDINAL",
        "PERCENT",
        "CARDINAL",
        "CARDINAL",
        "PERCENT",
        "PERCENT",
        "ORDINAL",
        "ORG",
        "PERCENT",
        "CARDINAL",
        "DATE",
        "CARDINAL",
        "QUANTITY",
        "PRODUCT",
        "DATE",
        "ORG",
        "CARDINAL",
        "DATE",
        "PRODUCT",
        "DATE",
        "ORG",
        "PERCENT",
        "ORG",
        "DATE",
        "PRODUCT",
        "ORG",
        "CARDINAL",
        "DATE",
        "DATE",
        "CARDINAL",
        "EVENT",
        "PRODUCT",
        "ORG",
        "ORG",
        "ORDINAL",
        "ORG",
        "PERSON",
        "ORG",
        "ORG"
    ]
}