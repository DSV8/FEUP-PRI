{
    "id": "4ZWjPZiU5vE",
    "title": "The problem with under-display cameras",
    "channel": "The Verge",
    "channel_id": "UCddiUEpeqJcYeBxX1IVBKvQ",
    "subscriber_count": 3390000,
    "upload_date": "2021-11-15T15:00:05Z",
    "video_url": "https://www.youtube.com/watch?v=4ZWjPZiU5vE",
    "category": "Science & Technology",
    "tags": [
        "under-display camera",
        "smartphone camera",
        "camera",
        "image quality",
        "under display",
        "smartphone",
        "galaxy z fold 3",
        "samsung galaxy",
        "foldable",
        "zte axon 20",
        "zte axon 30",
        "xiaomi mix 4",
        "xiaomi",
        "zte",
        "how it works",
        "tech",
        "technology",
        "gadgets",
        "photography",
        "selfie",
        "phone",
        "under display camera",
        "under screen camera",
        "screen",
        "resolution",
        "verge",
        "the verge"
    ],
    "views": 208096,
    "likes": 5818,
    "comments_count": 444,
    "description": "More and more phone manufacturers are turning to under-display cameras as a way to eliminate bezels or notches. But these cameras, still in their infancy, come with their own drawbacks. Mainly theyre not very good. But as the technology improves, do under-display cameras have what it takes to become the new standard? We spoke with Steven Bathiche, the head of Microsofts Applied Sciences group, to get a better understanding of the technology, its shortcomings, and whether under-display cameras have a place in the future of phone technology or are better off in other industries entirely.     Read more:   Subscribe: Like The Verge on Facebook: Follow on Twitter: Follow on Instagram:  The Vergecast Podcast: Decoder with Nilay Patel: More about our podcasts:  Read More: Community guidelines: Wallpapers from The Verge:  Subscribe to Verge Science on YouTube, a new home base for our explorations into the future of science:",
    "description_links": [
        "https://www.theverge.com/e/22540312",
        "http://goo.gl/G5RXGs",
        "https://goo.gl/2P1aGc",
        "https://goo.gl/XTWX61",
        "https://goo.gl/7ZeLvX",
        "https://pod.link/430333725",
        "http://apple.co/3v29nDc",
        "https://www.theverge.com/podcasts",
        "http://www.theverge.com",
        "http://bit.ly/2D0hlAv",
        "https://bit.ly/2xQXYJr",
        "http://bit.ly/2FqJZMl"
    ],
    "transcript": "- For years now, phone manufacturers have been attempting to eliminate or at least minimize bezels around the screen. They've tried hole punch cutouts or even little pop-up cameras to help maximize screen real estate. But a new solution that's gaining popularity is under display cameras, which are completely hidden from view. With them, you could have a perfect seamless screen with nothing breaking up your screen's image, or at least that's the dream. That dream is finally becoming a reality with three recently released phones using this technology. The Samsung Galaxy Z Fold3, the Xiaomi Mix 4, and ZTE's Axon 30. Question is, is the trade-off for a notchless phone worth the worse quality of the front facing camera? The idea itself isn't actually all that new. Companies like Microsoft have been researching under display cameras for a long time. But until now it hasn't shown up in consumer products like phones. Now, having a screen without a notch or a hole punch is wonderful, but mainly the area covering the camera was even more distracting than having a notch, and the camera quality was, to put it mildly, pretty awful. But hiding a camera under a phone screen is no easy feat. Steven Bathiche from Microsoft's Applied Sciences Team walked us through the technology. - It's kinda like looking through a screen door, so like if you're looking through a screen door and you have a camera through the screen door you can see through it, you know, but as a display gets higher and higher resolution, you got to think of that screen door becomes more dense and it becomes really hard to see through and you start losing a lot of light. And not only that, you not only lose a lot of light, you get these things that actually affect where the light goes, like diffraction. So we can put a camera behind a really big display because it's got big pixels, which really means it's got a lot of room that isn't a pixel, but when you get really small displays, like you see today in the market, the pixels are really dense. You're talking about like 400 DPI in a lot of cases. So what do you do then, right, like that's a really tough screen door to take an image through. - The first generation of under display cameras in phones solve this problem by reducing the pixel density in the area covering the camera. This led to less lens obstruction, and therefore let more light through to the sensor. But the image quality is still paled in comparison to traditional selfie cameras. Not to mention it was very clear where the camera was housed with a distracting low resolution patch. Newer generation phones are able to maintain a higher pixel density of around 400 PPI right over their cameras by utilizing a newer wiring technology that allows slightly more light to enter the lens. But even this cut down on nearly 80% of the light that would otherwise be hitting the lens, which still doesn't give great results, especially in low light. - So there's always a balance, there's a trade off. You know, you take a camera that potentially might be struggling in a dark environment and you just make it all that harder for them. You know, where do you solve the problem? You do your best on the optics side, and eventually I think the optics will be able to help and the display technology will be able to help them get maybe only a 40% of the light through rather than 20, but you're still losing like 60%. And then the rest you have to rely on computation. - To make up for these optical shortcomings manufacturers across the board have to use software to compensate for the challenges that still exist with their hardware. - So using AI and neural networks to do things that cameras in phones do today really well, which is take, you know, snapshots in the dark, and they use AI to try to recover as much of the detail that was there. And also at the same time, correct for any artifacts or aberrations caused by that screen door effect. It's a kind of a twofold problem. You gotta solve it in optics and you gotta solve it using computation in the end of the day. But in both ways, you're making it hard on the camera to do a great job in capturing a great image. - So the two phones I have here are two devices with more recent generation of this under display camera technology. This is the Xiaomi Mix 4, and this is the ZTE Axon 30. They both have kind of about 400 PPI area covering the screen, integrated into the OLED panel. And as you can see, it's pretty difficult to make out, especially with the naked eye, the previous phones that used under display cameras, they had a kind of rough, low pixel density area that honestly, I thought it looked worse than a notch, it was really distracting. But here, especially on this Mix 4, which is really nice looking phone, I think it looks great. You can barely see the camera under the screen unless you're looking really, really closely kind of at an angle or on a white background, but generally you can't really see this camera. The problems, of course are when you open the cameras themselves, and yeah, it's pretty clear just from looking at the live view feed that these cameras are working with some pretty serious hardware limitations, like the image is kind of hazy and blown out. And it does improve a little bit after you take the picture. So if I pop it and it, you know, it's still kind of processing, but after it processes the sharpness and the exposure is improved a little bit, but it's still, you know, it's not the best selfie camera around. for some people who don't care too much about the quality of their selfies or their zoom calls, maybe it is worth it. But if you do care about image quality with your selfies or if you want to take them in low light, you'll find that the technology really isn't ready yet, at least not for phones. Even experts like Steven don't know if the trade-off is worth it. - Customers would look at that and see maybe like immediate benefit in that there's no notch, but front cameras are also doing many other things, like biometric authentication and Windows Hello, and so you have to fit more things in there and it's up in the air whether you can actually do biometrics behind a screen like that. And so, you know, are you really solving a problem? I'm not sure yet. So I think it's going to be challenging. I also think that sometimes people like to see where the camera is, and so again, I'm not really sure whether it is. The benefit for the customer is obviously you have no notch and you potentially have thin bezels at the top and the bottom. That might have some benefit from maybe an aesthetic point of view, but it's really hard to say, I would say in anything like this, there's basically pros and cons and you just have to think through it, and it depends on the product you're trying to build and the experience you're trying to deliver. - Stephen's team at Microsoft has focused their efforts with under display cameras on larger video conferencing devices. They aren't set on solving the cosmetic issue of trying to eliminate bezels or notches, but are tackling a very real world problem, helping maintain eye contact over video calls. - You know, I was really intent in trying to solve the problem for telepresence. And we've been working in this area for at least 15 years where we wanted to help bring people together over video conferencing and make it feel like it's real. And one of the problems you want to solve there is to make the window basically like a real window, like I'm talking through you through an actual window rather than a computer screen, which is very two dimensional, doesn't take into account where you're looking, where your position is like a real window does, and also I wanted to do and solve for the cues that were really important in person to person communication, like eye contact. We have a number of different research threads around trying to solve the problem, both optically and computationally. And of course, you know, one of the nice applications is putting cameras underneath the display for the purposes of putting the camera where it needs to be to help with eye contact, right? Because if you have the camera where you're looking at, you are making eye contact, and also to hide the camera from the bezel. - Now it's important to note that Stephen mentioned the tech is only made possible with plastic OLED screens, which explains why you're seeing it in phones first. Most work machines like laptops, use LCDs, so it'll still be a minute before under display cameras start to appear in shipping devices. But Microsoft's efforts do show that there are uses for the idea beyond just shrinking phone bezels. Right now it's more of a neat curiosity than anything else, and I definitely don't think you should buy a phone based on this feature alone. These things tend to get better with time though, so who knows, maybe cameras under the screen will soon be as common as fingerprint sensors. - Okay, I have to speak from my personal point of view, rather than from a Microsoft product making point of view, My personal point of view, I don't mind the bezels. I think that the bezel is a great place to put technology and I don't want, you know, me personally, I would like the best front camera possible.",
    "transcript_keywords": [
        "camera",
        "cameras",
        "display cameras",
        "screen",
        "screen door",
        "display",
        "phones",
        "light",
        "solve",
        "phone",
        "problem",
        "Microsoft",
        "kind",
        "technology",
        "display camera technology",
        "door",
        "image",
        "view",
        "Xiaomi Mix",
        "bezels"
    ],
    "transcript_entity_values": [
        "about 400",
        "Steven",
        "one",
        "rather than 20",
        "30",
        "only a 40%",
        "at least 15 years",
        "twofold",
        "three",
        "60%",
        "The Samsung Galaxy",
        "AI",
        "today",
        "Axon 30",
        "the end of the day",
        "nearly 80%",
        "years",
        "Steven Bathiche",
        "Stephen",
        "about like 400",
        "two",
        "Windows Hello",
        "OLED",
        "ZTE",
        "around 400",
        "Microsoft",
        "first",
        "Applied Sciences Team"
    ],
    "transcript_entity_types": [
        "CARDINAL",
        "PERSON",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "PERCENT",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "PERCENT",
        "ORG",
        "ORG",
        "DATE",
        "LAW",
        "DATE",
        "PERCENT",
        "DATE",
        "PERSON",
        "PERSON",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "ORG",
        "ORG",
        "CARDINAL",
        "ORG",
        "ORDINAL",
        "ORG"
    ]
}