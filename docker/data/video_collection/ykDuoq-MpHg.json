{
    "id": "ykDuoq-MpHg",
    "title": "GPU Tier List - Nvidia Edition!",
    "channel": "Linus Tech Tips",
    "channel_id": "UCXuqSBlHAE6Xw-yeJA0Tunw",
    "subscriber_count": 15900000,
    "upload_date": "2023-02-15T18:02:04Z",
    "video_url": "https://www.youtube.com/watch?v=ykDuoq-MpHg",
    "category": "Science & Technology",
    "tags": [
        "Nvidia",
        "GPU",
        "Nvidia GPUs",
        "GPU generation",
        "best GPU",
        "worst GPU",
        "best Nvidia",
        "worst Nvidia",
        "GPU retrospective",
        "GPU history",
        "GPU tiers",
        "GPU tier list",
        "Nvidia tier list",
        "GeForce ranked",
        "Nvidia ranked",
        "GeForce cards",
        "best and worst GPU"
    ],
    "views": 4095796,
    "likes": 111580,
    "comments_count": 6833,
    "description": "Buy a Samsung Tab S8 Ultra Tablet:  Purchases made through some store links may provide some compensation to Linus Media Group.  Save 10% and Free Worldwide Shipping at Ridge by using offer code LINUS at   Its no surprise that Nvidias latest RTX 40 series GPUs are also the fastest. But how does this generation as a whole compare to its long list of predecessors? Were going back over 10 years to rank every NVIDIA GPU generation! How does your card fare?  Discuss on the forum:   Make your own tier list here:   Buy a GIGABYTE Eagle GeForce RTX 3050 Eagle OC:  Buy a ASUS Dual GeForce RTX 3060 OC Edition:  Buy a ZOTAC GeForce RTX 4070 TI Trinity OC:  Buy a MSI GeForce RTX 4080 Ventus 3X OC:  Buy a PNY GeForce RTX 4090:  Purchases made through some store links may provide some compensation to Linus Media Group.   GET MERCH:   LTX 2023 TICKETS AVAILABLE NOW:   GET EXCLUSIVE CONTENT ON FLOATPLANE:   AFFILIATES, SPONSORS & REFERRALS:   OUR WAN PODCAST GEAR:   FOLLOW US  ---------------------------------------------------   Twitter:  Facebook:  Instagram:  TikTok:  Twitch:   MUSIC CREDIT --------------------------------------------------- Intro: Laszlo - Supernova Video Link:  iTunes Download Link:  Artist Link:   Outro: Approaching Nirvana - Sugar High Video Link:  Listen on Spotify:  Artist Link:   Intro animation by MBarek Abdelwassaa  Monitor And Keyboard by vadimmihalkevich / CC BY 4.0   Mechanical RGB Keyboard by BigBrotherECE / CC BY 4.0  Mouse Gamer free Model By Oscar Creativo / CC BY 4.0   CHAPTERS --------------------------------------------------- 0:00 Intro 1:09 FX 5000 3:18 GeForce 6000 4:20 GeForce 7000 6:18 GeForce 8000 8:21 GeForce 9000 9:20 GeForce 100 9:50 GTX 200 11:12 GTX 300 11:35 GTX 400 13:20 GTX 500 14:16 GTX 600 16:17 GTX 700 18:05 GTX 800 18:28 GTX 900 20:50 GTX 10 22:40 RTX 20/ GTX 16 24:24 RTX 30 26:18 RTX 40 28:32 Get at me!",
    "description_links": [
        "https://lmg.gg/XS4uc",
        "https://www.ridge.com/LINUS",
        "https://linustechtips.com/topic/1488418-the-best-gpus-nvidia-ever-made%E2%80%A6-and-the-worst/",
        "https://tiermaker.com/create/nvidia-geforce-gpu-generations--15555726",
        "https://geni.us/w2ZQ",
        "https://geni.us/PGpBi",
        "https://geni.us/nvlny",
        "https://geni.us/D4ZkXxf",
        "https://geni.us/Z25C",
        "https://lttstore.com",
        "https://lmg.gg/ltx23",
        "https://lmg.gg/lttfloatplane",
        "https://lmg.gg/sponsors",
        "https://lmg.gg/podcastgear",
        "https://twitter.com/linustech",
        "http://www.facebook.com/LinusTech",
        "https://www.instagram.com/linustech",
        "https://www.tiktok.com/@linustech",
        "https://www.twitch.tv/linustech",
        "https://www.youtube.com/watch?v=PKfxmFU3lWY",
        "https://itunes.apple.com/us/album/supernova/id936805712",
        "https://soundcloud.com/laszlomusic",
        "https://www.youtube.com/watch?v=ngsGBSCDwcI",
        "http://spoti.fi/UxWkUw",
        "http://www.youtube.com/approachingnirvana",
        "https://www.instagram.com/mbarek_abdel/",
        "https://geni.us/PgGWp",
        "https://geni.us/mj6pHk4",
        "https://geni.us/Ps3XfE"
    ],
    "transcript": "- Ooh, really fast card. Hey! Ow, that price though. Turning back the clock on Nvidia's biggest GPU releases, we find plenty of wins, but also some Ls so big that Nvidia's own marketing team openly mocked them, which got us thinking, tier lists are easy views, right? Sorry, excuse me. Which got us thinking, with the benefit of hindsight, what were Nvidia's best and worst generations? Have you been a savvy shopper, or did you throw your money at the wrong horses? Like you're about to throw your money at our sponsor. - The Ridge. Are you tired of your old, bulky wallet? The Ridge Wallet will keep your pockets light and organized. Follow the link below and use code LINUS to save 10% off your purchase and get free shipping. - If our only consideration was performance, this would be a pretty simple exercise: best, worst, rest. But there's a lot more to delighting gamers than frames per second. So as we make our way through 17 generations of Nvidia hardware, we're gonna be looking at the bigger picture, with particular attention to efficiency, new features, notable controversies, and of course price. Let me set the stage for our first generation. It was 2003. Cargo pants were everywhere. I cracked open a copy of The Computer Paper and was shocked to discover that anyone would be deranged enough to spend 500 US dollars on a card that does nothing but make games run better. Oh, how naive I was. The good news is I kind of dodged a bullet there. (gun cracks) To say that Nvidia's first DirectX 9 GPUs were controversial would be a gross understatement. Depending on the gamer benchmark, performance gains compared to the previous generation were up to 55%, but could be as low as just 10%. And that uplift came at the cost of noise. And the pain kept coming. Nvidia marketed the FX Series' cinematic rendering capabilities as CineFX. And image quality was indeed a big discussion point for this generation, just for all the wrong reasons. Not anticipating that new games would use the baseline 24-bit color precision mode of DirectX 9 rather than 32-bit, FX cards ended up falling back to the 16-bit mode to increase frame rates. The result was a noticeable degradation of image quality. Worse still, Nvidia attempted to slip this little trick into driver version 43.45 without acknowledging it, until the obviously lower image quality forced them to come clean. Additionally, the implementation of MSAA on these cards was distinctly inferior to ATI's, leading to more pronounced stair stepping on the edges of angle geometry. To top it off, ATI's 9700 PRO not only performed better, but came out earlier and was the same price as the FX 5800 Ultra. The FX line of GPUs ended up being about as damaging to Nvidia's brand as later FX CPUs were to AMD's. Clearly a cursed naming scheme. D tier. The good news is that after a less embarrassing, mid-generation 5900 Series refresh of the FX lineup in 2004, C tier, Nvidia would follow up with a real banger. The performance gains of the GeForce 6th generation were outstanding. The mid-range 6600 GT outperformed the previous flagship for less than half the price, and if you went from flagship to flagship, you could double your performance or more. That's right, it was in 2004 that SLI made its triumphant return from the dead. Early adopters had gotten a taste of this dual GPU wizardry under the 3DFX name back in 1998. But it would take Nvidia four years after acquiring their rivals to reintroduce this technology to a much larger gaming audience. The competition with ATI though was tight in this generation. Flagship cards were neck and neck in both price and performance, with ATI's CrossFire offering similar dual GPU capabilities, though Team Red's solution was flakier and required a special master card, along with a silly external dongle. Furthermore, the best board partners were definitely available on the Nvidia side, with many offering lifetime warranties. This has gotta be S tier. Moving on, as we saw with FX, the GeForce 7 family got multiple flagship GPU launches. First came the 7800 GTX, built on the same 110-nanometer manufacturing process as its predecessor, but with a larger die, higher clock speeds, and graphics-optimized GDDR memory, contributing to a healthy 60% uplift in performance, even if it did come at a higher price. But then we got the 512-meg version with vastly higher clock speeds and performance and a super misleading name. Then we got the 7900 GTX that cranked clock speeds to 11, thanks to a more advanced 90-nanometer manufacturing process, but then barely managed to outperform the 7800 GTX. No, no, not that 7800. That one. Oh, and then the 7900 was at a lower price. Do we have an M tier for mixed bag? You know what though? Nvidia clearly won every mid-generational battle with ATI this time around. This was the last generation to be available for both PCIe and AGP slot motherboards, and it was full of fun oddities, like the sample that we have from this generation: The 7950 GX2 that frankensteined two SLI GPUs together into a single PCIe slot. Oh yeah, and the 7900 GTO. That's right, Nvidia used to bless us with limited-run cards as a way of clearing out old or not quite peak performance inventory. And in this case, many GTO cards could actually be unlocked to full GTX specifications. It was also the last time we saw a flagship GPU offered in a single-slot form factor. And fun fact, the 7800 GTX was used as the starting point for the PlayStation 3's RSX GPU. I'm going with A tier this time around. And as for you, 7900, hmm, you get a B. GeForce 8 was, in a word, revolutionary. S tier. I'm doing it right now. But we've gotta talk about it a bit more before we move on. First up, a single 8800 GTX was able to outperform a pair of 7900 GTXs running in SLI. It is still the single biggest generational leap in performance we have ever seen, and it cost only $100 more than a single 7900 GTX, leaving the ATI 2900 XT absolutely in the dust crying to its mama. Its new mama, AMD, who is probably feeling like entering the ring with Nvidia, might not have been a very good idea. The Tesla architecture's big innovation was doing away with the fixed pixel pipelines of previous microarchitectures. So instead of separate vertex and pixel shaders, we got unified shaders, meaning that any one of them was able to handle any type of shading task. This flexibility was extremely important as GPUs made the transition from graphics accelerators to the general-purpose accelerators that power workloads like simulation and machine learning today. Also key to that transition was the release of the CUDA API, which is still in use today and enables developers to run general-purpose code on GPUs. Less in use today, but certainly interesting was the introduction of three-way SLI for enthusiasts with more dollars than sense and plenty of patience for tinkering. And if all that wasn't enough, this generation also welcomed Nvidia's first GPU using TSMC'S 65-nanometer process. The 8800 GT was less than half the price of its big brother GTX, but offered anywhere from 70 to 90% of the performance, depending on the application. And this was in a single-slot form factor. It was such a clear winner in terms of value that Nvidia has never offered anything similar since. Now, I already declared GeForce 8 to be S tier, but it's worth saying it again. S tier. Which is how you'll feel and look in our underwear from lttstore.com. Take it from me. I would know. After a wild previous generation, GeForce 9 was a bit of a rest on the old laurels time for Nvidia. We went straight from the largest generational performance jump to the smallest one. The G92 core that was at the heart of the 9800 GTX, I mean, it was no slouch. It handily dispatched the ATI HD 3870, but it was based on the same Tesla architecture and, in fact, based on the same die as the 8800 GT, just shrunk for a smaller 55-nanometer process node, which was good for a healthy clock speed bump, but only about a 10% performance increase versus last gen. Unless, of course, you sprang for the dual GPU 9800 GX2 sandwich edition. I guess we also got PCIe Gen 2.0 support across the entire range, but it would be a while before cards, and it wouldn't be these ones, managed to saturate that connection. I'm going with C tier. What was next? (air whooshes) Right, nothing. All five cards from the GeForce 100 generation, yes, it existed, were OEM only. We've seen recent examples of GPUs that were sold exclusively to system integrators. The GTX 1060 5 gig is one that comes to mind. But an entire generation, Nvidia? The good news is we didn't miss out on anything because every 100 Series card was rebadged from either the previous or the following generation. You get a big, fat D tier. But ooh, this is new. Nvidia's Tesla architecture is back again with the 200 Series, but the GTX goes before the numbers now. Ooh. In all seriousness though, the flagship GTX 280 and its mid-gen, refreshed 285 used what Nvidia called their second-generation Tesla architecture on TSMC'S 65- and 55-nanometer process nodes, respectively. And they were hefty mamas, topping over 1 billion transistors for the first time ever. This was also the first and only time that we saw Nvidia use a whopping 512-bit memory bus, granting gamers a very respectable 60-ish percent performance bump. And while the ATI HD 4870 managed to take the frames per dollar crown, Nvidia's top tier was in a different league altogether and still hovering around that $500 flagship price point. SLI had also matured significantly by this point, allowing gamers to drive high-resolution, 2,560-by-1,600 displays. And it was even beneficial for lower resolutions, with scaling that could reach 70 to 80%. That means that two mid-range cards was a great value option compared to a single high-end one. I personally went that route with two GTX 260s. I'm going A tier. As for the GTX 300 Series. (crickets chirping) This again? Another generation of five cards that was OEM only? Thrilling. Except that no, it's actually worse than last time, because they were all rebadged from the previous generation. Let's say F tier for forgettable. This next one wasn't. The first DirectX-11-capable generation arrived five months later than planned, but with over 50% performance gains relative to the GTX 280, and it managed to edge out ATI's HD 5870. So clearly all those CUDA cores were worth waiting for. GPUs still used thousands of these computing cores for everything from rendering scenery, to drawing character models, to calculating lighting and shadows in a game environment. And all this performance came cheap. Okay, not cheap, but at an even $500, the GTX 480 was priced identically to the flagship FX GPU from seven years prior, making it $120 cheaper in today dollars if you account for inflation. Oh yeah. And it also cost 150 then dollars less than the GTX 280 that it replaced. It wasn't all rainbows and sparkles though. It was also a blazing inferno. The GTX furnace barbecue card and Fermi jokes were so common that even AMD joined in on the mockery. In terms of tech though, we got two big new arrivals. First, thanks to Nvidia's acquisition of AGEIA, who up until this point had made, I think, PowerPoint presentations and promises. No, sorry, a weird, standalone PhysX card. Well, yeah, that technology runs on the GPU now. And second was support for tessellation, a technique used to add detail to surfaces that might otherwise be rendered flat. Unfortunately, it was still early days for tessellation, and it incurred a 20% hit to frames per second, making it one of those features that doesn't really run so much as walk on first-generation hardware. (coughs) RTX. Excuse me, sorry. We're gonna go B tier here. The GTX 500 Series though was a solid tick in that it focused heavily on improving rather than revolutionizing Nvidia's existing Fermi chip microarchitecture. This is a strategy they borrowed from Intel that resulted in lower temperatures, noise, and power consumption, and also less mockery. Performance gains in the 20% range were a little on the low end, but Nvidia did widen the gap compared to AMD's best, and pricing stayed the same at 500 bucks for the top-end, single-GPU card. Notably, GeForce 500 saw the reintroduction of the Ti moniker, which hadn't been used since 2002. We're still not sure how to pronounce it. GTX 560 Ti, T-I. But we are sure that at the time, cards with this designation represented incredible performance for the price. Fun fact, if you've ever had the misfortune, by the way, of buying a fake GPU from a site like Wish or AliExpress, you probably got a card from this generation with a modified BIOS. I'm gonna go A tier. Now, one of the most notable things about our next generation, GTX 600, is that Nvidia's Kepler architecture was the first time they tried to pass off a mid-tier GPU as a flagship. See, here's the thing. The GTX 680 uses a GK104 chip, but the flagship die of each generation almost always ends in a zero. And then the higher that last number goes, the smaller the die and the lower end the part. What that means is, whether it was for cost concerns or an utter lack of competition from AMD, the GTX 680 that we got was a lesser version of what it could have been. But if you were expecting it to come with a discount, think again. To be fair, overall performance was up 20%, and it was an enormous leap in performance per watt thanks to a risky strategy of dramatically shrinking the process node and significantly altering the architecture in one generation. And this is the point where Nvidia's strategy of differentiating based on features starts to really make its mark. With the 600 Series, then, we got some basics, like support for PCI Express Gen 3.0 and DisplayPort 1.2, but we also got GPU Boost, NVENC hardware-accelerated video encoding, G-SYNC, less demanding FXAA and TXAA anti-aliasing, and support for the Vulkan API. And that's not all. A personal favorite of mine was the introduction of GameStream. RIP. Nvidia's end-to-end solution for streaming games from your GeForce-powered PC to a SHIELD handheld device. So cool. It wasn't all roses though. Driver issues that caused stuttering with adaptive VSync were widely reported, and, confusingly, the total number of SKUs ballooned from 15 to 27. And that's without factoring in the super clocks and super, super clocks of the world. Making matters worse, AMD, sayonara ATI branding, took its first performance crown in some time with the HD 7970. I think we can go B tier, but I also think I'm being kind of generous here. GTX 700, on the other hand, can be best summarized as more Kepler. Due to the slowdown of Moore's law, Nvidia was stuck with the same 28-nanometer manufacturing process and Kepler architecture, but this time bigger. Much bigger. That GK110 chip that was exclusive to enterprise compute cards last time around finally made its first appearance for consumers in the form of the GTX Titan. And boy was that thing ever interesting. Depending on who you asked at the time, Nvidia would tell you that Titan was intended for gamers or for professionals, or for somewhere in between. And it did have two key advantages over GeForce GPUs. Namely, it had a whopping six gigabytes of high-speed GDDR5 memory and eight times better double-precision floating-point performance. But then in subsequent iterations of these Titan cards, those advantages would ultimately disappear, and in retrospect, I think the Titan project was simply a way for Nvidia to test gamers' tolerance for much higher prices. \"$1,000 for a GPU,\" we said. Oh, young Linus, you ain't seen nothing yet. Anywho, the definitely for gamers, real flagships for this generation were the GTX 780, which managed a 25% increase over last gen for 150 more dollars, and the 780 Ti, which came only six months later and managed a similar performance jump for only a marginal increase in price. Meanwhile, AMD's code name Hawaii cards were hot and loud, with the bigger issue being that they were plagued by driver issues and wouldn't really catch up in terms of performance for a couple more years. 7 Series then comes away with the score the 6 Series should have gotten: A tier. As for GTX 800 Series, once again, it did exist, but instead of more Kepler, the theme was less Kepler in your laptop. D tier. Now, there were plans actually for a desktop line of 800 Series cards, apparently, but they were intended to be based on Nvidia's new Maxwell architecture, which would instead make its debut as the GTX 900 Series. Maxwell is notable for a number of reasons. It was the second time that Nvidia passed a mid-tier GPU off as a flagship. It was the third desktop generation that was stuck on TSMC'S 28-nanometer process. Moore's law was looking well and truly dead at this time. And it was the last time that we would see a new generation launch on a close enough to yearly cycle. Impressively though, Maxwell offered a 30% performance increase for, wait, less? Yes, the 980 was a $550 card at launch, $100 less than the 780. On top of that, it was AMD's turn to phone it in with a rebrand of their 290X to 390X, leaving Nvidia essentially alone at the top of the performance charts. It was also so efficient that for the first time ever, Nvidia used the same desktop GPU dies in 900 Series laptops. They had some interesting ideas for how to use their performance leadership. One was Dynamic Super Resolution, which was possible to do before, but simplified and allowed you to render your game at a higher than native resolution, then downsample it for a smoother appearance. Another was to push gaming on high-resolution monitors and TVs. Less demanding MFAA, or multi-frame anti-aliasing, and HDMI 2.0 made 4K 60-hertz gaming a major marketing point for Nvidia. But with that said, even the properly high-end 980 Ti that came as a 750 mid-cycle refresh struggled to deliver a playable 4K experience in AAA games. I mean, to be clear, these were fast cards and shockingly efficient considering that the transistors were the same size as Kepler, but Nvidia set our expectations maybe a little bit too high. Notable too from this generation was the introduction of VXGI, even if Voxel Global Illumination would ultimately give way to path-traced RTX lighting, which we'll get to later. And finally, it's impossible to talk about this generation without bringing up the 3.5-gig GTX 970 debacle, for which Nvidia eventually had to settle a class-action lawsuit. The cards did have four gigs of RAM as advertised, it's just that only 7/8 of it was actually accessible at full speed. Whoops. Yeah, you know what? It's still A tier in my book. Though maybe not as A tier as the GTX 10 Series. We finally got a new manufacturing node, guys. Let's go! TSMC'S 16-nanometer process meant a healthy bump in, well, everything. At launch, gamers could pick up a top-tier can, sort of, they did that thing again where they withheld the biggest die for a Ti refresh, with a very respectable 60% increase in performance for 600 bucks, while drawing less power and producing less heat. 10 Series also gave us our first taste of GPU Boost 3.0, which could best be described as self-overclocking, allowing the GPU to scale its clock speed well beyond base clock depending on available power and thermal headroom. For their part, AMD's flagship RX 480 was the value king at the time, but thanks to Nvidia's investments in GPU encoding and the explosion of online game streaming, it was well overshadowed by the mid-range GTX 1060. Which one you ask? Ah, good question. In another example of Nvidia using extremely misleading product names, the three-gig and six-gig version of the 1060 have performance differences that go way beyond their frame buffer size. For shame. Three- and four-way SLI were dropped, as was SLI altogether on mid-range cards, but Nvidia did introduce a high-bandwidth bridge as a bit of a swan song to two-way SLI. Speaking of bandwidth, the new DisplayPort 1.4 standard also continued the trend of catering towards high resolution, high refresh rate, and shiny new high dynamic range monitors. 4K 120 hertz HDR, anyone? I mean, not at that time, but it was so close we could smell it. I think I'm gonna go S here. It's just too bad that in hindsight, it turns out that what I smelled was the wet fart that was around the next corner. Alongside the confusingly named RTX 20/GTX 16 Series came ray tracing. I don't know if I can remember the last time gamers paid so much for so few frames in return. Remember that really cool marble demo that Nvidia put together to show off the capabilities of these new cards? Yeah, that ran at 25 frames per second at 720p. And with these capabilities came a $100 price hike. That's right, $700 for a, yes, they did it again, mid-tier GPU die at launch, with the proper big Ti one coming later. After the huge leap forward last generation, Nvidia's performance gains and traditional gains cooled to a more tepid 30-ish percent. But I mean, hey, alongside our ray tracing RT Cores, we got Tensor Cores for cool, machine-learning-accelerated features, like background noise removal and Deep Learning Super Sampling, which kind of sucked at launch, but is like freaking amazing now. It's kind of wild seeing what a long game Nvidia plays sometimes. Ray tracing is still making its way into the mainstream gaming space, but they were so sure it was the future of immersive, realistic in-game lighting that they went as far as to change their whole gaming brand. It's too bad the RTX 20 Series never ended up being capable of powering full-fledged ray-traced games. Newer demos like RTX Racer and the new RTX \"Portal\" look amazing, but they only really run on newer cards. And RTX Remix looks set to rewrite the history books for people who skipped the RTX 20 Series. Sorry, buddy, you're gonna have to be C tier. Is what I would say about the RTX 30 Series in hindsight, but man, at launch this generation was lit. Gamers were so hyped to get their hands on these cards that our announcement coverage was the most viewed GPU announcement video we have ever done. The comments were so full of hope. More than double the total transistors and CUDA cores at the top end. The 3070 was outperforming the 2080 Ti at less than half the price. What? Too bad it was not to be. After the initial availability issues dampened our enthusiasm, the subsequent crypto mining boom completely dissolved it. Secondary sellers- - [Production Member] They're called (beep) scalpers. - Drove those coveted $500 RTX 3070s, and every other card this generation, to prices beyond double their MSRP, and there they stayed. I mean, on the plus side, AMD returned to competitive form and was able to offer similar performance at lower prices, unless it came to real-time ray-traced lighting. And then, I mean, they too were shipping cards by the boatload to crypto farms, so boo AMD as well. SLI also officially bade us farewell at this stop in our journey, but we got to say hello to PCIe Gen 4.0, a stop-gap 12-pin power connector, and support for Direct Storage, which allows your GPU and your SSD to talk directly, basically eliminating loading times, assuming any games ever show up with support for it. As for our tier assignment, I feel like we need to kind of split this one up. For anyone who got one of these legitimately ray-tracing-capable cards for MSRP, 30 Series is an easy A. No, you know what? S tier. S tier. It delivered on the promises of last gen, but did it at attractive prices. For everyone else though, I think a C is pretty generous. Oh, bringing us to the present day. Technically, Nvidia's 40 Series offerings aren't all out yet, but based on what we've seen so far, we can make some pretty safe guesses. In the coming months, we'll probably see some unlaunches. Just kidding, that was weird. Probably won't happen again. More likely, we'll see some yes launches, fleshing out the lineup with presumably RTX 4060 and 4050s of some sort. And we also wouldn't be surprised to see some kind of new halo card launch farther down the road, similar to how the 3090 Ti arrived a year and a half after its non-Ti brother. We're gonna have the ones that are out linked down below. Similar to last generation, we saw a pretty nice 40% increase in performance. It's just that unlike last gen, prices didn't stay the same. They didn't even increase a little. They increased to a degree that I don't think we've ever seen before. Like, really Nvidia? From $700, the previous two generations, to 1,200? I think you guys got hooked on that pandemic Kool-Aid and haven't figured out that outside of the really wacky buyers, who have always existed, buying Titan Zs and the like, gamers are not gonna spend that kind of money to play video games. Hence the shelves full of 4080s and 4070 Tis. For their part, AMD has retained a strong value proposition, but hasn't been able to match the insanity of the RTX 4090. And we got to meet a new power connector again. The 12-volt, high-power connector has been a hot topic of conversation. It theoretically offers some cool benefits, like allowing the GPU and power supply to communicate their power requirements and capabilities to each other, but with all the melted connectors and adapters that got memed all over the internet, it's been a bit of a PR nightmare for Nvidia, who hit back saying that user error was the problem with pretty much everything that happened, which may actually be true. Please do make sure you plug things in all the way. In summary, if we're going by the kilogram, 40 Series offers a fine value. But we aren't. So B tier at best. And I'm generously baking in some future price drops once Nvidia regains their senses. All that remains then now is for you to come at me, bro. Seriously, we couldn't get into the nitty gritty of performance or talk about every new feature for all these generations. So let me know on our forum or in the comments down below if you agree or disagree with our reasoning. What's your tier list? And how does this video rank for you? I'm gonna give it an S for segue way to our sponsor. - Samsung. With a 14.8-inch, AMOLED, 120-hertz display, the Galaxy Tab S8 Ultra is optimized for both productivity and entertainment. The four AKG-tuned speakers provide loud, but balanced sound, making your viewing and listening experiences all the more enjoyable. Taking notes for school? The included S Pen, as well as the superb 11,000-milliamp-hour battery will keep you productive throughout your classes. The S Pen allows for features like taking photos, playing, pausing, and skipping songs, or changing slides on a presentation, all without having to even touch your tablet. Check out the Galaxy Tab 8 Ultra at the link below. - If you guys enjoyed this video, you'll also probably like the full review we did of the RTX 4070 Ti. That is, unless you bought one, in which case you might not enjoy that review that much.",
    "transcript_keywords": [
        "Nvidia",
        "GTX",
        "GPU",
        "Series",
        "performance",
        "generation",
        "tier",
        "cards",
        "Nvidia biggest GPU",
        "time",
        "RTX",
        "GPUs",
        "AMD",
        "Nvidia performance gains",
        "ATI",
        "card",
        "price",
        "Nvidia Kepler architecture",
        "Nvidia top tier",
        "SLI"
    ],
    "transcript_entity_values": [
        "40",
        "110-nanometer",
        "260s",
        "mid-gen",
        "3070",
        "one",
        "20",
        "150 then dollars",
        "100",
        "1,200",
        "The Computer Paper",
        "the 7900 GTX",
        "SSD",
        "GTX 700",
        "70 to 80%",
        "9",
        "eight",
        "only $100",
        "One",
        "1060",
        "the coming months",
        "Deep Learning Super Sampling",
        "zero",
        "800",
        "30-ish percent",
        "10%",
        "500 US dollars",
        "GPU",
        "the Galaxy Tab 8 Ultra",
        "7900",
        "seven years prior",
        "RTX Remix",
        "11",
        "120",
        "2002",
        "Titan",
        "16-nanometer",
        "GDDR5",
        "AMD",
        "GTX",
        "thousands",
        "700",
        "four years",
        "RT Cores",
        "three",
        "MFAA",
        "pandemic Kool-Aid",
        "7",
        "the CUDA API",
        "SLI",
        "1998",
        "FXAA",
        "60%",
        "six gigabytes",
        "2080 Ti",
        "1 billion",
        "Linus",
        "Dynamic Super Resolution",
        "the present day",
        "NVENC",
        "24",
        "DirectX 9",
        "750",
        "512",
        "Tensor Cores",
        "GT",
        "LINUS",
        "65-nanometer",
        "280",
        "14.8-inch",
        "first",
        "Direct Storage",
        "just 10%",
        "up to 55%",
        "8800",
        "GTX 280",
        "GT",
        "120",
        "the 6 Series",
        "GPU Boost",
        "2003",
        "First",
        "32",
        "2,560",
        "GTX 970",
        "PowerPoint",
        "Ls",
        "285",
        "AliExpress",
        "MSRP",
        "25",
        "GDDR",
        "ATI 2900 XT",
        "70 to 90%",
        "Hawaii",
        "AGEIA",
        "3DFX",
        "Titan",
        "4",
        "Fermi",
        "Kepler",
        "GPU Boost 3.0",
        "90-nanometer",
        "4060",
        "6600",
        "six",
        "550",
        "third",
        "50%",
        "GeForce 9",
        "TSMC",
        "7800",
        "60",
        "7900",
        "Intel",
        "Samsung",
        "12-volt",
        "SHIELD",
        "4050s",
        "2004",
        "Gen 2.0",
        "DisplayPort",
        "early days",
        "9700",
        "GeForce",
        "four",
        "Ridge",
        "500 bucks",
        "PCIe Gen 4.0",
        "GTX 560 Ti",
        "less than half",
        "the FX Series'",
        "G92",
        "780",
        "MSRP",
        "The Ridge Wallet",
        "600 bucks",
        "16",
        "AGP",
        "five",
        "VXGI",
        "PCI Express Gen 3.0",
        "1.2",
        "27",
        "10",
        "9800",
        "RX 480",
        "GameStream",
        "30",
        "RSX",
        "ATI",
        "GTO",
        "20%",
        "15",
        "25%",
        "Maxwell",
        "12",
        "five months later",
        "mid-generation 5900 Series",
        "Voxel Global Illumination",
        "4080s",
        "Team Red's",
        "two",
        "only six months later",
        "Series",
        "VSync",
        "43.45",
        "PlayStation 3's",
        "second",
        "the Galaxy Tab S8 Ultra",
        "150 more dollars",
        "11,000-milliamp-hour",
        "600",
        "17",
        "390X",
        "28-nanometer",
        "3.5",
        "GeForce 7",
        "980",
        "a couple more years",
        "290X",
        "1.4",
        "S Pen",
        "HDMI 2.0",
        "today",
        "GK110",
        "AKG",
        "7900 GTX",
        "Moore",
        "30%",
        "4090",
        "CUDA",
        "PhysX",
        "Ray",
        "Titan Zs",
        "RAM",
        "Tesla",
        "FX",
        "Kepler",
        "200",
        "1,000",
        "only 7/8",
        "GTX",
        "500",
        "Nvidia",
        "55-nanometer",
        "GK104",
        "100",
        "CrossFire",
        "780",
        "a year and a half",
        "The S Pen",
        "6th"
    ],
    "transcript_entity_types": [
        "CARDINAL",
        "QUANTITY",
        "CARDINAL",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "MONEY",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "ORG",
        "ORG",
        "PERCENT",
        "CARDINAL",
        "CARDINAL",
        "MONEY",
        "CARDINAL",
        "CARDINAL",
        "DATE",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "TIME",
        "PERCENT",
        "MONEY",
        "ORG",
        "ORG",
        "CARDINAL",
        "DATE",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "DATE",
        "FAC",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "PERSON",
        "CARDINAL",
        "MONEY",
        "DATE",
        "PRODUCT",
        "CARDINAL",
        "ORG",
        "PERSON",
        "CARDINAL",
        "ORG",
        "ORG",
        "DATE",
        "WORK_OF_ART",
        "PERCENT",
        "QUANTITY",
        "DATE",
        "CARDINAL",
        "PERSON",
        "ORG",
        "DATE",
        "ORG",
        "CARDINAL",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "PERSON",
        "CARDINAL",
        "CARDINAL",
        "QUANTITY",
        "ORDINAL",
        "ORG",
        "PERCENT",
        "PERCENT",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "MONEY",
        "EVENT",
        "ORG",
        "DATE",
        "ORDINAL",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "ORG",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "CARDINAL",
        "ORG",
        "ORG",
        "PERCENT",
        "GPE",
        "ORG",
        "ORG",
        "PRODUCT",
        "CARDINAL",
        "ORG",
        "ORG",
        "ORG",
        "QUANTITY",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "MONEY",
        "ORDINAL",
        "PERCENT",
        "PRODUCT",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "ORG",
        "DATE",
        "ORG",
        "CARDINAL",
        "DATE",
        "PRODUCT",
        "ORG",
        "DATE",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "PERSON",
        "MONEY",
        "PRODUCT",
        "ORG",
        "CARDINAL",
        "EVENT",
        "ORG",
        "CARDINAL",
        "ORG",
        "PERSON",
        "MONEY",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "ORG",
        "ORG",
        "PRODUCT",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "ORG",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "ORG",
        "PERCENT",
        "CARDINAL",
        "PERCENT",
        "ORG",
        "CARDINAL",
        "DATE",
        "DATE",
        "PRODUCT",
        "DATE",
        "ORG",
        "CARDINAL",
        "DATE",
        "EVENT",
        "ORG",
        "CARDINAL",
        "PRODUCT",
        "ORDINAL",
        "ORG",
        "MONEY",
        "QUANTITY",
        "CARDINAL",
        "CARDINAL",
        "CARDINAL",
        "QUANTITY",
        "CARDINAL",
        "PRODUCT",
        "CARDINAL",
        "DATE",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "DATE",
        "WORK_OF_ART",
        "ORG",
        "PRODUCT",
        "ORG",
        "PERCENT",
        "CARDINAL",
        "ORG",
        "ORG",
        "PERSON",
        "PRODUCT",
        "ORG",
        "ORG",
        "ORG",
        "PERSON",
        "CARDINAL",
        "MONEY",
        "CARDINAL",
        "ORG",
        "MONEY",
        "ORG",
        "QUANTITY",
        "ORG",
        "MONEY",
        "PRODUCT",
        "PRODUCT",
        "DATE",
        "WORK_OF_ART",
        "ORDINAL"
    ]
}