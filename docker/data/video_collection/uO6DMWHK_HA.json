{
    "id": "uO6DMWHK_HA",
    "title": "Mark Rober! I Built You a Computer! - Double NAS Build",
    "channel": "Linus Tech Tips",
    "channel_id": "UCXuqSBlHAE6Xw-yeJA0Tunw",
    "subscriber_count": 15900000,
    "upload_date": "2023-07-15T17:16:54Z",
    "video_url": "https://www.youtube.com/watch?v=uO6DMWHK_HA",
    "category": "Science & Technology",
    "tags": [
        "building a pc for mark rober",
        "mark rober i built you this pc",
        "mark rober has too much money",
        "mark rober nas build",
        "240tb nas for mark rober"
    ],
    "views": 4078793,
    "likes": 120814,
    "comments_count": 3311,
    "description": "Purchase Cablemods 12 Volt HPWR Basic cables at:    Mark Rober's team needed to fix their growing storage problem and they knew exactly who to call. Today we build two 240TB NAS' for Mark, and demo them remotely syncing across the globe!  Discuss on the forum:   Buy a Ubiquiti UniFi EnterpriseXG 24 10 Gig Network Switch:  Buy a Seagate Exos 20TB HDD:  Buy an AMD EPYC 7302P CPU:  Buy an AMD EPYC 7302P CPU on eBay:  Buy an ASrock Rack ROMED8-2T/BCM Motherboard:  Buy a Supermicro Motherboard on eBay:  Buy Micron 3200MT/s CL22 DDR4 32GB RAM:  Buy a Sabrent 1TB NVMe M.2 SSD:  Buy a Noctua NH-U14S TR4-SP3 CPU Cooler:  Buy a Fractal Design Define 7 XL E-ATX Computer Case:  Buy a Seasonic PRIME Platinum 1300W PSU:  Buy a Micron 5400 PRO SSD:   Purchases made through some store links may provide some compensation to Linus Media Group.   GET MERCH:   LTX 2023 TICKETS AVAILABLE NOW:   GET EXCLUSIVE CONTENT ON FLOATPLANE:   SPONSORS, AFFILIATES, AND PARTNERS:   EQUIPMENT WE USE TO FILM LTT:   OUR WAN PODCAST GEAR:   FOLLOW US  ---------------------------------------------------  Twitter:  Facebook:  Instagram:  TikTok:  Twitch:   MUSIC CREDIT --------------------------------------------------- Intro: Laszlo - Supernova Video Link:  iTunes Download Link:  Artist Link:   Outro: Approaching Nirvana - Sugar High Video Link:  Listen on Spotify:  Artist Link:   Intro animation by MBarek Abdelwassaa  Monitor And Keyboard by vadimmihalkevich / CC BY 4.0  Mechanical RGB Keyboard by BigBrotherECE / CC BY 4.0  Mouse Gamer free Model By Oscar Creativo / CC BY 4.0   CHAPTERS --------------------------------------------------- 0:00 Intro",
    "description_links": [
        "https://store.cablemod.com/cablemod-basics-12vhpwr-cables/",
        "https://www.amazon.com/gp/product/B0C5RVPTTD",
        "https://linustechtips.com/topic/1519668-i-built-this-computer-for-mark-rober/",
        "https://store.ui.com/us/en/collections/unifi-switching-enterprise-10-gbps-ethernet",
        "https://geni.us/AS0en85",
        "https://geni.us/xzUkBCk",
        "https://ebay.us/yfmFxS",
        "https://geni.us/fOOYW",
        "https://ebay.us/VVoXo2",
        "https://geni.us/AOlqUq",
        "https://geni.us/A1zInMb",
        "https://geni.us/QXAjAHc",
        "https://geni.us/kX9JVFf",
        "https://geni.us/AfN9edZ",
        "https://geni.us/AHHmTG",
        "https://lttstore.com",
        "https://lmg.gg/ltx23",
        "https://lmg.gg/lttfloatplane",
        "https://lmg.gg/partners",
        "https://lmg.gg/LTTEquipment",
        "https://lmg.gg/wanset",
        "https://twitter.com/linustech",
        "http://www.facebook.com/LinusTech",
        "https://www.instagram.com/linustech",
        "https://www.tiktok.com/@linustech",
        "https://www.twitch.tv/linustech",
        "https://www.youtube.com/watch?v=PKfxmFU3lWY",
        "https://itunes.apple.com/us/album/supernova/id936805712",
        "https://soundcloud.com/laszlomusic",
        "https://www.youtube.com/watch?v=ngsGBSCDwcI",
        "http://spoti.fi/UxWkUw",
        "http://www.youtube.com/approachingnirvana",
        "https://www.instagram.com/mbarek_abdel/",
        "https://geni.us/PgGWp",
        "https://geni.us/mj6pHk4",
        "https://geni.us/Ps3XfE"
    ],
    "transcript": "Everyone knows Mark Rober. He has dashing good looks, helped design a Mars Rover, single-handedly solved the porch pirating pandemic, and even has more subscribers than me. But it turns out he can make mistakes, like the way that his team is handling storage. We're talking towers of external hard drives, no real backup, and worst of all, editing videos off of Dropbox. Thankfully, he knew where to come for help. That's right, boys and girls. Today, we are building not one, but two identical storage servers for the one, the only Mark Rober. And not only that, but we're gonna show you guys how with basically zero networking configuration, no port forwarding, any of that stuff, these two epic machines are gonna be able to remotely and securely sync to each other from miles away. Just like I'm gonna remotely sync this message from today's sponsor. CableMod, worry no more about your graphics card going pyromaniac. Upgrade your default power cable to CableMod's 12-volt high power basic replacement cable. Learn more at the end of the video. When Mark first reached out, he had already come up with actually a pretty reasonable plan to solve their issues. To migrate off of the stacks of external hard drives, they had spec'd out an OWC Thunder Bay Flex 8, which is a DAS, or direct-attached storage chassis, that as the name implies, directly connects to the computer using a 40 gigabit Thunderbolt connection. Then for remote backup, they chose a smaller DAS box from that same company. These kinds of storage docs are great for the solo photographer or freelance video editor, where only that one person needs to access the data. To their credit, their current workflow only actually requires that one computer to be able to access the raw footage in order to generate low-quality proxy footage for their remote editors. Once the project is complete, that computer with the raw footage directly attached to it would run the final export for YouTube. However, just because that works for them today doesn't mean it's going to work for them in the future. And given the flexibility and the upgradeability that's afforded by a DIY NAS, or a network-attached storage box, like being able to access the footage on any computer on your network, or, I mean, heck, any computer in the world through a VPN, well, when you're spending this kind of money and you operate on a scale larger than one person, NAS is a no-brainer. Not to mention that whatever machine you end up plugging these storage boxes into is gonna be bogged down every time it has to sync to that offsite backup. So what do we build him? Well, the capacity is easy to figure out. He needs lots. He asked for 200 terabytes at each site. But what about the form factor or the hardware platform? Originally, we specced out two options, one based on AMD's enterprise Epic platform and one with their consumer-grade Ryzen parts. But it was immediately apparent that the cost was gonna be basically the same, so Epic was the obvious choice. This is gonna be a really fun build because while Mark obviously wants to take a spare no expense approach to keeping his data safe, we also don't wanna waste his money, meaning that this is a really solutions-oriented video and we tried to keep it really practical. So back when we specced this out, the Epic 7302P, a 16-core processor, was available on eBay for around $380 a piece. Now, the 16 cores might not be the fastest on the market, but they're frankly overkill for a hard drive-based storage workload like this. And considering the platform advantages, like tons of PCIe lanes and registered ECC memory, it's basically the perfect option. And it's gotten even more perfect. If you check eBay today, you can pick these things up for just $150 used or with a used Supermicro motherboard for less than $500. Now, some of you are probably freaking out right now, like, seriously, Linus, you're putting a used CPU in a system for Mark Rober? That's fair. That thought did occur to us. But if you pay attention to how used CPUs drop in price, when each new generation comes out, they go kachunk, kachunk, and there's a reason for that. It's because CPUs are damn near indestructible compared to, say, a motherboard or a GPU. So what happens is you've got this glut of CPUs on the market with no boards to put them in. You say indestructible code. Can we cut to that clip of him destroying that $10,000 Xeon? Yes, very funny. Except that's also a great way to prove my point because that $10,000 CPU that I ruined four years ago can now be found on the used market for as little as $1,000. Or if you're willing to accept a qualification sample, full performance one, as little as 350 bucks. I mean, for these kinds of prices, Mark could literally have four spare chips sitting on hand with needing only a screwdriver to swap them out for the price of one brand new one. Coming back to our motherboard, unlike a lot of other data center platforms, the Epic SP3 socket was used on three generations of chips, Naples, Rome, and Milan. That means that there's still a metric boatload of boards that are available, both new and on the used market. But since motherboards aren't anywhere near as reliable as CPUs, we ordered a brand new pair of ASRock Rack's Rome D8-2T. I love these boards. We've got several of them in the office that have been rock solid and they have an absolutely comical amount of IO. There's an IPMI port for remote management, dual onboard 10 gig networking, meaning we don't even need a separate network card, although we'd have plenty of places to put them, with seven PCIe Gen 4 by 16 slots, dual M.2, dual Oculink, which is another PCIe by four each, eight SATA ports through these onboard mini SAS HD connectors, and eight channel memory, all mounted to a standard ATX form factor PCB. This thing, it's better than the bee's knees. It's the shit. And for a bee, that's honey, right? I think. It'll fit in basically any case and it shows off the monstrous 128 PCIe lanes of our Epic CPU quite nicely. Next up is RAM, apparently. One moment, please. Since we're using Epic, Micron sent over four 32 gigabyte DDR4 registered ECC modules that are running at 3,200 mega transfers per second. RAM, honestly speaking, is also another place that you can save some money if you're doing this at home. It's just that when we were looking, the price cap wasn't huge for this specific capacity and speed between brand new and used. We're talking a difference of about $20 a stick. Now the experienced among you may be raising your eyebrows a little bit at our RAM configuration. On the one hand, we've got 128 gigs in a NAS, but on the other hand, we've kind of cheaped out. By using only four sticks on an eight channel platform, we're giving up half of our total potential memory bandwidth. But believe it or not, there's a pretty good reason for both of those things. One is that, okay, say you're using a QNAP small business NAS or something like that. You're not gonna use much RAM, but we are using TrueNAS scale. And since it uses ZFS, it uses system memory as a read cache for our most frequently accessed files. This is called ARC or adaptive replacement cache. And the rough guideline is to have one gigabyte of ARC per terabyte of magnetic storage. So we are right in that sweet spot with 128 gigs. As for why we only opted for a four channel configuration, well, if we were using NVMe storage, we might need the additional speed, but because we're using hard drives, I don't think our memory bandwidth is gonna be an issue. And this gives Mark plenty of room to upgrade in the future. All he has to do is double his memory and he could throw twice as many hard drives into his system. Of course, given Mark's budget, that is to say he didn't really provide one, we just tried to be sensible, we could have easily put in twice as much memory today or four times or eight times as much. And when we're talking about a very read intensive application like video editing, there would have been a clear benefit to that. But there are other ways to skin this cat. ZFS has another trick up its sleeve called L2 or level two ARC, which is a second tier of read caching that can be set up using commodity SSDs. And that's exactly what we're gonna do with this one terabyte Sabrent Gen 4 NVMe SSD. Now it's worth mentioning that you can go ludicrous overkill on level two ARC and put like 10 terabytes in a system like this, but that would actually use up some of your RAM based ARC capacity to index it, which could actually end up hurting your performance. Also, the level two ARC is filled up by stuff that gets evicted from the main ARC cache. So it might not even help until your system has actually been powered on for quite a while. The last thing to go on our board is our CPU cooler. And we've gone with a Noctua U14S TR4SP3. We want this machine to be reliable in the longterm. So using an AIO liquid cooler was out of the question. We also want it to be quiet since one of them is going to live at Mark's house and the other is gonna be within earshot of people's desks at their office. This one happens to meet both of our requirements. Just like I am required to tell you about the LTT screwdriver that is reliable and soon to be available in, that's right, a Noctua color scheme. Sign up for a notification on lttstore.com. Wait, are these even the same? They're not? Oh, these are like big chunky ones. We're trying to put two fans on it. That way in the unlikely event that one of them fails, the machine will still operate completely normally. It's not to get extra cooling. This is not a particularly hot running chip. This one has one of the big chunky ones on it. What, you left one of them on there? No, there are five big chunky ones. The four that I have and the one that's hot here. Holy fuck. Okay, let me go steal one more from another fan. Are you fucking kidding me? What the fuck? Are you just screwing with me at this point? I'm not. Like legitimately? No, legitimately, I'm not screwing with you. So you're telling me one of these came out of the box with the wrong one on there. There's no way. No, you must have messed it up. No, they must have gotten mixed up. No, the one that was still missing one was the one you brought me. Wait, I have three fans. Oh my God. Oh, this was the one I borrowed it from. That's the closer color match. Is it? Yeah. I don't think so, I think you're wrong. What? Yeah, that's really close. No, no, no, that's wrong. This is the closer one. No way. Oh, the brown is the way. No way, it's not even close. Why the hell? Was this one outside or something? No, they just are all over the place. Remember when I said that this thing is gonna live at Mark's house? Obviously, he doesn't have a server rack at his house. I mean, what kind of crazy person would have a server rack in their house? Especially a pink one. That means that building this into a rack mount chassis isn't necessarily the best option this time around. Typically, for a high capacity storage machine like this, you want a rack mount since regular tower cases just don't have enough drive bays anymore. But if you're a long time watcher, you might remember one that does. Ah, yes, the Fractal Define R7 XL is back, which with its optional drive bays can house 18 hard drives, which is plenty for the 12 we're putting in today and for them to add another six down the road. Of course, by default, since most people are not gonna put a ton of hard drives in here, it only holds four three and a half inch drives. But we've converted it just by moving this plate right here from the back up to the front into what Fractal calls storage layout. It's been a little while since I've done this, but basically you've got this slide and this nubbin and those hook in on the other side there, okay? And then you got a screw that goes in here. There you go, and it gets supported by this little tab. So, I mean, it's not amazing, but what are your other options for cases that carry hold this many hard drives? These are not sticking into the nubbin thing. Every mounting mechanism is great to do once. Now, I'm not gonna do it because we're gonna pull all these drives out for shipping anyway, but Mark, or someone from Mark's team more realistically, once it arrives, I would also, wow, that's heavy. Okay, like you to put the second screw into each drive right here. That's just gonna snug this up, make sure that this little nubbin stays in place and ensure that these drives don't just suddenly go, fall or anything like that. That would be bad. One thing we are putting the work into though is putting all of these silicone grommets on the hard drive trays. This gives them a nice little anti-vibrational cloud to sit on. And while you're not gonna kill a hard drive by moving it around, we had hard drives and laptops for literal decades, it's pretty well documented that any excess vibration is pretty bad for them. The other benefit is this keeps the drives, which have moving parts in them of course, from transferring their vibrational noise to the case and causing it to rattle. Which again, is a concern for the system because it will be near where people are working or living. It's like a storage brick in the front of the case. Good Lord. Oh, oh yeah. Storage brick. It's a good brick right there. Of course. What good is a brick without a brain? Let's go ahead and put our IO shield in. Your face is a brain. Because the year is 1998. Got them. I'm just trying not to slice my hand open. Thing of beauty right there. I don't know what it is, but compared to whatever the flavor du jour, RGB fiesta thing that's going on in the gaming spaces, workstations, server class stuff, just has that classic high performance look, you know? Black PCB, I sleep. Green PCB, real. Hey, hey, hey, what do you call the cold season when I'm making this video? The winter of my disc content. We got ourselves a computer here. Sort of. We got to talk about cooling. Oh, this is getting very heavy. Hopefully, yes. Oh, easy. Time to put some fans in the front. Just use the stock ones. Stock ones? Yeah, we'll use the Noctuas for the top. What? Where would I like to put my fan for it to have all of its airflow blocked by this wall of hard drives? I could put it here, or here, or here. There's not gonna be a GPU in this system. Ooh, at least not now. Well, no, he could put a GPU in it in the future if he wanted to pass through a GPU to a Plex VM or something like that. I thought you said he wasn't doing VMs. No, he's not gonna do any of that, but I am going to put the fans in such a place that they would deliver fresh airflow to a GPU or accelerator card or any other kind of thing you might want to put in here. I'm modifying the HBM, putting some cooling on here. This is a little big. That's a little small. This is fine. This is fine? Yeah, just put that in there. You're so cute. Realistically, a card like this, which we haven't actually talked about yet, but we need because our motherboard only supports eight SATA hard drives out of the box. 10, oh, well, whatever. That's still not 16 or 18 or whatever this can support. The point is we need to add some more SATA ports. This is an HBA host bus adapter, and it's kind of designed to get passive airflow from the server fans that are way over here somewhere. Right now it's got nothing. So we need to add something to this. And I mean, that's better than nothing. To be fair, it'll probably be fine. We're just doing it just in case. I think it's time for us to talk power supply. We could have gone with something redundant. In fact, there are some really cool ATX dual unit power supplies these days, but it's not quiet. So we've opted for the second best thing, this excellent Seasonic Prime Platinum 1300 watt power supply. Did we need 1300 watts? The answer is no. But the 1300 watt has native support for 16 SATA power connectors. And while we could have adapted something else or even used splitters, particularly for SATA, using splitters is not recommended because of the tiny little pins. If you drop too much current over them, they melt. And that's bad. This is a machine that's intended to be operated continuously for years on end. I mean, we don't know how long he's gonna keep it. Nothing would stop him from running this for like, I don't know, 10 years, as long as he replaces hard drives as they fail. So we don't wanna take any chances. I didn't have four of the same size zip ties. So there's two different size zip ties, but it's mint, okay? I mean, it's not going anywhere. No, it's not. You might be wondering how this HBA is gonna plug into our hard drives because that doesn't look anything like the port on a hard drive. So we have to use these mini SAS HD, that's the connector on the HBA, to four SATA connectors. And then we can plug directly in, no problem. Like Linus mentioned before, the motherboard actually has two of these mini SAS HD connectors, which means eight of our 12 hard drives are already covered. So this HBA is only gonna be used on one port. Now you can buy ones that are cheaper with less ports. This is a 16i, and they make an 8i, and I think some other companies might even make a 4i, which would be just one connector. It's just that we wanted to set it up for future expansion. Even in the situation where he went well beyond the capacity of this case and switched to like a rack mount chassis, this HBA is still gonna work, and he has enough ports for another 12 drives on here. You just slide it on in. There's no graphics card because it's a server, so we can put this right in the top slot like that. It's pretty cute, right? Aside from like an hour of cable management, the last thing this system needs is boot drives. We're gonna be using a pair of Micron's 5400 Pro series drives. These are like data center grade SATA SSDs. They're honestly overkill and probably more expensive than I would have spent on boot drives, but Micron sent them for the project, so not a big deal. And these are gonna last gosh dang pretty much forever. TrueNAS like doesn't really write a whole lot to the boot drives. You know, you're talking like the configuration and some, you know, some statistics and like logs and stuff, so you could probably run it on a USB if you had to. I wouldn't recommend that, but you could. So these are super, super overkill. Hey, look, it's working. Okay, let's see if all of our drives, ooh. These are just because these are new drives. Okay, we got one, two, three, four, five, six, seven, eight, nine, 10, 11, 12. Beautiful. Where are our boot drives? There are some weird stipulations on this board. Despite it having a bajillion IO, some of them are shared. I think slot two, which is either the second from the bottom or the second from the top, is shared with like the M.2, these ports, the Oculink ports, so depending on, there's like a little jumper you can move around, some of the things get disabled. I suspect that that's what the problem is right now, so I just gotta check the motherboard manual and see. We can see from this jumper chart that SATA four underscore seven, so four to seven does get disabled in some circumstances, and four to seven is the bottom one, which is what our boot drives are plugged into. So I was right, we're good. We just need to move this jumper. The Xs mean that it's disabled. We have two M.2 slots, so we don't have to worry about our M.2 because this M.2 slot is always on. Actually, the only thing we need to worry about is the SATA and probably that PCIe slot. So I think I'm gonna put it in this configuration because that means we get eight X on the PCIe slot. That other M.2 is gonna work and our SATA work. I don't think Mark is ever gonna wanna use Oculink for anything, and I would suspect if anything they might wanna use that PCIe slot. Maybe they won't use it. I don't know, I'm just gonna put it in that config and don't call me. This guy is already in the correct position. We just need to move the right-hand one over one pin. And now our boot drive should work. The system's booted up and we've got TrueNAS scale installed. Now we can set up our array. Because this is, you know, it's mission critical data. They don't wanna lose this stuff. This is already gonna have an offsite backup. We're gonna set it up in a pretty safe configuration, but one that is still gonna be very performant. In our experience with Zetafest, usually the best option to get good sequential and random performance, sequential being big video clips and whatnot, and random kind of being small text files, or if you have lots of photos, you're copying all those at once, is to use a VDEV size of six, which works great with our 12 drives. However, because they're hard drives, we do need to have some sort of protection for that array. They are at some point going to fail. It's a for sure thing. So we're gonna use two of those six drives as parity data. That means in each of those pools of six, we can lose two drives before our data is at jeopardy, which means we're gonna lose a little bit of capacity. I think that brings us from 240 terabytes, because these are 20 terabyte drives, down to 160 or something like that. It's a pretty substantial loss, but it's not as substantial as losing everything because you didn't have enough parity drives. So it's very important to set up your array in a safe configuration like this. So let's just do that. We'll pick six drives. One, two, three, four, five, six. I suspect TrueNAS is actually gonna automatically do this. Yeah, look at that RAID-Z2. It picked for us. This is what you're doing. You don't have a choice. And then we'll just hit repeat, because we can make an additional one. That's gonna give us a formatted capacity of about 150 terabytes. Also, before we're done here, we're gonna add our level two arc. You can see there's a cache type of VDEV, so we'll just add that, select our one terabyte NVMe drive, and plop it on there. There are a few more steps we still have to do. I wanna set up email alerts, so if a drive were to die, they actually know. It doesn't tell you. It just goes, hey, my drive's dead. You have to get an email for that. We're also gonna have to set up a data set, some user accounts, so they can actually read the data off of it. We're gonna have to set up the software for our remote sync, which is called Tailscale, and then set up the sync process. But we're gonna do all that when we're on the phone with Mark. Also, we said we were gonna build two of these today. That was fake news. We already built the first one. It was probably like six, nine, might even been a year ago that we built this thing, and shipped it to Mark's team, because we don't actually need both of them to build on camera. This way, we actually get to do the sync remotely. It's already with them all the way in Los Angeles. We're up here in Vancouver, so this'll be an even better demo. We're thousands of miles away. There are a few things we need to finalize before we actually ship the machine, but we've got it working enough now that we're ready to hear from its new owner and do a live demonstration where we blow Mark's mind with an automatic scheduled backup across this unassuming black wire over hundreds of miles. We're recording good audio for you over here. What up? Oh, hi, Mark. Oh, hi, Mark. Oh, hi, Mark. God damn it. So how's the NAS treating you? Yeah, the NAS is amazing. And then I also love the idea too, because we're gonna do a second one that's like at another location, so then we're like, really? Really, I have no idea what you're talking about. You don't say. Is that it? No way. Thank you for sharing your future plans with me. Yeah, maybe they didn't brief you too much on this, but that's what we're doing today. Oh, really? Yeah, we're gonna do an offsite backup, and you are going to sleep so much easier at night knowing that every night, everything that you ingest to your main editing NAS, which can be used by any of his editors, both local, remote, whatever. If Mark just wants to check on something, everything that he dumps on there is going to be replicated to this one so that in the event of a fire or other disaster, the data won't be lost because the hardware has a value, sure, in thousands of dollars. What's the data worth to you, Mark? $20 minimum, just kidding. Per kilobyte. Priceless, Linus. It's priceless. And that is the punchline here is it's like, it's the peace of mind. Even just having the NAS, I wish I should go grab it, but I'll send you a B-roll shot of it, but it was stored on these little Western Digital hard drives in a Tupperware in my freaking closet. Everything I own is in a NAS here, and then now, if we have a fire here and knowing that it's backed up a second physical location, knock on whatever, a game changer. Absolute game changer. Do you have any regrets not going with a DAS? Because I gotta give them credit. They did the research. Like your plan was not stupid. It was like the Mac plan. No, I think it's working well for us. I think the other thing that was different, that kind of was something we had to wrap our head around was that we don't necessarily have like a bunch of editors in here working physically in like onsite, right? Where you need a network that we're all connected to the ethernet. We don't have a lot of editors, first of all, but second of all, like we just kind of put it on proxies on Dropbox, it's kind of our workflow. Our main need was just like a one central computer that had the raws on it, that stored it all, that when it's time to export the video, we all work on proxies, then we remote into that and export it from that computer. So yeah, it's working amazingly. It's the freaking best. It's just the best. And it's something we wouldn't have been able to figure out on our own at all. And our solution was gonna be a lot more expensive than the one you guys proposed. So you were able to like look at what our actual needs were and being like, look, you don't need the Ferrari to go to the grocery store. You know, you just need, for what you guys need, this is what the perfect like solution would be. Just one of those things we're just like having this, because this is what we are, we make videos. This is our core product, right? So it's like our Fort Knox for everything just didn't even have a lock on it. And now it's actually organized and locked and I can sleep at night, so. You're probably gonna go back and actually use this footage like very rarely, but it's there. Yeah, that's right. It's there. But we just had this situation. We're getting a bunch of our videos translated and we had to, we used this like, cause we had to go back and like get the stems and stuff. And no, if we didn't have the server, like that made our lives infinitely easier. We went back like 40 videos, right? That's awesome. I'm so glad. So we are just about set up here to demo the offsite backup capabilities. Jake. We're gonna live try to sync the machine that's with you, which is thousands of miles away from us up here in Vancouver to this machine right here. And hopefully it'll just work. It all rests on this little cable right here. This also means that you'll be in possession of my entire back catalog of footage. So you better not start like a TikTok and bootlegging all my videos, Linus. I mean, you signed the end user license agreement, right? And the privacy policy. Did you read it? This was your end game all along. Curse you. You're only one of them. You are just one gear in this machine. This is exciting. So how long will it take? Cause I think we have like. You have a hundred terabytes. It's gonna take like a week. Yeah. The first go will take, you know, however, I mean, you've got one gig connection there. We'll probably set it to run at like half that speed. So it doesn't just destroy your internet. Yeah, so you don't go to like upload a video. Yeah, what's going on? Why does Google suck? So probably like a week or two. And then once that's done, every subsequent sync, it only copies that extra little bit. Yeah. So it's a lot faster. What's really cool about this is that in the event that you guys were to suffer from some kind of a cryptographic attack, right? Like a ransomware. There's really advanced ransomware's out there that will go and they will start encrypting everything, even on network attached drives that are accessible to the infected machine. So because we're using a technology called snapshotting, where it will actually retain an old non encrypted copy on that remote server, theoretically, you will be able to go back in time, kind of like Apple time machine and restore it to a state before it was encrypted. And it'll be super inconvenient and it'll suck. In fact, it might even be faster to literally get in the car and sneaker net that other machine back into the office. So you can not lose production time compared to, you know, copying it back over or whatever, but you'll have it, which is better. Cause so I see, so when you guys ship it to us, it'll already have all this stuff on it, huh? It will sort of, so it'll have everything on it, but we're going to pull all the hard drives out for safety during shipping, because they can be quite sensitive. We want to ship them in a proper hard drive shipping container. So theoretically, and we might need to give you a little, you know, 15 minutes of remote help with it or whatever, but theoretically. We already did this once, remember? Okay. So you'll take those drives, you'll slam them into this machine and everything will just pick up. I'm truly just something in my brain. It's just like, it's just so excited to get this peace of mind. Cause that's what this is. This is like insurance and peace of mind and something that's been nagging on me forever. Every time I opened the freaking closet and see that pile of hard drives. So. Okay. In theory, it's running now. Hey, look at that. We're getting about 40 megabytes a second. And I think you said too, we can set it on schedules where they just do it after 9 PM or something, right? Yeah, totally. And another thing you can do too actually is if it's not too much of a trek between your two locations, you could bring it onsite, do the first sync at full gigabit or even, I don't know if I switched that. Okay. So at ball in speeds, and then you can go and take the other one offsite after the fact. This is awesome, dude. We've already, we've actually already transferred two gigabytes here. Really? I was going to say like two, two gigabytes. That's like my first, probably 12 videos when I was filming camera. I think this whole project is six gigs. Do you remember it was called like watermelon smoothie or something? Oh yeah. Yeah. I know the watermelon smoothie. It's a classic. Look it's baby Mark. I know still rocking the backwards cap though. Show up to that last picnic of the summertime, like a boss. And all you're going to need is a watermelon, a coat hanger and a drill. Like a boss. Wow. That sideways gangster drill movement. That's still cool. I still stand by that drill movement. Well, this is a quick video. We can just watch the whole thing. It is kind of short. Did you clean the coat hanger before you used it for this? Have you re-uploaded? No, I didn't. Have you re-uploaded this as a short yet? No, I should. You should. How long is this video? Like two minutes. Yeah. No minute and 42. Oh, this could then no offense, but there's some dead air. Again, you picked an early folder to look into it. I'll put this on me. No, this is great. You have an age today. I swear. Yeah. I like the part where the watermelon juice goes in and then out and then in and then out. I still stand behind that barfing watermelon scene. So I think that's it. You have a meeting in one minute. So we got that resolved just in time. Thank goodness. Perfect timing. Enjoy the new NAS-ziz. You guys are legends. Eternally grateful. Thank you so much. You make it so I can sleep at night. Now it's time to rip this whole thing apart. Pack it up, ship it and tell you about our sponsor. Cable mod. You're still using that ugly space consuming 12 volt high power adapter that came with your GPU. Why? Cable mods, basic 12 volt high power replacement cables are designed to get rid of that squiddish adapter and leave you with a cleaner looking PC. These cables enable your ATX 2.0 power supply to power any graphics card with a 12 volt high power port. They're available for a wide variety of power supplies like Seasonic, EVGA, Corsair, and more. And just like Cable Mod's famous sleeved cables, these 12 volt high power cables are made with 16 AWG wire to fully support 600 Watts of safe aesthetic power delivery. So treat yourself and upgrade your build with Cable Mod today at the link below. You guys enjoyed this video. Maybe check out the time we built the NAS for dream. It was, yeah, it was less reasonable.",
    "transcript_keywords": [
        "hard drives",
        "drives",
        "Mark",
        "hard",
        "Yeah",
        "put",
        "Mark Rober",
        "thing",
        "drive",
        "SATA hard drives",
        "SATA",
        "NAS",
        "storage",
        "power",
        "boot drives",
        "time",
        "set",
        "machine",
        "kind",
        "video"
    ],
    "transcript_entity_values": [
        "40",
        "one gigabyte",
        "one",
        "eBay",
        "VPN",
        "SSD",
        "Seasonic",
        "eight",
        "One",
        "Supermicro",
        "RGB",
        "240 terabytes",
        "zero",
        "Corsair",
        "nine",
        "Dropbox",
        "EVGA",
        "GPU",
        "seven",
        "NAS-ziz",
        "eight",
        "Rome D8-2T.",
        "DAS",
        "a hundred terabytes",
        "200 terabytes",
        "squiddish adapter",
        "AMD",
        "Micron",
        "LTT",
        "four years ago",
        "three",
        "L2",
        "Plex VM",
        "like an hour",
        "11",
        "two gigabytes",
        "YouTube",
        "1998",
        "Noctuas",
        "20",
        "3,200",
        "Linus",
        "only one",
        "AIO",
        "half",
        "ASRock Rack's",
        "20 terabyte",
        "a bajillion",
        "the year",
        "years",
        "Milan",
        "thousands of miles",
        "as little as 350 bucks",
        "Apple",
        "first",
        "Tailscale",
        "Los Angeles",
        "Green PCB",
        "4i",
        "9 PM",
        "Ferrari",
        "Today",
        "Rome",
        "Mac",
        "Oculink",
        "HBM",
        "two minutes",
        "12 volt",
        "Seasonic Prime Platinum",
        "hundreds of miles",
        "Tupperware",
        "Mars Rover",
        "5400",
        "about 150 terabytes",
        "Ryzen",
        "CPU",
        "six",
        "Vancouver",
        "NAS",
        "16i",
        "1300 watt",
        "ATX",
        "12-volt",
        "IO",
        "thousands of dollars",
        "four",
        "1300 watts",
        "Naples",
        "10,000",
        "SAS HD connectors",
        "Black PCB",
        "Google",
        "SAS HD",
        "one terabyte",
        "ZFS",
        "four to seven",
        "ECC",
        "Oculink",
        "decades",
        "OWC Thunder Bay Flex 8",
        "Western Digital",
        "16",
        "Oculink",
        "five",
        "RAID-Z2",
        "No minute",
        "TikTok",
        "Watts",
        "10",
        "a ton",
        "10 years",
        "M.2",
        "QNAP",
        "Mark",
        "18",
        "CableMod",
        "Epic",
        "week",
        "as little as $1,000",
        "42",
        "ATX 2.0",
        "about 40 megabytes",
        "12",
        "about $20",
        "Epic",
        "every night",
        "10",
        "two",
        "Cable Mod's",
        "these days",
        "PCB",
        "second",
        "HBA",
        "160",
        "128",
        "Jake",
        "night",
        "like half",
        "Sabrent Gen 4",
        "600",
        "Fort Knox",
        "Thunderbolt",
        "Epic CPU",
        "just $150",
        "15 minutes",
        "today",
        "Dropbox",
        "only four",
        "SATA",
        "Mark Rober",
        "RAM",
        "DIY NAS",
        "one minute",
        "around $380",
        "USB",
        "five",
        "Zetafest",
        "Fractal",
        "less than $500",
        "IO",
        "Noctua",
        "a year ago"
    ],
    "transcript_entity_types": [
        "CARDINAL",
        "QUANTITY",
        "CARDINAL",
        "ORG",
        "PRODUCT",
        "ORG",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "DATE",
        "ORG",
        "ORG",
        "ORG",
        "CARDINAL",
        "ORG",
        "DATE",
        "PERSON",
        "ORG",
        "CARDINAL",
        "DATE",
        "ORG",
        "ORG",
        "ORG",
        "ORG",
        "DATE",
        "CARDINAL",
        "PRODUCT",
        "ORG",
        "TIME",
        "DATE",
        "QUANTITY",
        "ORG",
        "DATE",
        "PERSON",
        "MONEY",
        "CARDINAL",
        "PERSON",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "ORG",
        "QUANTITY",
        "CARDINAL",
        "DATE",
        "DATE",
        "GPE",
        "QUANTITY",
        "CARDINAL",
        "ORG",
        "ORDINAL",
        "ORG",
        "GPE",
        "ORG",
        "CARDINAL",
        "TIME",
        "ORG",
        "DATE",
        "GPE",
        "PERSON",
        "ORG",
        "ORG",
        "TIME",
        "QUANTITY",
        "ORG",
        "QUANTITY",
        "ORG",
        "PRODUCT",
        "CARDINAL",
        "QUANTITY",
        "NORP",
        "ORG",
        "CARDINAL",
        "GPE",
        "ORG",
        "CARDINAL",
        "QUANTITY",
        "ORG",
        "QUANTITY",
        "ORG",
        "MONEY",
        "CARDINAL",
        "QUANTITY",
        "GPE",
        "MONEY",
        "ORG",
        "ORG",
        "ORG",
        "ORG",
        "QUANTITY",
        "PRODUCT",
        "CARDINAL",
        "ORG",
        "WORK_OF_ART",
        "DATE",
        "ORG",
        "ORG",
        "CARDINAL",
        "PERSON",
        "CARDINAL",
        "ORG",
        "TIME",
        "ORG",
        "LOC",
        "CARDINAL",
        "QUANTITY",
        "DATE",
        "ORG",
        "ORG",
        "PERSON",
        "CARDINAL",
        "ORG",
        "WORK_OF_ART",
        "DATE",
        "MONEY",
        "DATE",
        "PRODUCT",
        "QUANTITY",
        "CARDINAL",
        "MONEY",
        "PERSON",
        "TIME",
        "DATE",
        "CARDINAL",
        "ORG",
        "DATE",
        "ORG",
        "ORDINAL",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "PERSON",
        "TIME",
        "CARDINAL",
        "ORG",
        "CARDINAL",
        "GPE",
        "PRODUCT",
        "PRODUCT",
        "MONEY",
        "TIME",
        "DATE",
        "PRODUCT",
        "CARDINAL",
        "ORG",
        "PERSON",
        "ORG",
        "ORG",
        "TIME",
        "MONEY",
        "ORG",
        "DATE",
        "PERSON",
        "ORG",
        "MONEY",
        "GPE",
        "ORG",
        "DATE"
    ]
}