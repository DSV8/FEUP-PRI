{
    "id": "YCmGVXlpE3k",
    "title": "GPT-4 is here but no longer open source | The Vergecast",
    "channel": "The Verge",
    "channel_id": "UCddiUEpeqJcYeBxX1IVBKvQ",
    "subscriber_count": 3390000,
    "upload_date": "2023-03-17T21:20:16Z",
    "video_url": "https://www.youtube.com/watch?v=YCmGVXlpE3k",
    "category": "Science & Technology",
    "tags": [
        "gpt 4",
        "gpt4",
        "gpt-4",
        "openai",
        "open ai",
        "chatgpt",
        "chat gpt",
        "artificial intelligence",
        "ai",
        "gpt3",
        "gpt 3",
        "gpt-3",
        "machine learning",
        "natural language processing",
        "open ai chat gpt",
        "chatbot",
        "chat gpt explained",
        "what is chatgpt",
        "chatgpt explained",
        "how to use chat gpt",
        "openai chatgpt",
        "ai news",
        "what is chat gpt",
        "openai chatbot gpt",
        "ai art",
        "chat gpt tutorial",
        "the verge",
        "the vergecast",
        "vergecast podcast",
        "vergecast",
        "vergecast video",
        "tech",
        "tech news"
    ],
    "views": 40680,
    "likes": 865,
    "comments_count": 41,
    "description": "They are another corporate actor like anyone else: The Verges James Vincent joins us on The Vergecast this week to discuss peoples concerns with OpenAI. #OpenAI #Tech #Podcasts   Check out the full episode here:    Subscribe:  Like The Verge on Facebook:  Follow on Twitter:  Follow on Instagram:   The Vergecast Podcast:  Decoder with Nilay Patel:   More about our podcasts:   Read More:  Community guidelines:  Wallpapers from The Verge:   Subscribe to The Vergecast on YouTube, new episodes on Wednesday and Friday:",
    "description_links": [
        "https://youtu.be/MMpP3f2rv90",
        "http://goo.gl/G5RXGs",
        "https://goo.gl/2P1aGc",
        "https://goo.gl/XTWX61",
        "https://goo.gl/7ZeLvX",
        "https://pod.link/430333725",
        "http://apple.co/3v29nDc",
        "https://www.theverge.com/podcasts",
        "http://www.theverge.com",
        "http://bit.ly/2D0hlAv",
        "https://bit.ly/2xQXYJr",
        "https://bit.ly/3I6nJtz"
    ],
    "transcript": "(upbeat music) - There is actually AI news this week. GPT-4 was released from OpenAI. Google announced AI tools in Gmail and Docs. Microsoft its own AI tools in Office. Let's start with GPT-4 which, frankly the things people have done with it in just the the handful of days that it has been publicly available are kind of mind blowing. James, what's going on here? - So, this has been awaited and hyped and (indistinct) for a long time. GPT-3 came out in, oh gosh now 2022. 3.5 has been powering chatGPT. So people have been waiting for this and there's been a lot of pressure on OpenAI about what they're gonna do with this. They've given it to a lot of people already I feel they've already got it in a lot of products. I think this is the point at which, the earth, the, you look back at the first GPT paper which was in 2018, obviously it's a research paper. GPT-4 is straight out of gate. It's a product. It is something that is being used by Stripe it's being used by Morgan Stanley it's being used by Duolingo, it's being used by all these companies already. So I think the excitement with GPT-4 is, that it is a fully fledged product. There are all these interesting novelties, the you load up Twitter and you cannot escape some thread of someone saying \"Here's why GPT-4 is gonna be the most revolutionary thing since the steam engine, since fire, since whatever.\" And a lot of those are truly very impressive. But we've seen in the past with technologies like this that consistency, that truthfulness, continue to be big problems for these language models. And obviously we also have the Microsoft news which will get to later that they're putting GPT-4 they're using it throughout their Office suite in order to help with the sort of drudgery of office tasks. So yeah, it's a huge story. It's been everywhere, but people are still really trying to assess how much of a revolution this is. The big thing that it does that earlier iterations didn't do, is it can understand it can process images as well as text. So you can show it a visual input of some sort whether that's a meme or a diagram. And it will be able to answer questions for you. One demo of this was you show it a picture of the inside of your fridge. It recognizes what's inside there and gives you recipes to make. However, that is still, that's not a skill a functionality that is widely available yet. So far we've only got the chat input and output really available to the public. So yeah, there's a lot of stuff that we're gonna have to process as this sort of rolls out and people test it more. - And one of the things that is weird to me about this rollout, and I'm curious how you've processed it James, is that on the one hand, like you said this is the most producty thing OpenAI has ever done. Two wild degrees, right? Like it's they're charging money for these things now they're closing their research wings and not showing people a lot less about what they're doing which we should get to in a minute. But then at the same time, Sam Altman, the CEO of OpenAI is, has been out here sandbagging GPT-4 for like months in every interview. He's like, \"This thing isn't gonna be as good as you think. We haven't solved everything.\" He keeps saying like, \"It's less impressive the longer you use it.\" Which is just a deeply hilarious thing to say about your own product. Like what does OpenAI actually think of this, do you think? - It's really interesting to look at what he says depending on who his audience is gonna be. And I think when he's speaking the when he's saying these things about dumbing down people's expectations he's often speaking to not the mainstream crowd per se but he's speaking to a sort of hardcore of AI researchers within Silicon Valley who are very concerned about existential risk, for example. These are people who think that the current path we're on is that AI is going to become, this out of control entity that acts on its own instructions acts under its own regards and starts messing up things on the internet. So in he's definitely speaking to them, he's saying, \"Look guys, it's not at that point you need to calm down.\" - So he's trying to convince them that it's not the end of the world, like literally the end of the world. (all laughing) - Yes, but he's doing this rhetorical trick, oh my God I should have looked this up beforehand. litotes, I think it's called, where you bring up something in order to say that it's not a thing. It's like, I wouldn't I would never dream of talking about my opponent's luxury. I would never even accuse him of, visiting brothels or whatever it is. And Altman is sort of doing that with AI. He's saying, \"Oh, don't not even worry about this being the world destroying super intelligent computer that's gonna take over the world.\" (all laughing) \"We would never, we have that so under control don't even think about it.\" And then, and then suddenly everyone's going, \"Oh my God they're building a super intelligent computer.\" Like I think that's what he's doing as well is that he is very clever at using, at using people's cultural expectations of AI in order to gin up excitement. And if you look at the trajectory that OpenAI has been on under his command, it's worked fantastically. They are rolling in money, they are beating Google. They are Microsoft is working for them in some ways in terms of the Azure supercomputer that they've built for them. Like open AI are from a sort of business competition standpoint doing incredibly well. And a lot of that is to do with how Altman masters that sort of rhetoric in the open field. - But he's also doing it to like cover up the fact that it is kind of dangerous. People do have concerns and he hasn't addressed any of the facts of like, how it can be a major tool for misinformation, right? Like he's doing successful on the business stuff at the, at genuinely the the potential cost of like major parts of it- - Sure and the evidence of that, Alex, I completely agree. The evidence of that is that they've closed down the research function. It's the open and OpenAI is a misnomer now they've closed it down. And James, they have told you that their previous approach to building in the open was I think the word they actually used was we were wrong. - Yeah flat out wrong was the quote I got from Ilya Sutskever who is chief scientist co-founder. So he was one of the original seven or eight figures along with Altman, along with Elon Musk, who's obviously, he's no longer connected with the company, who founded OpenAI. And again, they are speaking to this idea of AI safety and AI risk. And the tricky thing about this is, well not the tricky thing. The fascinating thing about it is that everyone disagrees. Some people think you should have OpenAI systems because only the community can truly test, stress test these things. And I think there's, obviously we look at what happened to the Bing chatbot. Microsoft obviously rushed that out - The most stress tested. - But it got stress tested by the entire internet over the space of a couple of weeks. And they, it on in a way that was very bad for Microsoft to put out such a easily breakable product. But I bet Microsoft was also pretty happy with the fact that they got all this fascinating and useful data about how to improve it. - No, Microsoft went from no one ever talking about Bing to a lot of people being like, \"I think Bing is in love with me.\" Which is an incredible journey for any brand to go on. - Yeah they yeah, they got a lot out of it. And some people think that Open AI's research should be open for the same reason. Others think that as Sutskever told me, that because it is now getting potentially dangerous that means it should be closed off. However, on a stress that he gave two reasons. He gave, one was the business reason in that we don't want our rivals to copy us. And the second was the safety reason in that we think this could be a threat to society. And he said right now the business reason is foremost. So I think Microsoft has probably had a word I think at this point, the amount of money that Microsoft has behind this product and the amount of which their brand is currently tied to this AI and what it can do, we have their new announcement for them today. I think someone said, Nadella said, \"We can't be given these secrets away to Google when we are suddenly in a chance to overturn their position in a lot of dominant mar.. In a lot of markets.\" So a lot of people are incredibly mad at OpenAI because they were, to use the \"Star Wars\" meme they were the chosen one. They were supposed to save AI research by making sure that everything would be developed for the benefit of humanity. That's like part of their original mission statement. And now they are another corporate actor like anyone else. And if you're really worried about AI risk you might now see them as someone who is accelerating AI risk because they are developing it based on business interests not on ethical and safety interests. So it's a big trouble. - Maybe the most prominent critic there, Elon who, surprise Elon has an opinion about something online. But Elon initial investor in OpenAI and I think his tweet was, \"Very curious how my a hundred million dollar investment into an OpenAI project has turned into a $30 billion for-profit company.\" Which Elon baggage aside, that is a very direct statement of the problem. Right here is this, this thing that was started as a non-profit to reduce this risk and has now become a very profitable private company. - Increasing the risk. - Yes yeah, the tricky thing is that the non-profit still exists. OpenAI has an incredibly bizarre corporate structure which I'm probably not fully qualified to explain all the details of but essentially it has a non-profit controlling entity and then a capped profit entity that makes all the money. And that is controlled by the charter of OpenAI. And they have this big promise in the nonprofits charter that as soon as they think they are anyone in the world is two years away from developing a super intelligent AGI they will stop all business work that they're doing and work towards helping that project be launched safely. Now in one way it's obviously very admirable. You some people see it as very admirable to be like, yes, okay, we'll give that up in order to have the safe thing first. On the other hand, it's also, for lots of critics complete bullshit. Who has a definition of what a super intelligent AI is? They can change that whenever they like. There is, if open AI has proved anything it's that they're extremely malleable and if they've proved what their goal is at the moment it's making money from Microsoft, that's it. - And what's been weird to me about this is on the one hand it does totally fly in the face of everything that OpenAI has ever said about what it wants to be as an organization. But on the other hand they've been kind of telegraphing this for a long time. And my running theory for the last like six months has been that this happened much, much, much faster than anybody at OpenAI thought. And that somewhere in the last like 12 months, the executive team there and frankly like the whole tech industry went like oh my God this is here. Like this is real now we can do this. And somebody at OpenAI went like, \"Oh no we're screwed if we don't figure out how to do this.\" And somebody at Microsoft potentially including somebody like Satya Nadella was like, \"We need to pull as much of this under our own auspices as possible.\" And I don't know, I just can't stop thinking everybody thought this was gonna be like a 2027 problem and then turned around in like September and was like oh, we should probably start doing this now. - Google is just like lost, right. And like Google's errors along the way to not let people play with the product or demonstrate it convincingly have created a perception that it is very far behind. Whether or not that is true. They're giving away one of their models. But the the good one Lambda that the guy thought was alive we haven't really seen it in action. It's gonna get rolled out into some of these products. We, James, I'm very curious, the Facebook model was leaked you can just like torrent it. - Yeah. - Weird things have started happening with that model that has implications for safety. I think that's gonna be the first kind of big test case of what happens when these models are just literally out in the open. - Yeah. - And in the meantime, I don't wanna lose sight of this, the things we have seen from GPT-4 this week are legitimately amazing, right. I took a photo of a hand drawn sketch of a website and it coded the website for me and it works is amazing. The, I saw one person feed into it \"Make a code me a game where the right side is pong and I control the paddle and the left side is the game of life.\" It worked, it just worked. I can't do that. That is a capability I didn't have and now I can just will it into existence by telling a robot to make it for me. I've seen people fully code SwiftUI iOS apps. - Yeah did you guys see the one where the guy built an app that would recommend five movies to him every day? - Yeah. - That to me is like, it's such a for whatever reason for me, like all of the chatGPT stuff has just been like a movie recommendation service. Like it's all neat and whatever, but I can say like I like heist movies and I have Amazon Prime and Netflix what movies should I watch tonight? And it like, does it successfully and it's incredible. And this guy was just he basically with some back and forth with GPT-4 built an app that every day recommends five movies pulls in trailers, pulls in information and it just does it. No coding, no nothing and then at least according to his thread basically like, copied and pasted it and submitted it to the app store. It's nuts. - Right so there's something underlying that that is important, which is he knew how to make an iOS app and so the thing writing the code like chatGPT couldn't do the work as James is pointing out. Like it can't, it might be able to deduce the nuclear codes but it can't go push the buttons for you. - Right. - Sam Altman is like and we'll never let it do that, winking. This is like, yeah it can write a bunch of Swift code cause there's a bunch of Swift code in the internet for it to go look at. But it can't actually put it into Xcode. It can't actually hit compile it can't tell you if it's gonna work or not, right. This is like the examples here are a human being working with that system almost as a peer, right? And like, going back and forth together in a way that even the previous GPT3.5 iteration of chatGPT was not up to that standard. So that's really impressive. But the idea that now it's a business and the GPT-4 announcement came with a lot of sort of like API customer announcements as you were saying James. Now other businesses can depend on this to run their business, that's the turn. And that's where I think Casey and Zoe had it in platform or this week that Microsoft is like, scaling down its ethical AI research investment because they're the people who say no. And now you're like, well there's money here so we're gonna start saying yes at a higher rate. - So the turn here it seems to me isn't that chatGPT got better, the AI's got better. It's that we realized we could make money we figured out how to profit off of them and we found that the profit was better than the potential moral ramifications of releasing this thing that has like is a major misinformation tool. - James, do you think that's accurate to say? - Is that accurate? Yeah, James, I mean, call my bullshits if it's bullshit but that's like my read. - I think that is a hundred percent part of the dynamic. And I think that is why this lack of information that OpenAI released for GPT-4 in particular has stung people because they were founded as a nonprofit where they were supposed to be above these corporate motivations. And obviously they prove that they're not. Their reason for getting into bed with Microsoft was that they needed a huge amount of computing power in order to create these systems. And Microsoft or some other corporate partner was necessary to provide that. And I speak to a lot of people in the AI policy world and this is like one of the big things they're really worried about, is that only corporations can build these systems and corporations have very different incentives, have incentives that are not necessarily aligned with the rest of society. And that is not a controversial statement. You look at any, I don't know the history of any chemical manufacturer DuPont or whoever it is or any industrial supplier they will always make decisions where or consistently make decisions where people's safety is just not first and foremost. So Alex, I think you're completely right that this is part of what is happening now. The interesting or that the thing that makes this so naughty is that you have people who believe, not that this is say a minor hazard to society misinformation or propaganda or spam, but it is an exist existential threat to society that it's gonna turn everything into paperclips then it's gonna turn us all into gray goo. It's very difficult to pull apart those two strands of thinking and and to know what is motivating whom. Because a lot of people in Silicon Valley who are building this stuff, you look at surveys and they're like, \"Yeah I fully believe this is a huge threat to humanity.\" And then you kinda go, \"Well why are you building it then, man?\" And they say, \"Because I think I can help it be less of a threat.\" And that's very real as well. So pulling apart what is a corporate motivation and what is an existential, a philosophical motivation, it's very, very difficult. - Yeah I think that the thing that gets me right now, is we're so on the verge of there being a a robot internet where robots are making SEO spam for other robots to read and turn into affiliate links and then a human internet where real people are just like writing fanfic for each other or whatever. - Yeah this was another GPT-4 experiment where a guy was like, he started a conversation with it and was like, \"I've got a budget of a hundred dollars, I want you to make me money. Tell me what to do and I will do it.\" And he ended up up the GPT-4 came up with this idea of starting an affiliate link website of green gadgets. - Beautiful. - And so it, but it coded the website for him. It decided what gadgets to put in there. And it is, this was, this is happening as we speak now. So I don't know how far it's doing, but it had started making a little trickle of money. I'm pretty sure, but also it started making money cause people started investing in it because everyone knew that the thread was going viral on Twitter so it was bound to get some click through. So it became this sort of like it ruined the experiment immediately. It was not a- - It's very good. - An isolated experiment, but yeah that is one way. And we saw this news with LinkedIn this week that they're now saying GPT-4 will write your user bio for you. - Yeah and then LinkedIn already has prompts like AI written prompts and then people answer it and then it generates AI written articles. What, I don't know how to be a work influencer or whatever it is on LinkedIn. There's a whole universe of robot inter internet to come, right. - A lot of AI moons. - A lot of AI moons. And it's like, if you're shopping for a desk, is it and you know what the answer is like you have to like slice your way through the AI chum, that is designed to convince Google it's people and like land like here just by this desk or whatever. And I think that there's like a parallel human internet that will be created out of all this, this is just my, this is my fear. - Will it just be Reddit? - Yeah it's like Reddit. Like it's, there's another kind of social networking, that is to come in particular on the internet, that where people, people are pretty good at spotting the chat, like the chatGPT output. They're better than the AI systems are detecting it and they're certainly good at spotting boring stuff, which is the vast majority of what is produced. And I, you just like, that's my optimistic take on it is that eventually the, it'll be more profitable for the robots to just be robots at each other. Like we'll all just like hang out somewhere we're just gonna like be in a vBulletin that hasn't been updated since 2004 and that'll be fine. (upbeat music)",
    "transcript_keywords": [
        "people",
        "Microsoft",
        "thing",
        "lot",
        "OpenAI",
        "yeah",
        "things",
        "James",
        "money",
        "sort",
        "make",
        "open",
        "lot of people",
        "business",
        "Google",
        "internet",
        "Altman",
        "things people",
        "tricky thing",
        "Elon"
    ],
    "transcript_entity_values": [
        "Azure",
        "GPT",
        "GPT3.5",
        "DuPont",
        "Elon",
        "September",
        "the last like six months",
        "this week",
        "one",
        "like months",
        "Duolingo",
        "a hundred million dollar",
        "2027",
        "a hundred percent",
        "Twitter",
        "AI",
        "Reddit",
        "3.5",
        "today",
        "Sutskever",
        "Silicon Valley",
        "Google",
        "vBulletin",
        "eight",
        "a hundred dollars",
        "OpenAI",
        "Xcode",
        "tonight",
        "Office",
        "AGI",
        "Nadella",
        "two years",
        "API",
        "Morgan Stanley",
        "Gmail",
        "Casey",
        "Stripe",
        "$30 billion",
        "two",
        "Satya Nadella",
        "Docs",
        "Elon Musk",
        "Amazon",
        "Two",
        "One",
        "Facebook",
        "Sam Altman",
        "Zoe",
        "Alex",
        "LinkedIn",
        "a couple of weeks",
        "2018",
        "second",
        "the last like 12 months",
        "five",
        "Netflix",
        "Ilya Sutskever",
        "Microsoft",
        "first",
        "Reddit",
        "2004",
        "LinkedIn",
        "James",
        "Swift",
        "seven",
        "mar",
        "every day",
        "a minute",
        "2022",
        "Altman"
    ],
    "transcript_entity_types": [
        "ORG",
        "ORG",
        "WORK_OF_ART",
        "ORG",
        "ORG",
        "DATE",
        "DATE",
        "DATE",
        "CARDINAL",
        "DATE",
        "ORG",
        "MONEY",
        "CARDINAL",
        "PERCENT",
        "ORG",
        "ORG",
        "GPE",
        "CARDINAL",
        "DATE",
        "ORG",
        "LOC",
        "ORG",
        "ORG",
        "CARDINAL",
        "MONEY",
        "GPE",
        "WORK_OF_ART",
        "TIME",
        "ORG",
        "ORG",
        "PERSON",
        "DATE",
        "ORG",
        "ORG",
        "ORG",
        "PERSON",
        "ORG",
        "MONEY",
        "CARDINAL",
        "PERSON",
        "ORG",
        "PERSON",
        "ORG",
        "CARDINAL",
        "CARDINAL",
        "ORG",
        "PERSON",
        "PERSON",
        "PERSON",
        "PERSON",
        "DATE",
        "DATE",
        "ORDINAL",
        "DATE",
        "CARDINAL",
        "ORG",
        "PERSON",
        "ORG",
        "ORDINAL",
        "LOC",
        "DATE",
        "ORG",
        "PERSON",
        "PRODUCT",
        "CARDINAL",
        "DATE",
        "DATE",
        "TIME",
        "DATE",
        "PERSON"
    ],
    "vector": [
        -0.08050191402435303,
        -0.10719743371009827,
        -0.015970168635249138,
        -0.010610767640173435,
        0.12689892947673798,
        -0.06527964770793915,
        -0.015975112095475197,
        0.021497558802366257,
        0.03891602158546448,
        -0.016189171001315117,
        -0.047164320945739746,
        0.05861874297261238,
        -0.041924718767404556,
        0.03722964599728584,
        0.033019185066223145,
        -0.011749090626835823,
        -0.006075815763324499,
        -0.06072030961513519,
        -0.05160028859972954,
        -0.03764820098876953,
        -0.06709173321723938,
        0.020716890692710876,
        0.04300551861524582,
        -0.03485001251101494,
        0.026583386585116386,
        0.02347845584154129,
        0.014061646535992622,
        -0.16470152139663696,
        -0.0011343104997649789,
        0.019542012363672256,
        0.0009430312202312052,
        0.03372158855199814,
        0.028421100229024887,
        -0.012668275274336338,
        -0.06730850040912628,
        -0.01835154928267002,
        0.011163563467562199,
        -0.023155096918344498,
        -0.05445825308561325,
        -0.012099704705178738,
        0.055503249168395996,
        -0.0382583811879158,
        -0.01190017070621252,
        0.01572590507566929,
        0.06031787768006325,
        0.011309514753520489,
        -0.011928359046578407,
        -0.10025126487016678,
        -0.018557284027338028,
        -0.009538089856505394,
        -0.06865322589874268,
        -0.09171504527330399,
        0.02604338526725769,
        -0.024184783920645714,
        0.030160387977957726,
        0.010342922061681747,
        -0.041719309985637665,
        0.03345053270459175,
        0.021592648699879646,
        0.04419911652803421,
        0.08393462002277374,
        -0.057483792304992676,
        -0.08643074333667755,
        -0.0074753426015377045,
        0.014660034328699112,
        0.08374518901109695,
        0.01725093275308609,
        0.006434471812099218,
        0.021585961803793907,
        -0.10016650706529617,
        -0.0022923883516341448,
        0.06265319883823395,
        -0.023453684523701668,
        -0.0035784367937594652,
        0.03025958128273487,
        0.035429030656814575,
        0.048664361238479614,
        0.01949380524456501,
        0.02291366644203663,
        -0.05960596725344658,
        0.09982523322105408,
        -0.005642417352646589,
        0.03693217784166336,
        -0.017078034579753876,
        -0.01981218159198761,
        -0.012255065143108368,
        0.013764255680143833,
        0.03483055904507637,
        0.04135255515575409,
        0.03606325387954712,
        -0.03759697452187538,
        0.017942065373063087,
        0.03066435270011425,
        0.007295290939509869,
        0.06907042115926743,
        -0.06722217053174973,
        -0.1032375693321228,
        -0.07649707049131393,
        -0.007443291135132313,
        0.05811896547675133,
        -0.04204599931836128,
        0.03591984137892723,
        -0.032829463481903076,
        -0.005002505145967007,
        -0.08427958190441132,
        0.004480540286749601,
        0.02296987920999527,
        0.0753662958741188,
        0.03371069207787514,
        0.050087954849004745,
        0.010483750142157078,
        -0.023270683363080025,
        0.0730958953499794,
        -0.10261958092451096,
        -0.045714132487773895,
        0.05445818975567818,
        -0.05091356858611107,
        0.04610545560717583,
        0.03534042835235596,
        0.08200050890445709,
        -0.0448482520878315,
        0.06394842267036438,
        -0.012321668677031994,
        -0.05360519140958786,
        0.05974676460027695,
        0.0835980772972107,
        -0.04701365530490875,
        4.597607463931547e-33,
        0.050647344440221786,
        0.05988604202866554,
        0.013096384704113007,
        -0.014951860532164574,
        0.05471966788172722,
        0.042807888239622116,
        -0.03628652170300484,
        -0.038024526089429855,
        -0.018491266295313835,
        -0.07669918984174728,
        0.003325757570564747,
        0.04314162954688072,
        -0.09843245148658752,
        -0.0019350462825968862,
        0.004093961324542761,
        -0.06291592866182327,
        0.014578551054000854,
        0.05965377762913704,
        -0.04185371473431587,
        -0.01456492394208908,
        0.03097466006875038,
        0.057318028062582016,
        -0.009821314364671707,
        -0.010309676639735699,
        -0.022411542013287544,
        0.07430702447891235,
        0.013317698612809181,
        -0.03894137218594551,
        0.14230458438396454,
        0.02788790501654148,
        -0.1147867888212204,
        0.042412467300891876,
        -0.0526178777217865,
        0.03324020653963089,
        0.005320809315890074,
        0.02390759438276291,
        -0.08117659389972687,
        -0.109353207051754,
        0.038192253559827805,
        0.029263317584991455,
        -0.024302257224917412,
        0.0076639349572360516,
        0.03115224465727806,
        -0.10199003666639328,
        0.00960561353713274,
        -0.011817233636975288,
        0.0023942620027810335,
        0.032949186861515045,
        0.055379800498485565,
        0.03361715376377106,
        -0.04656080901622772,
        0.08088504523038864,
        -0.0746326893568039,
        0.025023259222507477,
        -0.01832417957484722,
        -0.007262449711561203,
        0.021663786843419075,
        -0.0005703612114302814,
        0.06033724918961525,
        0.02661999873816967,
        0.05193034186959267,
        0.06990722566843033,
        -0.033547163009643555,
        -0.00598073611035943,
        -0.08375421911478043,
        0.04467371478676796,
        -0.0330498144030571,
        0.0234692320227623,
        -0.023161157965660095,
        0.11200257390737534,
        -0.03272051736712456,
        -0.013169582933187485,
        -0.003371977712959051,
        -0.014702638611197472,
        0.045288365334272385,
        -0.021606996655464172,
        -0.047906242311000824,
        -0.03531226888298988,
        0.010169537737965584,
        0.005177740007638931,
        -0.07090948522090912,
        0.013886779546737671,
        0.015399579890072346,
        -0.052900530397892,
        -0.029760872945189476,
        -0.04382174462080002,
        -0.00494738295674324,
        0.04144921526312828,
        0.0014540704432874918,
        0.01010715588927269,
        -0.11260624974966049,
        -0.022965652868151665,
        -0.06409671902656555,
        0.13264216482639313,
        -0.015378325246274471,
        -5.1664743633585616e-33,
        -0.048732176423072815,
        -0.010196027345955372,
        -0.04682045802474022,
        0.06563959270715714,
        -0.04483918100595474,
        -0.06138232350349426,
        0.02310669608414173,
        0.019043829292058945,
        0.042317964136600494,
        0.026220621541142464,
        0.07851704955101013,
        -0.0361408106982708,
        0.03580145537853241,
        0.008381476625800133,
        0.05823586508631706,
        -0.05131366848945618,
        -0.013922382146120071,
        -0.10700239986181259,
        -0.04242321476340294,
        0.03792766481637955,
        0.07955040037631989,
        -0.005120293702930212,
        -0.11464710533618927,
        0.031768616288900375,
        0.08267956227064133,
        0.008081577718257904,
        0.10342604666948318,
        0.039074212312698364,
        0.018393579870462418,
        0.00229961471632123,
        -0.05611685290932655,
        0.009053236804902554,
        -0.10361045598983765,
        0.00938920583575964,
        0.04065418615937233,
        0.06708087772130966,
        0.10707341879606247,
        0.02434573695063591,
        -0.08997105062007904,
        -0.006301992107182741,
        0.022523725405335426,
        -0.03634282574057579,
        0.022647691890597343,
        0.028194205835461617,
        -0.02972193993628025,
        0.052933573722839355,
        -0.04066262021660805,
        0.1089053675532341,
        -0.012138457968831062,
        -0.02354854717850685,
        0.01915080100297928,
        -0.014089103788137436,
        0.021351046860218048,
        -0.06224115192890167,
        -0.06757251173257828,
        -0.06820745766162872,
        -0.02152096852660179,
        0.016989482566714287,
        -0.10106030851602554,
        0.04618166387081146,
        -0.013759303838014603,
        -0.08368109166622162,
        0.0739138051867485,
        -0.02422398515045643,
        -0.03020509146153927,
        0.00020433100871741772,
        0.05956099554896355,
        0.030163981020450592,
        0.0159994438290596,
        0.004688943270593882,
        -0.0380428172647953,
        -0.039860691875219345,
        -0.005720589309930801,
        -0.07088867574930191,
        -0.01618601754307747,
        0.08578526973724365,
        -0.034989453852176666,
        -0.04734452813863754,
        -0.01347398478537798,
        -0.03373759612441063,
        0.032153163105249405,
        -0.0013121585361659527,
        0.11387450248003006,
        -0.030220340937376022,
        0.07859209924936295,
        -0.007058500312268734,
        0.07423625886440277,
        0.052306484431028366,
        0.018206961452960968,
        0.0824037566781044,
        -0.11101407557725906,
        0.06406693905591965,
        -0.02848648466169834,
        0.1510811299085617,
        -0.04643605276942253,
        -5.303286698676857e-08,
        -0.0057091983035206795,
        -0.03018711693584919,
        -0.028344014659523964,
        0.025006968528032303,
        0.010189947672188282,
        -0.069295234978199,
        -0.01438914705067873,
        0.04803146794438362,
        -0.01799585297703743,
        0.023037370294332504,
        0.007547794375568628,
        -0.08135300129652023,
        -0.09880875051021576,
        -0.04156339913606644,
        0.10874547809362411,
        0.0371883250772953,
        -0.0742935836315155,
        -0.04571682959794998,
        -0.02051989547908306,
        -0.07143201678991318,
        -0.0020801271311938763,
        -0.03676607832312584,
        0.0677221342921257,
        -0.06465960294008255,
        -0.006188611034303904,
        -0.04048457369208336,
        -0.01577189564704895,
        0.01293889805674553,
        -0.007444361690431833,
        0.04054682329297066,
        0.029710622504353523,
        0.022805416956543922,
        0.026993917301297188,
        -0.04002746194601059,
        -0.01742829754948616,
        -0.032898224890232086,
        0.054899927228689194,
        0.06149457022547722,
        0.07376199960708618,
        0.03553350269794464,
        0.006257122848182917,
        0.007658298593014479,
        -0.006545515265315771,
        0.013724181801080704,
        -0.010507508181035519,
        -0.02923283353447914,
        -0.08593350648880005,
        -0.04141931235790253,
        0.0471341609954834,
        -0.01609039306640625,
        -0.01235714741051197,
        0.0011015476193279028,
        -0.012605481781065464,
        0.08300791680812836,
        0.09153217822313309,
        0.007211498916149139,
        -0.02770175412297249,
        -0.07998566329479218,
        -0.04500008001923561,
        0.06241467222571373,
        -0.03851817175745964,
        -0.06706350296735764,
        0.0329107940196991,
        0.07740902900695801
    ]
}