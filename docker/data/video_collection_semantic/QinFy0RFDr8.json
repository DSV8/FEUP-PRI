{
    "id": "QinFy0RFDr8",
    "title": "Why Microsoftâ€™s CEO is ready to take on Google with ChatGPT",
    "channel": "The Verge",
    "channel_id": "UCddiUEpeqJcYeBxX1IVBKvQ",
    "subscriber_count": 3390000,
    "upload_date": "2023-02-08T00:02:53Z",
    "video_url": "https://www.youtube.com/watch?v=QinFy0RFDr8",
    "category": "Science & Technology",
    "tags": [
        "chatgpt",
        "ai",
        "artificial intelligence",
        "microsoft",
        "what is chatgpt",
        "how to use chatgpt",
        "chatgpt explained",
        "bing",
        "google search",
        "google",
        "search engine",
        "best search engine",
        "chatgpt examples",
        "chat gpt trading bot",
        "chat gpt tutorial",
        "Satya Nadella",
        "microsoft ceo",
        "satya nadella interview",
        "the verge",
        "deocder",
        "nilay patel",
        "nilay patel decoder",
        "openai",
        "open ai"
    ],
    "views": 277361,
    "likes": 8569,
    "comments_count": 587,
    "description": "Microsoft has announced a new version of its search engine Bing, powered by an upgraded version of the same AI technology that underpins chatbot ChatGPT. The Verges Nilay Patel sat down withMicrosoft CEO Satya Nadella to discuss.   Read more:   Subscribe:  Like The Verge on Facebook:  Follow on Twitter:  Follow on Instagram:   The Vergecast Podcast:  Decoder with Nilay Patel:   More about our podcasts:   Read More:  Community guidelines:",
    "description_links": [
        "http://bit.ly/3x9aeUO",
        "http://goo.gl/G5RXGs",
        "https://goo.gl/2P1aGc",
        "https://goo.gl/XTWX61",
        "https://goo.gl/7ZeLvX",
        "https://pod.link/430333725",
        "http://apple.co/3v29nDc",
        "https://www.theverge.com/podcasts",
        "http://www.theverge.com",
        "http://bit.ly/2D0hlAv"
    ],
    "transcript": "- Hey everybody, it's Nilay. I have a very special episode of the Decoder podcast today with Microsoft CEO, Satya Nadella. I'm actually sitting on the Microsoft campus right now. The company just announced a new version of the Bing search engine that's powered by OpenAI. OpenAI makes ChatGPT. Microsoft is using a new version of that model to run Bing, actually answer questions in the Bing search box. And there's a new version of the Edge web browser that has a chat box right next to it where you can just ask it to summarize webpages for you, do all kinds of things. It is a big new step in search. Microsoft is not being shy about directly competing with Google in search, and I got the chance to ask Satya all about it. - Satya Nadella, you are the CEO of Microsoft. Thank you for coming on Decoder today. - Thank you so much Nilay for having me. - So Microsoft just announced a huge new version of Bing. It's powered by a bunch of OpenAI technology. A couple weeks ago, the company made a what was called a multi-billion dollar, multi-year investment in OpenAI. Tell us what's going on. - Well, I mean, today's announcement is all about rethinking the largest, software category there is, search, with this new generation of AI, because it's a platform shift, and you get to sort of reimagine pretty much everything, right? Starting with the core ranking. In fact, perhaps the most salient part of today's announcement is we've had the best gain in relevance in the core ranking using some of these large models. Second is it's not just a search engine, it's an answer engine, because we've always had answers, but with these large models, the fidelity of the answers just gets so much better. And then we've incorporated chat right into search, which is grounded in search data. So you can do a natural language prompt, which is an auto query, which is long. You get a great answer, and then you can engage in a conversation with that as the grounding or the context. So it's about basically, essentially bringing in fact a more sophisticated model, larger model, next generation model, compared to ChatGPT and grounding it in search data. The other last thing we also added was a co-pilot for the web, so that you, in Edge, can be looking at any website or any document on a website, like a 10-Q for example, and then do things like summarization. So a whole lot of these features all coming together essentially as the new Bing. - So a really interesting piece of the puzzle here is a lot of this is powered by OpenAI and OpenAI technology. OpenAI CEO, Sam Altman, was on stage with you today. You've been working with OpenAI for three years, but you haven't acquired them. You've made a huge investment into them. Why work with an outside technology vendor for the largest software category in the world? - Well, I mean, look, first of all, you gotta remember the relationship with OpenAI and our cooperation with OpenAI has got many facets. The most important thing is what we've done over the last four years is to actually build out the core infrastructure on which OpenAI is built. I mean, these large models, the training infrastructure and the inference infrastructure doesn't look like just vanilla cloud, right? So we have had to essentially evolve Azure to be pretty specialized AI infrastructure on which OpenAI is built. And by the way, Inception is also using Azure, Character.AI is using Azure. There will be many others who will also use Azure infrastructure. So we are very excited about that part. And then of course, we get to incorporate these large models inside of our products and make those large models available as Azure AI. And in all of this, we both have an investment return and we have a commercial return. And so we think we are well-placed to partner. Like I will never assume that great partnerships can't be both great returns for our customers, shareholders, and Microsoft. - There is a lot of talk today in the presentation about the values that are coming into Bing, about the safety work that's being done, about the responsible AI work that Microsoft has done for years. How do you make sure that bridges the gap to OpenAI, which is not your company, but obviously very tied very closely, and how do you make sure your products inherit all those values even when you're working with an outside company? - Yeah, first of all, OpenAI cares about safety. I mean, in some sense, their entire Inception was about how to think about safety in AI and alignment in AI. And so we share that. And we've had our principles as we talked about it today, Nilay, which since 2016, we've published the principles, ever since quite frankly we've been very focused on what I'll call the hard work of incorporating it in the engineering practice of building products, right? Starting with design, one of the things I think a lot about is when you have, let's say a new model coming, it's probably most important to actually put human in the loop versus design the human out, so that you can in fact ensure that the human agency, judgment, is what you use to train the model to be aligned with human feedback. So that's kind of what we are doing. Like when I look at even what we are doing in Bing is taking it even one step further to even ground it in the context, which is search. So I always say, look, these generator models just don't randomly generate stuff. You prompted it. So there's a whole lot you can do in the meta prompt and the sequence of prompts you generate, which we can assist with. So there's a lot of, I'll call it product design choices one gets to make, of when you think about AI, AI safety. Then you, let's come at it the other way, right? You have to take real care on the pre-trained data, right? Because that's where, you know, after all the models are trained on pre-trained data, what's the quality, the provenance of that pre-trained data? That's a place where we've done a lot of work. Second, then the safety around the model, right? At runtime we have lots of classifiers around harmful content or bias, which we then catch. And then of course the take down, ultimately in the application layer, you also have more of the safety net for it. So this is all ones that come down to, I would call it the everyday engineering practice. And guess what? Search is like that, search is an AI product. I mean, one of the things, it's kind of interesting, that we are now talking about a new algorithmic breakthrough in these large models. But we've always had AI models for, you know, decades now. And we've really built, you know, our sense of what is authoritative, how to detect authoritative, how to ensure harmful content doesn't get through. And those are all practices that will now be used. - So that leads me into, I think, the value exchange of search right now. So in a traditional search model, I ask Bing some question, it might return some snippet, but it usually returns a list of links. I go visit a webpage, the creator of that webpage might capture some advertising revenue or something else. Now you're just answering the question directly and you've trained the model on other people's information, other people's reporting, I'm very biased in favor of reporting. How do you make sure that they get the value back? - It's a very important, in fact, one of the biggest things that is different about the way we have done the design now, and I'd really encourage people to go look at it. This is about, look at the end of the day, search is about fair use. Ultimately, all this content we only get to use inside of a search engine if you're generating traffic for the people who create it. And so that's why if you look at whether it's in the answer, whether it's in chat, these are just a different way to represent the 10 blue links more in the context of what the user wants. So the core measure, even what SEO looks like, if anything, that'll be the thing in the next multiple years, we'll all learn. Perhaps there will be new incentives in SEO to even generate more authoritative content that then gets in. So overall, everything you saw there had annotations, everything was linkable. And that'll be the goal, whether it's inside a search, whether it's in the answer or even in the chat session. - But if I ask the new Bing, what are the 10 best gaming TVs? And it just makes me a list, why should I, the user, then click on the link to \"The Verge,\" which has another list of the 10 best gaming TVs? - Well, I mean, that's a great question. But even there you will sort of say, \"Hey, where did these things come from and would you want to go dig in?\" Like even search today has that, like we have answers, they may not be as high quality answers, they just start getting better. So I don't think of this as a complete departure from what is expected of a search engine today, which is supposed to really respond to your query while giving them the links that they can then click on like ads, and search works that way. - The reason I ask this is obviously, when you say, you're taking on a larger software category in the world, that's search, there's a dominant player in Google. If Google stops sending as much traffic from its search engine results page to publishers, to creators, to other websites, regulators around the world would freak out, because they have a dominant market share. Bing does not have a dominant market share. When you evaluate the risks, both IP risks, legal risks, regulatory risks, you say, \"Well look, we don't have the share, we can take a step forward in how we present these results in a way that our competitor cannot.\" - That's not how I come at it. - I'm just curious. - Yeah, I come at it primarily on like basic. Today, if you look at the search category, it's great. It works 50% of the time. (Nilay laughs) It doesn't work for the other 50% of the time. So I think what really I wanna do is to go back and say, \"Look, is there some new powerful technology that can make a search a better product without fundamentally changing how search gets permission to even exist as a product?\" Which is other people's content organized in useful ways so that users can find them. To me, that is the category. And so we will live and die by our ability to help publishers get their content to be seen by more people. Up to now, you're absolutely right. Google dominates this market by a significant margin. We hope, in fact, if anything, having two, you know, or multiple search engine, it's not just us. There'll be others who will be competitors. By having more, let's call it evenly spread search share, will only help publishers all get traffic from multiple sources. And by the way, advertisers better pricing. And so publishers will make more money, advertisers will make more money, and users will have great innovation. Oh and think about what a great day it'll be. (Nilay laughs) - I am eager for there to be more competition in search. What I'm curious about is if more and more people are producing more and more AI content and that becomes the base layer that you're training against. So if instead of me writing a story about the Chinese spy balloon, I ask Bing to write such a story, and that gets fed back into Bing. Eventually the amount of original content in the ecosystem begins to wither. Is that a feedback loop that you're worried about? - So yeah, absolutely. But the way I look at it and say is what people sort of talk about, like my daughter sent me this unbelievable example the other day. She's taking some French lit class and she said, Hey, I was using this AI tool to summarize what I was writing and it took me two hours, because she was doing meta prompts and prompts, and learned more about that text than ever before. And so I feel like a little bit, let's give ourselves a little permission to think about what is original content. Because as I said, AI just doesn't generate it. You prompted it. You have a draft which you edit today. I mean, I would be unemployable, but for the red squiggly in Microsoft Word, because that's what helps me write anything. So I think we all used and evolved to use new tools. I think of it that way, right? I think it, yes, it'll create, you know, some of the drudgery of knowledge work may go away, but doesn't mean I won't enjoy. Like in fact, the best place, Nilay, I feel it, is in GitHub Copilot, right? Coding, I mean, it's not like suddenly you are not coding. If anything, you are more in the flow of coding with some of these prompts. You read more code, you accept more code. So I think it's just a different way for us to perhaps enjoy our knowledge work more. - That brings us to the the second product, right? Which is the co-pilot inside of the Edge browser. If you look at Bing, you have an opportunity now to capture market share from Google. If you look at Edge, you have an opportunity to capture a market share from Chrome, potentially Safari if you go to the iPhone. Is that how you're seeing this? This is an inflection point. You have a new technology. You have a lead with this partnership with OpenAI. It's creating an opportunity for you to go take share, or is it you are expanding the category and you think you can initiate new users in a new way. - Like, I always sort of, you know, I start always not from zero sum, but I sort of sort of look and say, \"Hey, how does the category expand? How can we participate in that expansion?\" That's I think at the foundational level, but at the same time, you know, there will be, like these are places where the dominant browser is Chrome. I mean, forget anywhere else. On Windows, Google makes more money than all of Microsoft, right? So let's start there. So there's a huge opportunity for us if we got some additional share, well, for whether it's our browser or our search engine. And so that's kind of how I look at it, which is let's build first a product that is competitive in the marketplace, that's actually serving user needs. And like all things, Nilay, I'm also, I'm not a one platform guy. I'm like, I want ask, I grew up in a Microsoft. - Yeah, This is your big change in Microsoft from your leadership. - Not really. The Microsoft that I grew up in, because I always remember, yeah, that Microsoft software, like Office was on the Mac before even Windows. So that's kind of the Microsoft that I learned from. And I'll always make sure that our software is everywhere where users want it. - It's been a relative period of calm between Microsoft and Google. There was a previous period of, I would say antipathy or more open antipathy. Recently you've partnered on things like Android on some of your hardware. You've partnered, I think Microsoft 365 on Chromebooks is some partnership that was recently announced. Do you expect this new sort of head-on competition against their most important product to change that relationship? - First of all, I mean, look, I have the greatest of admirations for Google and what they've done. And you know, they're an unbelievable company with great talent and, you know, and I have a lot of respect for Sundar and his team. So therefore, I just want us to innovate, right? So there's always, I mean, we compete today. Today was a day where we brought some more competition to search. We've been at it, believe me, I've been at it for 20 years and I've been waiting for it. But look, at the end of the day, let's not, you know, they're the 800-pound gorilla on this, which is what they are. And I hope that with our innovation, they will definitely want to come out and show that they can dance. And I want people to know that we made them dance, and I think that'll be a great day. - What was the moment in the development of the product where you said, okay, it's ready, we should announce it like this, with a pretty direct shot at the 800-pound gorilla. Was there a light switch that flipped for you? Was it committee decision? How'd that work? - So when I first saw this new model, because the model that you saw today is the next generation model. - Is it GPT-4? - I'll let Sam, at the right time, talk about his numbers. So it is the next generation model and it's been done as we said, we called it the Prometheus model, because as I said, we've done a lot to the model to ground it in search, right? So the search use case is pretty unique and so we needed to ground it in that as well. So when I first saw the raw model back in the summer of, I would say 2022, is when I thought that this is a game changer in terms of the search category, aside from everything else that I'm excited about, because I do care about Azure having these APIs even. So we've been at it. In fact, I'll never forget my first query I did on the model, which I think sort of for me, growing up, you know, I always felt, like if only I could read Rumi, translate it into Urdu, transliterate it into English, that is my dream. I just put that in as one long query. And it was magical to see it generate it. And I said, \"Man, this is different.\" And you could have, I mean I could have programmed it, done some multi turn. - That was your first query? - That was the query that changed. - You're one of the classiest people I've ever met in my entire life. I mean that's like a very complicated. - It was just one of, I've read Lorca. I mean people like, well look, poetry is great, man. - I mean, I buy it. My first query was like, are you alive? So that's where I would've gone. So you run this query, right? To translate, Rumi is a Indian poet. - Persian. - Persian. Into across two languages. And you receive the response, and you think, okay, this is a product, or this is a product with revenue possibility, or this is a product with market share possibility. - Yeah, I mean like all things, one of the things that I think about is in the end, platform shifts, the two things have to happen. You have to retool pretty much every product of yours, right? So you gotta rethink it, whether it's on the way you build it, what its core features are, it's kind of like, you know, how Microsoft had to pivot for the cloud, right? Which is, you had to rethink Exchange. It was not an Exchange server. It was Exchange as a service. Or, what we had to do with, you know, our server infrastructure. We had to rebuild essentially a new core stack in Azure. So every time with transitions, you have to essentially rewrite it. That's kind of how I think about it. The second thing is you also have to think about the business model. Sometimes these transitions are pretty harsh. I'll tell you the last transition from having, you know, the high share server business with great gross margins, and saying, hey, the new business is called cloud and it's going to have one fourth the margins, is like the new news. It was pretty harsh, so we made it. Whereas in here, I look at this, there are two things. One is it's absolutely new tech, but it builds on cloud, right? So that's one place where we already have relevance, and so there is the next generation of cloud. And second in search, the economics are interesting, which is we already have a profitable business, but with very little share. And so every day I just want a few users and a little bit more gross margin. And so yeah, I did see, I think a tremendous opportunity for us to make some real progress here. - So the model right now, last I think, like Bing is an $11 billion a year revenue business. Something like that? - Something like that. I think Amy's gonna talk about, I don't know how she wants to talk about it, yeah. - Incredible hobby. I wish I had an $11 billion a year hobby. You want to grow that into a real business. You wanna take share, but obviously the new technology does not have the same cost structure as the old search query, right? I'm sure that whatever you're doing with OpenAI, it's more compute intensive. And then obviously, you have that partner sitting in the middle of it, and then the monetization model is still search ads, right? It's direct response search ads. But as you bring more and more content on the screen, that model might change or the price of those ads might change. Are you, huh? - It's so wonderful. - Yeah. - I mean, just think about what you just said. You said, okay, here is the largest software category where we have the smallest share, and what you just painted out is an unbelievable picture of incremental GM. If Steve Ballmer saw that, he would've like lit up and said, \"Oh my god.\" Very few times in history do opportunities like that show up where you suddenly can start a new race with a base where every day is incremental GM for you, and someone else has to play to protect it all, every user and all the GM. - So I wanna wrap up with two questions here. One, I just wanna come back to this. I think you are going to face a lot of scrutiny from publishers, creators, other website owners saying, \"Hey, that is our training data.\" You are already seeing it, right? Getty is suing a handful of the image generation AI companies saying, \"Hey, you're generating results with our watermark in it,\" right? \"This is obviously ours.\" So I'm curious if you have a view of the potential IP risk on the downside or on the positive side of how to grow and keep the ecosystem vibe. - I mean, on the search side, I'm very, very clear. The search category is about fair use so that we can generate traffic back to publishers. And so that's sort of, we wanna stay very focused. - [Nilay] And is that a KPI that you're keeping track of traffic you're sending out. - Absolutely, a hundred percent. Like, I mean that's the only way we are gonna be, our bots are not gonna be allowed to crawl search if we are not driving traffic. So therefore, that I think is the core of the category. In other places, again, it'll have to be really thought through as to what is the fair use. - Yeah. - And then sometimes, I think there'll be some legal cases that will also have to create precedent, but at the end of the day, I don't think any of this can be done without a framework of law that governs it and ultimately financial incentives that benefit. If anything, I look at this and say, \"God, is this something where the fact that there's going to be more competition can really help publishers get more monetization, advertisers get better returns for their investment, and users have more choice?\" - All right, I wanna end with a question that I think is the most important question. You have described a transformational moment in the largest software category in the world. You've said it obviously, there's a moment of increased competition against the dominant player. What was it like in the room when you decided to stick with the Bing brand, right? There had to been a slide with like 50 options. I'm assuming it's Microsoft. There's some passionate back and forth debate. Eventually someone decides, was it you who decided? - Yeah, we wanted to call it Azure Search 2023 Edition. - [Nilay] Xbox Live Search. (both laugh) Just go for it. - No, or bring back Clippy. - Yeah. - No, look, really, interestingly enough, it was not much of a discussion because we felt, look, we love Bing, we have been at it. I was there at the day of launch of Bing, I worked on it. - But it has a lot of baggage as a brand. - You know, it's like, look, brands can be rebuilt as long as there's innovation. I think the brands are only as good as the product and as good as the innovation. And so we're gonna go work it. - And that was your choice. - Absolutely. - All right, well, Satya, thank you so much for talking today. It was really exciting to see all the new stuff. I'm eager to see how it grows in the future. - Thank you so much, Nilay. - That's great. I have like 50 more, but I can feel the waves all around me. (laughs) - It was fun, that was great. - Huh? Thanks again for Satya for taking the time to talk to me on Decoder. Open your podcast app, subscribe to Decoder. I host it, it's great. It's a lot of conversations like that. Tom Warren and I are here at Microsoft. We're gonna be trying out the new Bing. Stay tuned. Lots of videos, hands-on impressions, and maybe a little bit more coming from Microsoft.",
    "transcript_keywords": [
        "search",
        "Microsoft",
        "Bing",
        "model",
        "search engine",
        "OpenAI",
        "Bing search",
        "today",
        "Bing search engine",
        "large models",
        "share",
        "great",
        "product",
        "models",
        "things",
        "lot",
        "Azure",
        "category",
        "Yeah",
        "search category"
    ],
    "transcript_entity_values": [
        "Azure",
        "zero",
        "Decoder",
        "Bing",
        "Android",
        "Inception",
        "Sam",
        "the day",
        "three years",
        "the end of the day",
        "Office",
        "Rumi",
        "Safari",
        "GitHub Copilot",
        "50%",
        "A couple weeks ago",
        "English",
        "Sundar",
        "Chrome",
        "One",
        "Sam Altman",
        "Exchange",
        "50",
        "Tom Warren",
        "Edge",
        "Lorca",
        "Microsoft",
        "KPI",
        "the other 50%",
        "every day",
        "Steve Ballmer",
        "Getty",
        "the next multiple years",
        "Second",
        "GM",
        "Nilay",
        "Google",
        "Persian",
        "20 years",
        "Indian",
        "decades",
        "first",
        "IP",
        "Chinese",
        "10",
        "$11 billion",
        "Today",
        "Amy",
        "the last four years",
        "The Verge",
        "AI",
        "Azure AI",
        "the summer",
        "Windows",
        "2016",
        "Nilay",
        "two hours",
        "one fourth",
        "second",
        "800-pound",
        "First",
        "one",
        "a hundred percent",
        "Chromebooks",
        "today",
        "Bing",
        "year",
        "years",
        "Satya",
        "two",
        "Satya Nadella",
        "Azure Search",
        "French",
        "a day",
        "Urdu",
        "Prometheus",
        "iPhone",
        "Mac",
        "2022"
    ],
    "transcript_entity_types": [
        "ORG",
        "CARDINAL",
        "ORG",
        "PERSON",
        "ORG",
        "ORG",
        "PERSON",
        "DATE",
        "DATE",
        "DATE",
        "ORG",
        "PERSON",
        "ORG",
        "ORG",
        "PERCENT",
        "DATE",
        "LANGUAGE",
        "PERSON",
        "ORG",
        "CARDINAL",
        "PERSON",
        "ORG",
        "CARDINAL",
        "PERSON",
        "ORG",
        "PERSON",
        "ORG",
        "ORG",
        "PERCENT",
        "DATE",
        "PERSON",
        "PERSON",
        "DATE",
        "ORDINAL",
        "ORG",
        "NORP",
        "ORG",
        "NORP",
        "DATE",
        "NORP",
        "DATE",
        "ORDINAL",
        "ORG",
        "NORP",
        "CARDINAL",
        "MONEY",
        "DATE",
        "PERSON",
        "DATE",
        "WORK_OF_ART",
        "ORG",
        "ORG",
        "DATE",
        "WORK_OF_ART",
        "DATE",
        "WORK_OF_ART",
        "TIME",
        "CARDINAL",
        "ORDINAL",
        "QUANTITY",
        "ORDINAL",
        "CARDINAL",
        "PERCENT",
        "ORG",
        "DATE",
        "ORG",
        "DATE",
        "DATE",
        "PERSON",
        "CARDINAL",
        "PERSON",
        "ORG",
        "NORP",
        "DATE",
        "GPE",
        "PERSON",
        "ORG",
        "PERSON",
        "DATE"
    ],
    "vector": [
        -0.039834361523389816,
        -0.08699887990951538,
        0.026225322857499123,
        -0.013716262765228748,
        0.07270681113004684,
        -0.06448537111282349,
        0.014855410903692245,
        -0.030288416892290115,
        0.029383709654211998,
        -0.05253986269235611,
        -0.060160212218761444,
        0.058485474437475204,
        -0.11570558696985245,
        0.028448879718780518,
        0.03867870941758156,
        0.02299896627664566,
        0.07786770164966583,
        -0.11802857369184494,
        -0.057303354144096375,
        -0.016446711495518684,
        0.00040329061448574066,
        0.029575353488326073,
        0.04725982993841171,
        -0.028769688680768013,
        -0.00838839914649725,
        0.007549141068011522,
        -0.10165505111217499,
        -0.059135351330041885,
        0.021222226321697235,
        0.015888266265392303,
        0.029135460034012794,
        0.04060228168964386,
        0.10903698205947876,
        0.08657031506299973,
        -0.06620574742555618,
        -0.022623078897595406,
        0.008031091652810574,
        0.06955554336309433,
        -0.08769750595092773,
        -0.05495180934667587,
        0.03726324066519737,
        -0.053300030529499054,
        -0.043369319289922714,
        0.0024353996850550175,
        0.010911804623901844,
        -0.049232471734285355,
        -0.040334176272153854,
        -0.08528351038694382,
        0.021454695612192154,
        0.0539269782602787,
        -0.14681804180145264,
        -0.0674683004617691,
        0.023482022807002068,
        -0.022192200645804405,
        -0.016221994534134865,
        0.055395014584064484,
        0.006765515077859163,
        0.046847011893987656,
        0.04125668480992317,
        -0.02429153025150299,
        0.013444401323795319,
        -0.07572370767593384,
        -0.012958373874425888,
        0.03782430663704872,
        0.02841261588037014,
        0.028612712398171425,
        0.022461719810962677,
        -0.02641753852367401,
        -0.015693094581365585,
        -0.07578093558549881,
        0.01725364476442337,
        -0.00835850927978754,
        0.014623874798417091,
        0.016900639981031418,
        -0.036776501685380936,
        0.0324319489300251,
        0.04211807996034622,
        0.05199135094881058,
        0.0030184558127075434,
        0.009648461826145649,
        0.021889174357056618,
        -0.026119021698832512,
        0.05452541261911392,
        0.055333785712718964,
        -0.011612887494266033,
        0.006068703718483448,
        0.0018859730334952474,
        -0.05246323347091675,
        0.04567665234208107,
        -0.03140248730778694,
        -0.069881372153759,
        -0.041903622448444366,
        0.06692143529653549,
        0.03543825447559357,
        0.0648333951830864,
        -0.017366984859108925,
        -0.051013216376304626,
        0.004944948945194483,
        -0.02931199222803116,
        0.04521426185965538,
        0.016709880903363228,
        0.033736273646354675,
        -0.031088951975107193,
        -0.12177743762731552,
        -0.09544768184423447,
        -0.006826256401836872,
        0.06443223357200623,
        0.11060672998428345,
        0.09040606766939163,
        0.009292544797062874,
        -0.02785760909318924,
        -0.008506069891154766,
        0.09352684020996094,
        -0.0660058856010437,
        -0.011470936238765717,
        0.006156370043754578,
        -0.06802535802125931,
        0.0340152233839035,
        0.06542152911424637,
        0.03541732206940651,
        0.018791021779179573,
        0.04420703649520874,
        -0.03287413343787193,
        -0.0606471486389637,
        0.014661096036434174,
        0.03989511355757713,
        -0.06194421276450157,
        2.3059685537050276e-33,
        0.05143100023269653,
        0.04805295541882515,
        -0.02685622125864029,
        0.020224858075380325,
        0.06233774498105049,
        0.03604178875684738,
        0.017693329602479935,
        0.02504892833530903,
        -0.032306548207998276,
        -0.04166058823466301,
        -0.027881676331162453,
        0.01731295883655548,
        -0.05222030729055405,
        -0.019963469356298447,
        0.05128302797675133,
        0.02210678532719612,
        -0.054798342287540436,
        0.05562051013112068,
        0.02506082132458687,
        -0.04601310193538666,
        0.08515357971191406,
        0.04362038895487785,
        0.002105619525536895,
        -0.021290399134159088,
        -0.013936959207057953,
        0.009016849100589752,
        -0.0048329150304198265,
        -0.09631448239088058,
        0.06706155091524124,
        0.03636045381426811,
        -0.09434215724468231,
        -0.009684025309979916,
        -0.10077524930238724,
        0.007426469586789608,
        0.027302386239171028,
        0.026397982612252235,
        -0.06469357013702393,
        -0.05173560976982117,
        -0.018878867849707603,
        0.01912735402584076,
        -0.0592716783285141,
        -0.003811531700193882,
        -0.0017089331522583961,
        -0.1211296021938324,
        -0.03917871043086052,
        -0.05077595263719559,
        -0.048515547066926956,
        0.012750424444675446,
        0.10377375036478043,
        0.04655490815639496,
        -0.005174384918063879,
        0.030489766970276833,
        -0.040001727640628815,
        0.025507597252726555,
        0.04817162826657295,
        -0.05077037215232849,
        0.06493351608514786,
        -0.01950644701719284,
        0.05526064336299896,
        0.012426044791936874,
        0.0173934493213892,
        -0.07454438507556915,
        -0.031190255656838417,
        0.029884394258260727,
        -0.04296863451600075,
        0.005557184107601643,
        0.046173345297575,
        0.036212023347616196,
        -0.03277803584933281,
        0.02589043416082859,
        -0.007901975885033607,
        0.004020757507532835,
        -0.01747903600335121,
        -0.02397938445210457,
        -0.0880095511674881,
        -0.00537898251786828,
        -0.05107025057077408,
        0.0010541666997596622,
        0.049071379005908966,
        0.003942468669265509,
        0.04447973892092705,
        0.007631746586412191,
        0.010855731554329395,
        -0.06618938595056534,
        -0.052138812839984894,
        0.001998176099732518,
        0.02917643077671528,
        0.014506409876048565,
        0.006079009734094143,
        0.07325180619955063,
        -0.05838603526353836,
        -0.015477040782570839,
        -0.07955454289913177,
        0.07511749863624573,
        -0.003128085983917117,
        -2.3067891956986954e-33,
        -0.10100281983613968,
        -0.006586862727999687,
        -0.0610930472612381,
        0.0007688512559980154,
        -0.03571221977472305,
        -0.01059864554554224,
        0.04642389714717865,
        -0.0065623680129647255,
        0.010635877028107643,
        -0.011422433890402317,
        0.031278885900974274,
        -0.021160747855901718,
        0.05571858584880829,
        0.04023030027747154,
        -0.012500809505581856,
        0.009305288083851337,
        0.05666853487491608,
        -0.12241832911968231,
        -0.047867558896541595,
        -0.01961084082722664,
        0.01562933623790741,
        0.08067096769809723,
        -0.16521593928337097,
        0.009718854911625385,
        0.042400579899549484,
        0.020306410267949104,
        0.05133254453539848,
        0.07112845033407211,
        0.026256531476974487,
        -0.02180606499314308,
        0.006840661633759737,
        0.023409085348248482,
        -0.13961923122406006,
        -0.0019076840253546834,
        0.09657011926174164,
        0.11083482950925827,
        0.04466245695948601,
        -0.06470729410648346,
        -0.05865643173456192,
        0.013287017121911049,
        0.040167707949876785,
        -0.04639216139912605,
        -0.04436279460787773,
        -0.027142435312271118,
        0.039834026247262955,
        0.034866344183683395,
        -0.09513965994119644,
        0.006772547494620085,
        -0.03254520520567894,
        0.007236120756715536,
        0.07611749321222305,
        0.0027639390900731087,
        0.08209606260061264,
        -0.05302325263619423,
        -0.04382820427417755,
        -0.038422875106334686,
        -0.013008460402488708,
        0.03658965975046158,
        -0.06244894489645958,
        -0.06190839782357216,
        -0.02582482248544693,
        -0.042757607996463776,
        0.05169183388352394,
        -0.0038267162162810564,
        -0.046909719705581665,
        0.04846819490194321,
        0.06077691912651062,
        0.033424437046051025,
        -0.04101431369781494,
        -0.024271421134471893,
        -0.044870343059301376,
        -0.07888297736644745,
        0.008704151026904583,
        -0.029741711914539337,
        -0.004990107845515013,
        0.09586920589208603,
        0.06206666678190231,
        -0.009661640040576458,
        -0.0645715519785881,
        -0.031891968101263046,
        -0.02265199087560177,
        -0.0213614609092474,
        0.11869648844003677,
        0.012093995697796345,
        0.10381557792425156,
        0.01147112250328064,
        0.06687930971384048,
        0.022501830011606216,
        -0.03902469202876091,
        0.014631413854658604,
        -0.05848276615142822,
        -0.026235446333885193,
        -0.15072694420814514,
        0.1182585135102272,
        0.04858945682644844,
        -4.894713967473763e-08,
        -0.09104668349027634,
        -0.08700164407491684,
        -0.08545047789812088,
        0.04866352677345276,
        0.051400892436504364,
        0.0013789241202175617,
        -0.017896203324198723,
        0.02703561820089817,
        -0.04194517806172371,
        0.017274072393774986,
        0.05934187397360802,
        -0.043772369623184204,
        -0.05672171339392662,
        0.04086931049823761,
        0.09902961552143097,
        0.07590358704328537,
        -0.04318862035870552,
        -0.0653906837105751,
        0.009412618353962898,
        -0.08978790044784546,
        0.03902805969119072,
        -0.003646352794021368,
        0.07685506343841553,
        0.036300670355558395,
        -0.039627473801374435,
        -0.025200648233294487,
        0.0003144193906337023,
        0.048238907009363174,
        -0.036276742815971375,
        0.03763367608189583,
        -0.026914546266198158,
        0.04979392886161804,
        0.0010563392424955964,
        0.0117489043623209,
        0.02234359085559845,
        -0.0161236971616745,
        0.0034182576928287745,
        0.018399450927972794,
        0.03893902152776718,
        0.054627712815999985,
        0.03786138445138931,
        0.027255719527602196,
        0.005867804866284132,
        0.004127201624214649,
        0.03502105548977852,
        0.018682006746530533,
        -0.07224279642105103,
        -0.04170789197087288,
        0.04196346178650856,
        -0.011664649471640587,
        -0.015204820781946182,
        -0.0232455525547266,
        0.08358588069677353,
        0.10972566157579422,
        0.0782354474067688,
        -0.010935196653008461,
        0.03905223682522774,
        -0.055447567254304886,
        -0.019977642223238945,
        0.1000140830874443,
        0.03105820342898369,
        0.04577479138970375,
        0.040688253939151764,
        0.024738898500800133
    ]
}